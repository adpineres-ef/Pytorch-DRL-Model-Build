{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e300f916",
   "metadata": {},
   "source": [
    "# # VRP Variant Solver Comparison (8-Node Example)\n",
    "\n",
    "# We will compare three methods for solving a profit-maximizing, duration-constrained vehicle routing problem variant on an 8-node graph:\n",
    "# 1. Deep Reinforcement Learning (DRL) using DQN.\n",
    "# 2. Mixed-Integer Programming (MIP) for the optimal solution.\n",
    "# 3. A simple Greedy Heuristic (Best Reward/Time Ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b1170ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical # For sampling actions\n",
    "import random\n",
    "from collections import deque, namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pulp \n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ee856",
   "metadata": {},
   "source": [
    "# # Define Constants (Adjusted for 8 Nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "6f7e36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set input dates\n",
    "date = \"_2024-12-09\"\n",
    "truck = \"VAN\"\n",
    "mpg = 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9d111816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name\n",
    "file_name1 = \"rate_q2_west_\"+truck+date+\".csv\"\n",
    "file_name2 = \"duration_west.csv\"\n",
    "file_name3 = \"prob_west_\"+truck+date+\".csv\"\n",
    "file_name4 = \"load_av_west_\"+truck+date+\".csv\"\n",
    "file_name5 = \"distance_west.csv\"\n",
    "file_name6 = \"diesel_west\"+date+\".csv\"\n",
    "file_name7 = \"labels_west.csv\"\n",
    "# Read the Excel file into a DataFrame\n",
    "rate_matrix = pd.read_csv(file_name1,header= None)\n",
    "time_matrix = pd.read_csv(file_name2,header = None)\n",
    "markov_matrix = pd.read_csv(file_name3,header=None)\n",
    "loads_matrix = pd.read_csv(file_name4,header=None)\n",
    "distance_matrix = pd.read_csv(file_name5,header=None)\n",
    "diesel_matrix = pd.read_csv(file_name6,header=None)\n",
    "hub_labels = pd.read_csv(file_name7,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "371ccd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_matrix = rate_matrix * distance_matrix\n",
    "revenue_matrix[loads_matrix <= 1] = 0\n",
    "diesel_matrix = diesel_matrix / mpg\n",
    "var_cost_matrix = 1.2 * distance_matrix\n",
    "cost_matrix = distance_matrix * diesel_matrix\n",
    "cost_matrix = cost_matrix + 163\n",
    "cost_matrix = cost_matrix + var_cost_matrix\n",
    "reward_matrix = revenue_matrix - cost_matrix\n",
    "time_matrix *= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9f8e466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NODES = 10\n",
    "ACTION_SPACE_SIZE = NUM_NODES\n",
    "\n",
    "# Problem Constraints (Keep the same duration limits for consistency)\n",
    "DURATION_LIMIT = 60.0\n",
    "DURATION_TOLERANCE = 0.10\n",
    "MIN_DURATION = DURATION_LIMIT * (1 - DURATION_TOLERANCE)\n",
    "MAX_DURATION = DURATION_LIMIT * (1 + DURATION_TOLERANCE)\n",
    "BIG_M_PENALTY = -1e9 # Large negative number for rewards\n",
    "\n",
    "# Use a fixed seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19180f",
   "metadata": {},
   "source": [
    "# ### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "ebbb01f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data for 10 nodes...\n",
      "\n",
      "Time Matrix (hours):\n",
      "      0     1     2     3     4     5     6     7     8     9\n",
      "0   0.0   3.4   4.2   5.4   3.7   1.7  19.1  11.5  13.3   9.3\n",
      "1   3.4   0.0   5.1   8.1   6.1   2.6  19.0  10.9  12.8  10.3\n",
      "2   4.1   5.1   0.0   8.8   6.9   2.8  15.8   7.8   9.7   6.2\n",
      "3   5.4   8.0   8.8   0.0   4.1   6.3  23.8  16.1  18.0  14.0\n",
      "4   3.6   6.1   6.9   4.1   0.0   4.4  21.9  14.2  16.1  12.1\n",
      "5   1.7   2.6   2.8   6.4   4.4   0.0  17.7  10.1  11.9   8.0\n",
      "6  19.0  19.0  15.9  23.7  21.7  17.7   0.0   8.1   6.3  10.1\n",
      "7  11.4  11.0   7.9  16.1  14.1  10.1   8.0   0.0   1.9   2.4\n",
      "8  13.2  12.8   9.6  17.9  15.9  11.9   6.3   1.9   0.0   4.2\n",
      "9   9.3  10.2   6.2  14.0  12.0   7.9  10.1   2.4   4.3   0.0\n",
      "\n",
      "Reward Matrix:\n",
      "       0      1      2      3      4      5      6      7      8      9\n",
      "0 -163.0   28.0   79.0  149.0   79.0  -68.0 -408.0 -519.0 -439.0 -452.0\n",
      "1  252.0 -163.0  188.0  400.0  316.0  204.0 -435.0 -518.0 -419.0 -495.0\n",
      "2  213.0  533.0 -163.0  429.0  327.0   20.0 -367.0 -411.0 -363.0 -358.0\n",
      "3  183.0  371.0  390.0 -163.0  119.0  238.0 -826.0 -623.0 -676.0 -481.0\n",
      "4  127.0  358.0  249.0  164.0 -163.0  211.0 -609.0 -521.0 -474.0 -528.0\n",
      "5   -5.0   -3.0   13.0  224.0  190.0 -163.0 -404.0 -491.0 -410.0 -422.0\n",
      "6 -276.0 -360.0 -327.0 -407.0 -391.0 -348.0 -163.0 -373.0  255.0 -431.0\n",
      "7  272.0  323.0  193.0  215.0  220.0  232.0   31.0 -163.0 -119.0   68.0\n",
      "8 -224.0 -222.0 -204.0 -225.0 -143.0 -217.0  259.0 -193.0 -163.0 -235.0\n",
      "9  207.0  306.0  133.0  132.0  136.0  174.0   78.0   70.0  -70.0 -163.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating data for {NUM_NODES} nodes...\")\n",
    "time_matrix = time_matrix.iloc[:NUM_NODES, :NUM_NODES]\n",
    "reward_matrix = reward_matrix.iloc[:NUM_NODES, :NUM_NODES]\n",
    "# Round for clarity\n",
    "time_matrix = np.round(time_matrix, 1)\n",
    "reward_matrix = np.round(reward_matrix, 0)\n",
    "\n",
    "# Create DataFrames for easy viewing\n",
    "time_df = pd.DataFrame(time_matrix, index=range(NUM_NODES), columns=range(NUM_NODES))\n",
    "reward_df = pd.DataFrame(reward_matrix, index=range(NUM_NODES), columns=range(NUM_NODES))\n",
    "\n",
    "print(\"\\nTime Matrix (hours):\")\n",
    "print(time_df)\n",
    "print(\"\\nReward Matrix:\")\n",
    "print(reward_df)\n",
    "\n",
    "# Apply Big M penalty to reward matrix diagonal (used by DRL and Heuristic)\n",
    "reward_matrix_penalized = reward_matrix.copy()\n",
    "reward_array = reward_matrix_penalized.to_numpy()\n",
    "np.fill_diagonal(reward_array, BIG_M_PENALTY)\n",
    "reward_matrix_penalized = pd.DataFrame(reward_array, index=reward_matrix_penalized.index, columns=reward_matrix_penalized.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b23b65",
   "metadata": {},
   "source": [
    "# **Data Description:**\n",
    "# * **Nodes:** 8 locations, indexed 0 through 7.\n",
    "# * **Time Matrix:** Shows the travel time in hours between any two nodes `i` and `j` (`time_matrix[i][j]`). Times are generally between 2 and 15 hours and are slightly asymmetric (travel `i` to `j` might take slightly different time than `j` to `i`). Diagonal is 0.\n",
    "# * **Reward Matrix:** Shows the reward (profit) gained by traveling between nodes `i` and `j` (`reward_matrix[i][j]`). Rewards range roughly from 50 to 500. There's a loose inverse correlation with time (shorter trips *tend* to have higher reward density) plus random noise. Diagonal is 0.\n",
    "#\n",
    "# **Goal Reminder:** For each starting node, find a route (cycle) that starts and ends at that node, maximizes total reward, and has a total duration around 60 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d228d8a",
   "metadata": {},
   "source": [
    "## Part 2: DRL Implementation and Training\n",
    "### DRL Hyperparameters and Agent Definition (Using PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6f17bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# DRL Hyperparameters (Can potentially reduce episodes/steps for smaller problem)\n",
    "STATE_SIZE = 2 # (current_node_index, time_elapsed_normalized)\n",
    "LEARNING_RATE = 0.0001\n",
    "GAMMA = 0.95 # Discount factor\n",
    "\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.05 \n",
    "EPSILON_DECAY_STEPS = max(50000, NUM_NODES * 10000)\n",
    "\n",
    "BUFFER_SIZE = 10000 \n",
    "BATCH_SIZE = 32 \n",
    "\n",
    "NUM_EPISODES = 60000 \n",
    "MAX_STEPS_PER_EPISODE = 50\n",
    "TARGET_UPDATE_FREQ = 50 \n",
    "\n",
    "REWARD_SCALE_FACTOR = 100.0\n",
    "\n",
    "# Rewards / Penalties \n",
    "RETURN_SUCCESS_BONUS = 1000.0 / REWARD_SCALE_FACTOR      \n",
    "TIME_VIOLATION_PENALTY = -100.0 / REWARD_SCALE_FACTOR  \n",
    "INCOMPLETE_PENALTY = -200.0 / REWARD_SCALE_FACTOR    \n",
    "\n",
    "# PyTorch Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fd1775ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qnetwork_sizes(num_nodes):\n",
    "    hidden1 = max(128, num_nodes * 8)\n",
    "    hidden2 = max(256, num_nodes * 8)\n",
    "    hidden3 = max(64, num_nodes * 4)\n",
    "    return hidden1, hidden2, hidden3\n",
    "\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, num_nodes):\n",
    "        super(QNetwork, self).__init__()\n",
    "        h1, h2, h3 = get_qnetwork_sizes(num_nodes)\n",
    "        self.fc1 = nn.Linear(state_size, h1)\n",
    "        self.bn1 = nn.BatchNorm1d(h1)\n",
    "        self.fc2 = nn.Linear(h1, h2)\n",
    "        self.bn2 = nn.BatchNorm1d(h2)\n",
    "        self.fc3 = nn.Linear(h2, h3)\n",
    "        self.bn3 = nn.BatchNorm1d(h3)\n",
    "        self.fc4 = nn.Linear(h3, action_size)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        nn.init.xavier_uniform_(self.fc4.weight)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.bn1(self.fc1(state)))\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = F.relu(self.bn3(self.fc3(x)))\n",
    "        return self.fc4(x)\n",
    "\n",
    "class DQNAgent_PyTorch:\n",
    "    def __init__(self, state_size, action_size, learning_rate, gamma, buffer_size, batch_size, device, num_nodes):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "        # Use the smaller QNetwork\n",
    "        self.policy_net = QNetwork(state_size, action_size, num_nodes).to(self.device)\n",
    "        self.target_net = QNetwork(state_size, action_size, num_nodes).to(self.device)\n",
    "        self.update_target_model()\n",
    "        self.target_net.eval()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.epsilon = EPSILON_START\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state, invalid_actions=None): # Added invalid_actions parameter\n",
    "        \"\"\"Selects an action using epsilon-greedy strategy, avoiding invalid actions.\"\"\"\n",
    "        if invalid_actions is None:\n",
    "            invalid_actions = set()\n",
    "\n",
    "        current_node_index = int(state[0]) # Assuming state[0] is node index\n",
    "\n",
    "        # Add current node itself to invalid actions for this step\n",
    "        current_step_invalid_actions = invalid_actions.union({current_node_index})\n",
    "\n",
    "        possible_actions = list(range(self.action_size))\n",
    "        valid_actions = [a for a in possible_actions if a not in current_step_invalid_actions]\n",
    "\n",
    "        # If no valid actions are possible (shouldn't normally happen unless trapped)\n",
    "        if not valid_actions:\n",
    "            # Fallback: maybe allow returning home if that's the only invalid action?\n",
    "            # Or just return a dummy action (e.g., 0) - the environment should handle this.\n",
    "            # Let's return current_node to signal being stuck, though env should handle.\n",
    "             # print(f\"Warning: No valid actions from node {current_node_index} with invalid set {current_step_invalid_actions}\")\n",
    "             return current_node_index # Return current node to signal being stuck\n",
    "\n",
    "        if random.random() <= self.epsilon:\n",
    "            # Explore: Choose randomly from valid actions\n",
    "            return random.choice(valid_actions)\n",
    "        else:\n",
    "            # Exploit: Choose the best action from Q-values among valid ones\n",
    "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "            self.policy_net.eval()\n",
    "            with torch.no_grad():\n",
    "                q_values = self.policy_net(state_tensor)\n",
    "            self.policy_net.train()\n",
    "\n",
    "            q_values_numpy = q_values.cpu().data.numpy()[0]\n",
    "\n",
    "            # Mask invalid actions by setting their Q-values to -infinity\n",
    "            for invalid_action in current_step_invalid_actions:\n",
    "                 if 0 <= invalid_action < self.action_size:\n",
    "                      q_values_numpy[invalid_action] = -np.inf\n",
    "\n",
    "            # Choose the best among the remaining valid actions\n",
    "            best_action = np.argmax(q_values_numpy)\n",
    "\n",
    "            # Sanity check if argmax still picked an invalid action (e.g., all are -inf)\n",
    "            if q_values_numpy[best_action] == -np.inf:\n",
    "                 # print(f\"Warning: All valid actions have -inf Q-value from node {current_node_index}. Choosing randomly from valid.\")\n",
    "                 # Fallback to random choice among valid if exploitation leads nowhere\n",
    "                 if valid_actions: # Ensure valid_actions is not empty\n",
    "                    return random.choice(valid_actions)\n",
    "                 else: # Truly stuck\n",
    "                    return current_node_index # Signal stuck\n",
    "\n",
    "            return best_action\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return 0.0\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e[0] for e in minibatch])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e[1] for e in minibatch])).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e[2] for e in minibatch])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e[3] for e in minibatch])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e[4] for e in minibatch]).astype(np.uint8)).float().to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target_q_next = self.target_net(next_states)\n",
    "            max_q_next = target_q_next.max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards + (self.gamma * max_q_next * (1 - dones))\n",
    "\n",
    "        current_q_values = self.policy_net(states)\n",
    "        action_q_values = current_q_values.gather(1, actions)\n",
    "        loss = self.loss_function(action_q_values, target_q_values)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def decay_epsilon(self, current_step):\n",
    "         self.epsilon = max(EPSILON_END, EPSILON_START - (EPSILON_START - EPSILON_END) * (current_step / EPSILON_DECAY_STEPS))\n",
    "\n",
    "    def load(self, path):\n",
    "        try:\n",
    "             self.policy_net.load_state_dict(torch.load(path, map_location=self.device))\n",
    "             self.update_target_model()\n",
    "             print(f\"Model weights loaded from {path}\")\n",
    "        except Exception as e:\n",
    "             print(f\"Error loading model weights: {e}\")\n",
    "\n",
    "    def save(self, path):\n",
    "        try:\n",
    "             os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "             torch.save(self.policy_net.state_dict(), path)\n",
    "             print(f\"Model weights saved to {path}\")\n",
    "        except Exception as e:\n",
    "             print(f\"Error saving model weights: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "bf1392a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-04 10:39:47,749] A new study created in memory with name: no-name-d396e0b5-4d59-4111-a7b4-3f9619fa10b0\n",
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_27132\\2420589574.py:5: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_27132\\2420589574.py:6: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  gamma = trial.suggest_uniform('gamma', 0.90, 0.99)\n",
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_27132\\2420589574.py:7: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  epsilon_start = trial.suggest_uniform('epsilon_start', 0.8, 1.0)\n",
      "C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_27132\\2420589574.py:8: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  epsilon_end = trial.suggest_uniform('epsilon_end', 0.01, 0.2)\n",
      "[I 2025-09-04 10:39:55,071] Trial 0 finished with value: -4.6476 and parameters: {'learning_rate': 7.147279574815912e-05, 'gamma': 0.9396958218734056, 'epsilon_start': 0.8537556977747792, 'epsilon_end': 0.029264461644690182, 'epsilon_decay_steps': 394006, 'buffer_size': 31834, 'batch_size': 74, 'num_episodes': 3653, 'max_steps_per_episode': 13, 'target_update_freq': 189, 'hidden1': 358, 'hidden2': 253, 'hidden3': 236}. Best is trial 0 with value: -4.6476.\n",
      "[I 2025-09-04 10:40:00,921] Trial 1 finished with value: -4.0818 and parameters: {'learning_rate': 0.0008179894398358224, 'gamma': 0.9764567885762305, 'epsilon_start': 0.9532123688057241, 'epsilon_end': 0.1252210663330476, 'epsilon_decay_steps': 225483, 'buffer_size': 41149, 'batch_size': 117, 'num_episodes': 4129, 'max_steps_per_episode': 20, 'target_update_freq': 191, 'hidden1': 257, 'hidden2': 113, 'hidden3': 221}. Best is trial 1 with value: -4.0818.\n",
      "[I 2025-09-04 10:40:03,858] Trial 2 finished with value: -7.026199999999999 and parameters: {'learning_rate': 0.00015770002731988083, 'gamma': 0.9661281166176903, 'epsilon_start': 0.8415937305814088, 'epsilon_end': 0.07058010043223736, 'epsilon_decay_steps': 156781, 'buffer_size': 27180, 'batch_size': 79, 'num_episodes': 17031, 'max_steps_per_episode': 14, 'target_update_freq': 136, 'hidden1': 464, 'hidden2': 397, 'hidden3': 198}. Best is trial 1 with value: -4.0818.\n",
      "[I 2025-09-04 10:40:06,891] Trial 3 finished with value: -4.508 and parameters: {'learning_rate': 0.00014454408536227438, 'gamma': 0.9442512556224635, 'epsilon_start': 0.8262540090660591, 'epsilon_end': 0.03448416226225012, 'epsilon_decay_steps': 206652, 'buffer_size': 23432, 'batch_size': 122, 'num_episodes': 3138, 'max_steps_per_episode': 13, 'target_update_freq': 23, 'hidden1': 422, 'hidden2': 222, 'hidden3': 235}. Best is trial 1 with value: -4.0818.\n",
      "[I 2025-09-04 10:40:09,526] Trial 4 finished with value: -3.2226 and parameters: {'learning_rate': 0.005337542515307722, 'gamma': 0.9563951898820117, 'epsilon_start': 0.9687433020584839, 'epsilon_end': 0.19054040122842236, 'epsilon_decay_steps': 440320, 'buffer_size': 49128, 'batch_size': 104, 'num_episodes': 13920, 'max_steps_per_episode': 49, 'target_update_freq': 57, 'hidden1': 134, 'hidden2': 340, 'hidden3': 230}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:11,488] Trial 5 finished with value: -4.0725999999999996 and parameters: {'learning_rate': 5.3361498641786966e-05, 'gamma': 0.9881312891427518, 'epsilon_start': 0.938204774882559, 'epsilon_end': 0.06346486722009047, 'epsilon_decay_steps': 415635, 'buffer_size': 37737, 'batch_size': 62, 'num_episodes': 7796, 'max_steps_per_episode': 43, 'target_update_freq': 126, 'hidden1': 93, 'hidden2': 269, 'hidden3': 161}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:14,990] Trial 6 finished with value: -4.7741999999999996 and parameters: {'learning_rate': 0.0028278601322765584, 'gamma': 0.9704167645478654, 'epsilon_start': 0.8215799117291007, 'epsilon_end': 0.0723883919522566, 'epsilon_decay_steps': 115587, 'buffer_size': 7283, 'batch_size': 98, 'num_episodes': 13686, 'max_steps_per_episode': 36, 'target_update_freq': 189, 'hidden1': 277, 'hidden2': 490, 'hidden3': 181}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:16,753] Trial 7 finished with value: -6.1266 and parameters: {'learning_rate': 3.779440550208072e-05, 'gamma': 0.9796651821307402, 'epsilon_start': 0.9796419772993958, 'epsilon_end': 0.1641732799035036, 'epsilon_decay_steps': 442038, 'buffer_size': 43375, 'batch_size': 42, 'num_episodes': 7418, 'max_steps_per_episode': 26, 'target_update_freq': 182, 'hidden1': 241, 'hidden2': 336, 'hidden3': 40}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:18,892] Trial 8 finished with value: -3.895 and parameters: {'learning_rate': 0.00017313498714738662, 'gamma': 0.9754098454906037, 'epsilon_start': 0.8183146672003994, 'epsilon_end': 0.19534294641849761, 'epsilon_decay_steps': 218247, 'buffer_size': 16819, 'batch_size': 76, 'num_episodes': 14636, 'max_steps_per_episode': 16, 'target_update_freq': 137, 'hidden1': 226, 'hidden2': 225, 'hidden3': 93}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:21,071] Trial 9 finished with value: -4.8107999999999995 and parameters: {'learning_rate': 0.00031714038041511444, 'gamma': 0.9667352003122835, 'epsilon_start': 0.8189743531019459, 'epsilon_end': 0.1010477759236917, 'epsilon_decay_steps': 271214, 'buffer_size': 7000, 'batch_size': 58, 'num_episodes': 7843, 'max_steps_per_episode': 45, 'target_update_freq': 106, 'hidden1': 306, 'hidden2': 495, 'hidden3': 48}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:22,754] Trial 10 finished with value: -5.836799999999999 and parameters: {'learning_rate': 0.008997115480095784, 'gamma': 0.9123531226628443, 'epsilon_start': 0.9168678193403986, 'epsilon_end': 0.1488616545100578, 'epsilon_decay_steps': 341283, 'buffer_size': 49949, 'batch_size': 16, 'num_episodes': 19178, 'max_steps_per_episode': 50, 'target_update_freq': 34, 'hidden1': 67, 'hidden2': 104, 'hidden3': 109}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:24,625] Trial 11 finished with value: -3.434 and parameters: {'learning_rate': 1.0226652201972072e-05, 'gamma': 0.9537051923167481, 'epsilon_start': 0.8781010901246311, 'epsilon_end': 0.19460616179954093, 'epsilon_decay_steps': 319417, 'buffer_size': 17956, 'batch_size': 97, 'num_episodes': 13657, 'max_steps_per_episode': 31, 'target_update_freq': 66, 'hidden1': 171, 'hidden2': 184, 'hidden3': 103}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:26,638] Trial 12 finished with value: -4.698 and parameters: {'learning_rate': 1.168161368674187e-05, 'gamma': 0.9264692922792463, 'epsilon_start': 0.8715231833106029, 'epsilon_end': 0.19882120569922043, 'epsilon_decay_steps': 482984, 'buffer_size': 17781, 'batch_size': 100, 'num_episodes': 11951, 'max_steps_per_episode': 32, 'target_update_freq': 61, 'hidden1': 158, 'hidden2': 161, 'hidden3': 123}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:28,821] Trial 13 finished with value: -5.934 and parameters: {'learning_rate': 0.0010008532629623733, 'gamma': 0.9551620224608254, 'epsilon_start': 0.8881664764391871, 'epsilon_end': 0.1671334719357986, 'epsilon_decay_steps': 339934, 'buffer_size': 16029, 'batch_size': 99, 'num_episodes': 16442, 'max_steps_per_episode': 38, 'target_update_freq': 65, 'hidden1': 159, 'hidden2': 361, 'hidden3': 80}. Best is trial 4 with value: -3.2226.\n",
      "[I 2025-09-04 10:40:30,755] Trial 14 finished with value: -2.7326000000000006 and parameters: {'learning_rate': 1.3608891719398204e-05, 'gamma': 0.9514985498331432, 'epsilon_start': 0.9911961509412119, 'epsilon_end': 0.17685002385822235, 'epsilon_decay_steps': 341629, 'buffer_size': 35816, 'batch_size': 112, 'num_episodes': 10525, 'max_steps_per_episode': 25, 'target_update_freq': 67, 'hidden1': 153, 'hidden2': 162, 'hidden3': 141}. Best is trial 14 with value: -2.7326000000000006.\n",
      "[I 2025-09-04 10:40:35,979] Trial 15 finished with value: -4.9113999999999995 and parameters: {'learning_rate': 0.009432719723431675, 'gamma': 0.9301482983556174, 'epsilon_start': 0.9960336486145465, 'epsilon_end': 0.13415535510531384, 'epsilon_decay_steps': 52187, 'buffer_size': 49767, 'batch_size': 124, 'num_episodes': 10516, 'max_steps_per_episode': 24, 'target_update_freq': 82, 'hidden1': 122, 'hidden2': 416, 'hidden3': 142}. Best is trial 14 with value: -2.7326000000000006.\n",
      "[I 2025-09-04 10:40:43,234] Trial 16 finished with value: -4.240399999999999 and parameters: {'learning_rate': 0.003269863301562338, 'gamma': 0.9557125752938752, 'epsilon_start': 0.9654963709760113, 'epsilon_end': 0.17271851189291615, 'epsilon_decay_steps': 497885, 'buffer_size': 34427, 'batch_size': 91, 'num_episodes': 10313, 'max_steps_per_episode': 25, 'target_update_freq': 42, 'hidden1': 198, 'hidden2': 313, 'hidden3': 256}. Best is trial 14 with value: -2.7326000000000006.\n",
      "[I 2025-09-04 10:40:50,888] Trial 17 finished with value: -3.8415999999999997 and parameters: {'learning_rate': 0.0006541379749876332, 'gamma': 0.9335280284606261, 'epsilon_start': 0.999397537207845, 'epsilon_end': 0.11081066644431999, 'epsilon_decay_steps': 385839, 'buffer_size': 44327, 'batch_size': 116, 'num_episodes': 19998, 'max_steps_per_episode': 50, 'target_update_freq': 10, 'hidden1': 334, 'hidden2': 159, 'hidden3': 182}. Best is trial 14 with value: -2.7326000000000006.\n",
      "[I 2025-09-04 10:40:56,903] Trial 18 finished with value: -1.8869999999999998 and parameters: {'learning_rate': 2.515534379947871e-05, 'gamma': 0.9143710782891383, 'epsilon_start': 0.9224812243602115, 'epsilon_end': 0.17562153271847875, 'epsilon_decay_steps': 297063, 'buffer_size': 31159, 'batch_size': 111, 'num_episodes': 11546, 'max_steps_per_episode': 20, 'target_update_freq': 95, 'hidden1': 124, 'hidden2': 67, 'hidden3': 139}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:04,198] Trial 19 finished with value: -5.549799999999999 and parameters: {'learning_rate': 2.4609372273378554e-05, 'gamma': 0.9033243601777065, 'epsilon_start': 0.9156222725947474, 'epsilon_end': 0.14522502614005522, 'epsilon_decay_steps': 291381, 'buffer_size': 29967, 'batch_size': 113, 'num_episodes': 6108, 'max_steps_per_episode': 20, 'target_update_freq': 93, 'hidden1': 64, 'hidden2': 65, 'hidden3': 142}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:10,997] Trial 20 finished with value: -4.5169999999999995 and parameters: {'learning_rate': 2.2042050802307995e-05, 'gamma': 0.9177046602576175, 'epsilon_start': 0.9338052287634689, 'epsilon_end': 0.10351200670147746, 'epsilon_decay_steps': 265542, 'buffer_size': 24647, 'batch_size': 86, 'num_episodes': 9574, 'max_steps_per_episode': 19, 'target_update_freq': 159, 'hidden1': 209, 'hidden2': 68, 'hidden3': 73}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:19,776] Trial 21 finished with value: -5.002199999999999 and parameters: {'learning_rate': 1.972086554737739e-05, 'gamma': 0.9497440257364963, 'epsilon_start': 0.9732663512978652, 'epsilon_end': 0.1766640853143235, 'epsilon_decay_steps': 356466, 'buffer_size': 37126, 'batch_size': 110, 'num_episodes': 12111, 'max_steps_per_episode': 28, 'target_update_freq': 107, 'hidden1': 127, 'hidden2': 144, 'hidden3': 159}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:27,141] Trial 22 finished with value: -5.719600000000001 and parameters: {'learning_rate': 0.002441841360268964, 'gamma': 0.9609192287866661, 'epsilon_start': 0.9495791851468074, 'epsilon_end': 0.17742951536505125, 'epsilon_decay_steps': 432259, 'buffer_size': 45557, 'batch_size': 128, 'num_episodes': 15845, 'max_steps_per_episode': 22, 'target_update_freq': 49, 'hidden1': 118, 'hidden2': 113, 'hidden3': 118}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:34,195] Trial 23 finished with value: -4.5584 and parameters: {'learning_rate': 8.607435069058209e-05, 'gamma': 0.9009430262121156, 'epsilon_start': 0.980266413619919, 'epsilon_end': 0.15264543169829045, 'epsilon_decay_steps': 374424, 'buffer_size': 38441, 'batch_size': 107, 'num_episodes': 12196, 'max_steps_per_episode': 35, 'target_update_freq': 80, 'hidden1': 192, 'hidden2': 196, 'hidden3': 195}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:41,548] Trial 24 finished with value: -2.9858 and parameters: {'learning_rate': 0.00043197912840273184, 'gamma': 0.9417107087877454, 'epsilon_start': 0.9099340644248604, 'epsilon_end': 0.18253298083470612, 'epsilon_decay_steps': 311033, 'buffer_size': 33249, 'batch_size': 107, 'num_episodes': 8626, 'max_steps_per_episode': 10, 'target_update_freq': 82, 'hidden1': 141, 'hidden2': 288, 'hidden3': 132}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:46,248] Trial 25 finished with value: -3.0846000000000005 and parameters: {'learning_rate': 0.0003214612288560631, 'gamma': 0.9183478607037323, 'epsilon_start': 0.8974026656365282, 'epsilon_end': 0.15654492582626428, 'epsilon_decay_steps': 310513, 'buffer_size': 32920, 'batch_size': 83, 'num_episodes': 9501, 'max_steps_per_episode': 17, 'target_update_freq': 89, 'hidden1': 100, 'hidden2': 95, 'hidden3': 129}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:51,225] Trial 26 finished with value: -4.6586 and parameters: {'learning_rate': 3.994638038308892e-05, 'gamma': 0.9404217321002575, 'epsilon_start': 0.9209136085866187, 'epsilon_end': 0.1331584271574171, 'epsilon_decay_steps': 253424, 'buffer_size': 28418, 'batch_size': 62, 'num_episodes': 5865, 'max_steps_per_episode': 10, 'target_update_freq': 120, 'hidden1': 155, 'hidden2': 239, 'hidden3': 160}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:41:57,047] Trial 27 finished with value: -4.4068000000000005 and parameters: {'learning_rate': 0.0004773780171777269, 'gamma': 0.922402218641358, 'epsilon_start': 0.9042790679337902, 'epsilon_end': 0.1851662801516949, 'epsilon_decay_steps': 179836, 'buffer_size': 34699, 'batch_size': 90, 'num_episodes': 8379, 'max_steps_per_episode': 10, 'target_update_freq': 98, 'hidden1': 211, 'hidden2': 286, 'hidden3': 134}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:02,824] Trial 28 finished with value: -2.103 and parameters: {'learning_rate': 0.0015209724290952606, 'gamma': 0.908094903117357, 'epsilon_start': 0.8629612082023568, 'epsilon_end': 0.011158717393248807, 'epsilon_decay_steps': 296645, 'buffer_size': 41145, 'batch_size': 119, 'num_episodes': 6046, 'max_steps_per_episode': 28, 'target_update_freq': 76, 'hidden1': 383, 'hidden2': 141, 'hidden3': 153}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:08,724] Trial 29 finished with value: -3.3122 and parameters: {'learning_rate': 0.001797597781225244, 'gamma': 0.9090302358312811, 'epsilon_start': 0.8546627525330279, 'epsilon_end': 0.012036144677482308, 'epsilon_decay_steps': 246737, 'buffer_size': 40336, 'batch_size': 120, 'num_episodes': 2146, 'max_steps_per_episode': 28, 'target_update_freq': 154, 'hidden1': 377, 'hidden2': 139, 'hidden3': 173}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:14,251] Trial 30 finished with value: -3.6844 and parameters: {'learning_rate': 9.103377448675292e-05, 'gamma': 0.9349047310150111, 'epsilon_start': 0.8559342142804368, 'epsilon_end': 0.05319807407905931, 'epsilon_decay_steps': 291509, 'buffer_size': 30358, 'batch_size': 39, 'num_episodes': 5662, 'max_steps_per_episode': 28, 'target_update_freq': 116, 'hidden1': 502, 'hidden2': 195, 'hidden3': 208}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:19,942] Trial 31 finished with value: -4.239 and parameters: {'learning_rate': 0.001376606707808611, 'gamma': 0.9113223906204134, 'epsilon_start': 0.876912241421685, 'epsilon_end': 0.011151797212157227, 'epsilon_decay_steps': 315987, 'buffer_size': 35287, 'batch_size': 112, 'num_episodes': 8879, 'max_steps_per_episode': 23, 'target_update_freq': 81, 'hidden1': 383, 'hidden2': 129, 'hidden3': 153}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:25,554] Trial 32 finished with value: -4.9378 and parameters: {'learning_rate': 1.6338313044163327e-05, 'gamma': 0.9470518088092904, 'epsilon_start': 0.8011281683342163, 'epsilon_end': 0.09156649806070434, 'epsilon_decay_steps': 350233, 'buffer_size': 41621, 'batch_size': 127, 'num_episodes': 6629, 'max_steps_per_episode': 17, 'target_update_freq': 74, 'hidden1': 306, 'hidden2': 84, 'hidden3': 144}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:31,127] Trial 33 finished with value: -4.2612 and parameters: {'learning_rate': 0.0005254177757081878, 'gamma': 0.9058016214154374, 'epsilon_start': 0.902517903491979, 'epsilon_end': 0.12530660146144945, 'epsilon_decay_steps': 296950, 'buffer_size': 31978, 'batch_size': 107, 'num_episodes': 5131, 'max_steps_per_episode': 21, 'target_update_freq': 71, 'hidden1': 430, 'hidden2': 169, 'hidden3': 110}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:37,403] Trial 34 finished with value: -3.5550000000000006 and parameters: {'learning_rate': 0.0010041161519204833, 'gamma': 0.9395053589682277, 'epsilon_start': 0.8426098539159989, 'epsilon_end': 0.03389863255065735, 'epsilon_decay_steps': 232263, 'buffer_size': 25887, 'batch_size': 121, 'num_episodes': 4113, 'max_steps_per_episode': 14, 'target_update_freq': 53, 'hidden1': 265, 'hidden2': 260, 'hidden3': 175}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:45,232] Trial 35 finished with value: -4.642599999999999 and parameters: {'learning_rate': 0.00020020726136250243, 'gamma': 0.9167189831913843, 'epsilon_start': 0.8659176175551833, 'epsilon_end': 0.1837548925134973, 'epsilon_decay_steps': 403214, 'buffer_size': 40147, 'batch_size': 116, 'num_episodes': 11494, 'max_steps_per_episode': 32, 'target_update_freq': 95, 'hidden1': 339, 'hidden2': 430, 'hidden3': 132}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:51,583] Trial 36 finished with value: -5.410999999999999 and parameters: {'learning_rate': 3.163370276457838e-05, 'gamma': 0.9284845682364279, 'epsilon_start': 0.9304412100429214, 'epsilon_end': 0.16244265248251738, 'epsilon_decay_steps': 370504, 'buffer_size': 22737, 'batch_size': 106, 'num_episodes': 10859, 'max_steps_per_episode': 26, 'target_update_freq': 36, 'hidden1': 93, 'hidden2': 121, 'hidden3': 87}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:42:59,474] Trial 37 finished with value: -5.546799999999999 and parameters: {'learning_rate': 0.00010785972734962902, 'gamma': 0.9398274993116494, 'epsilon_start': 0.9548437452860198, 'epsilon_end': 0.08351883081420786, 'epsilon_decay_steps': 197054, 'buffer_size': 21244, 'batch_size': 93, 'num_episodes': 12960, 'max_steps_per_episode': 12, 'target_update_freq': 105, 'hidden1': 435, 'hidden2': 210, 'hidden3': 145}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:43:06,082] Trial 38 finished with value: -2.5724 and parameters: {'learning_rate': 4.943308558164941e-05, 'gamma': 0.9229268049888737, 'epsilon_start': 0.8862476565600855, 'epsilon_end': 0.1416998540920541, 'epsilon_decay_steps': 326181, 'buffer_size': 27627, 'batch_size': 70, 'num_episodes': 7295, 'max_steps_per_episode': 34, 'target_update_freq': 133, 'hidden1': 243, 'hidden2': 86, 'hidden3': 194}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:43:12,983] Trial 39 finished with value: -3.9218 and parameters: {'learning_rate': 5.5909814663439914e-05, 'gamma': 0.9214401217556053, 'epsilon_start': 0.8870308302919275, 'epsilon_end': 0.14057871790532755, 'epsilon_decay_steps': 324111, 'buffer_size': 27879, 'batch_size': 52, 'num_episodes': 7085, 'max_steps_per_episode': 40, 'target_update_freq': 147, 'hidden1': 183, 'hidden2': 84, 'hidden3': 218}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:43:21,098] Trial 40 finished with value: -6.1728 and parameters: {'learning_rate': 5.507324180886803e-05, 'gamma': 0.9131398557967034, 'epsilon_start': 0.8417932232334504, 'epsilon_end': 0.11416798875878521, 'epsilon_decay_steps': 129381, 'buffer_size': 45992, 'batch_size': 74, 'num_episodes': 3199, 'max_steps_per_episode': 35, 'target_update_freq': 169, 'hidden1': 246, 'hidden2': 108, 'hidden3': 201}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:43:28,335] Trial 41 finished with value: -4.077999999999999 and parameters: {'learning_rate': 1.5571271989373654e-05, 'gamma': 0.922757316029138, 'epsilon_start': 0.8912769488909349, 'epsilon_end': 0.18372460424700887, 'epsilon_decay_steps': 292435, 'buffer_size': 36678, 'batch_size': 103, 'num_episodes': 4719, 'max_steps_per_episode': 30, 'target_update_freq': 125, 'hidden1': 142, 'hidden2': 139, 'hidden3': 169}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:43:34,680] Trial 42 finished with value: -5.306 and parameters: {'learning_rate': 3.0228759527969533e-05, 'gamma': 0.9069608997914553, 'epsilon_start': 0.9098554771839524, 'epsilon_end': 0.16181876245627883, 'epsilon_decay_steps': 333741, 'buffer_size': 32904, 'batch_size': 72, 'num_episodes': 9034, 'max_steps_per_episode': 34, 'target_update_freq': 138, 'hidden1': 236, 'hidden2': 67, 'hidden3': 116}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:43:42,945] Trial 43 finished with value: -7.284199999999999 and parameters: {'learning_rate': 0.00023094606799395134, 'gamma': 0.962969449844771, 'epsilon_start': 0.8642868498690064, 'epsilon_end': 0.053649036870821, 'epsilon_decay_steps': 253025, 'buffer_size': 30539, 'batch_size': 69, 'num_episodes': 8032, 'max_steps_per_episode': 38, 'target_update_freq': 113, 'hidden1': 298, 'hidden2': 377, 'hidden3': 187}. Best is trial 18 with value: -1.8869999999999998.\n",
      "[I 2025-09-04 10:43:49,846] Trial 44 finished with value: -1.1463999999999999 and parameters: {'learning_rate': 0.00012086962231577061, 'gamma': 0.944569325661885, 'epsilon_start': 0.9442954134728971, 'epsilon_end': 0.17221328941162498, 'epsilon_decay_steps': 279452, 'buffer_size': 38980, 'batch_size': 81, 'num_episodes': 10215, 'max_steps_per_episode': 15, 'target_update_freq': 86, 'hidden1': 108, 'hidden2': 312, 'hidden3': 154}. Best is trial 44 with value: -1.1463999999999999.\n",
      "[I 2025-09-04 10:43:56,443] Trial 45 finished with value: -2.8618 and parameters: {'learning_rate': 0.00012670506519234457, 'gamma': 0.9894625986829186, 'epsilon_start': 0.9444275633733056, 'epsilon_end': 0.17217531173283002, 'epsilon_decay_steps': 279397, 'buffer_size': 38511, 'batch_size': 82, 'num_episodes': 14984, 'max_steps_per_episode': 19, 'target_update_freq': 130, 'hidden1': 108, 'hidden2': 333, 'hidden3': 153}. Best is trial 44 with value: -1.1463999999999999.\n",
      "[I 2025-09-04 10:44:02,773] Trial 46 finished with value: -4.892399999999999 and parameters: {'learning_rate': 6.714871999759728e-05, 'gamma': 0.9504714959619976, 'epsilon_start': 0.9283675710004266, 'epsilon_end': 0.1908337609039879, 'epsilon_decay_steps': 234217, 'buffer_size': 42322, 'batch_size': 47, 'num_episodes': 9874, 'max_steps_per_episode': 15, 'target_update_freq': 200, 'hidden1': 398, 'hidden2': 174, 'hidden3': 167}. Best is trial 44 with value: -1.1463999999999999.\n",
      "[I 2025-09-04 10:44:08,895] Trial 47 finished with value: -4.4012 and parameters: {'learning_rate': 1.3303890602928419e-05, 'gamma': 0.9339648794054908, 'epsilon_start': 0.9854591669397793, 'epsilon_end': 0.15631926813943484, 'epsilon_decay_steps': 359063, 'buffer_size': 20584, 'batch_size': 66, 'num_episodes': 12958, 'max_steps_per_episode': 23, 'target_update_freq': 70, 'hidden1': 83, 'hidden2': 92, 'hidden3': 191}. Best is trial 44 with value: -1.1463999999999999.\n",
      "[I 2025-09-04 10:44:18,878] Trial 48 finished with value: -4.5212 and parameters: {'learning_rate': 4.06804178697408e-05, 'gamma': 0.9830100186452018, 'epsilon_start': 0.9597567511532132, 'epsilon_end': 0.1223047690805315, 'epsilon_decay_steps': 275676, 'buffer_size': 12945, 'batch_size': 22, 'num_episodes': 7412, 'max_steps_per_episode': 26, 'target_update_freq': 105, 'hidden1': 465, 'hidden2': 309, 'hidden3': 229}. Best is trial 44 with value: -1.1463999999999999.\n",
      "[I 2025-09-04 10:44:28,527] Trial 49 finished with value: -5.376200000000001 and parameters: {'learning_rate': 0.0041424837267364945, 'gamma': 0.9139688914718034, 'epsilon_start': 0.8317393925153289, 'epsilon_end': 0.16871261749965064, 'epsilon_decay_steps': 422986, 'buffer_size': 47752, 'batch_size': 96, 'num_episodes': 10822, 'max_steps_per_episode': 18, 'target_update_freq': 58, 'hidden1': 277, 'hidden2': 236, 'hidden3': 103}. Best is trial 44 with value: -1.1463999999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "{'learning_rate': 0.00012086962231577061, 'gamma': 0.944569325661885, 'epsilon_start': 0.9442954134728971, 'epsilon_end': 0.17221328941162498, 'epsilon_decay_steps': 279452, 'buffer_size': 38980, 'batch_size': 81, 'num_episodes': 10215, 'max_steps_per_episode': 15, 'target_update_freq': 86, 'hidden1': 108, 'hidden2': 312, 'hidden3': 154}\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-2)\n",
    "    gamma = trial.suggest_uniform('gamma', 0.90, 0.99)\n",
    "    epsilon_start = trial.suggest_uniform('epsilon_start', 0.8, 1.0)\n",
    "    epsilon_end = trial.suggest_uniform('epsilon_end', 0.01, 0.2)\n",
    "    epsilon_decay_steps = trial.suggest_int('epsilon_decay_steps', NUM_NODES*5000, NUM_NODES*50000)\n",
    "    buffer_size = trial.suggest_int('buffer_size', 5000, 50000)\n",
    "    batch_size = trial.suggest_int('batch_size', 16, 128)\n",
    "    num_episodes = trial.suggest_int('num_episodes', 2000, 20000)\n",
    "    max_steps_per_episode = trial.suggest_int('max_steps_per_episode', NUM_NODES, NUM_NODES*5)\n",
    "    target_update_freq = trial.suggest_int('target_update_freq', 10, 200)\n",
    "    # QNetwork sizes\n",
    "    hidden1 = trial.suggest_int('hidden1', max(64, NUM_NODES*4), max(512, NUM_NODES*32))\n",
    "    hidden2 = trial.suggest_int('hidden2', max(64, NUM_NODES*4), max(512, NUM_NODES*32))\n",
    "    hidden3 = trial.suggest_int('hidden3', max(32, NUM_NODES*2), max(256, NUM_NODES*16))\n",
    "\n",
    "    # Define QNetwork with trial sizes\n",
    "    class QNetworkOptuna(nn.Module):\n",
    "        def __init__(self, state_size, action_size):\n",
    "            super().__init__()\n",
    "            self.fc1 = nn.Linear(state_size, hidden1)\n",
    "            self.bn1 = nn.BatchNorm1d(hidden1)\n",
    "            self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "            self.bn2 = nn.BatchNorm1d(hidden2)\n",
    "            self.fc3 = nn.Linear(hidden2, hidden3)\n",
    "            self.bn3 = nn.BatchNorm1d(hidden3)\n",
    "            self.fc4 = nn.Linear(hidden3, action_size)\n",
    "            nn.init.xavier_uniform_(self.fc1.weight)\n",
    "            nn.init.xavier_uniform_(self.fc2.weight)\n",
    "            nn.init.xavier_uniform_(self.fc3.weight)\n",
    "            nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        def forward(self, state):\n",
    "            x = F.relu(self.bn1(self.fc1(state)))\n",
    "            x = F.relu(self.bn2(self.fc2(x)))\n",
    "            x = F.relu(self.bn3(self.fc3(x)))\n",
    "            return self.fc4(x)\n",
    "\n",
    "    # Minimal agent for tuning\n",
    "    class DQNAgentOptuna(DQNAgent_PyTorch):\n",
    "        def __init__(self, state_size, action_size, device):\n",
    "            super().__init__(\n",
    "                state_size, action_size, learning_rate, gamma,\n",
    "                buffer_size, batch_size, device, NUM_NODES\n",
    "            )\n",
    "            self.policy_net = QNetworkOptuna(state_size, action_size).to(device)\n",
    "            self.target_net = QNetworkOptuna(state_size, action_size).to(device)\n",
    "            self.update_target_model()\n",
    "            self.target_net.eval()\n",
    "            self.epsilon = epsilon_start\n",
    "\n",
    "        def decay_epsilon(self, current_step):\n",
    "            self.epsilon = max(epsilon_end, epsilon_start - (epsilon_start - epsilon_end) * (current_step / epsilon_decay_steps))\n",
    "\n",
    "    # Run a short training loop for evaluation\n",
    "    agent = DQNAgentOptuna(STATE_SIZE, ACTION_SPACE_SIZE, device)\n",
    "    avg_rewards = []\n",
    "    total_steps = 0\n",
    "    for ep in range(num_episodes):\n",
    "        #start_node = random.randint(0, NUM_NODES-1)\n",
    "        start_node = 0\n",
    "        current_node = start_node\n",
    "        time_elapsed = 0.0\n",
    "        state = np.array([current_node, time_elapsed / MAX_DURATION], dtype=np.float32)\n",
    "        episode_reward = 0\n",
    "        for step in range(max_steps_per_episode):\n",
    "            action = agent.act(state)\n",
    "            next_node = action\n",
    "            step_time = time_matrix[current_node][next_node]\n",
    "            step_reward = reward_matrix[current_node][next_node] / REWARD_SCALE_FACTOR\n",
    "            next_time_elapsed = time_elapsed + step_time\n",
    "            next_state = np.array([next_node, min(next_time_elapsed, MAX_DURATION) / MAX_DURATION], dtype=np.float32)\n",
    "            terminal_reward = 0\n",
    "            done = False\n",
    "            if next_node == start_node:\n",
    "                if MIN_DURATION <= next_time_elapsed <= MAX_DURATION:\n",
    "                    terminal_reward = RETURN_SUCCESS_BONUS\n",
    "                    done = True\n",
    "                elif next_time_elapsed < MIN_DURATION:\n",
    "                    terminal_reward = INCOMPLETE_PENALTY\n",
    "                    done = True\n",
    "                else:\n",
    "                    terminal_reward = TIME_VIOLATION_PENALTY\n",
    "                    done = True\n",
    "            elif next_time_elapsed > MAX_DURATION:\n",
    "                terminal_reward = TIME_VIOLATION_PENALTY\n",
    "                done = True\n",
    "            total_reward_experience = step_reward + terminal_reward\n",
    "            agent.remember(state, action, total_reward_experience, next_state, done)\n",
    "            state = next_state\n",
    "            current_node = next_node\n",
    "            time_elapsed = next_time_elapsed\n",
    "            episode_reward += step_reward\n",
    "            total_steps += 1\n",
    "            agent.decay_epsilon(total_steps)\n",
    "            agent.replay()\n",
    "            if done:\n",
    "                episode_reward += terminal_reward\n",
    "                break\n",
    "        avg_rewards.append(episode_reward)\n",
    "        # Early stopping for speed\n",
    "        if ep > 100 and np.mean(avg_rewards[-50:]) < 0.1:\n",
    "            break\n",
    "    # Return mean reward over last 50 episodes\n",
    "    return np.mean(avg_rewards[-50:])\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192963f",
   "metadata": {},
   "source": [
    "### DRL Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d14d130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best Optuna parameters\n",
    "best = study.best_params\n",
    "\n",
    "LEARNING_RATE = best['learning_rate']\n",
    "GAMMA = best['gamma']\n",
    "EPSILON_START = best['epsilon_start']\n",
    "EPSILON_END = best['epsilon_end']\n",
    "EPSILON_DECAY_STEPS = best['epsilon_decay_steps']\n",
    "BUFFER_SIZE = best['buffer_size']\n",
    "BATCH_SIZE = best['batch_size']\n",
    "NUM_EPISODES = best['num_episodes']\n",
    "MAX_STEPS_PER_EPISODE = best['max_steps_per_episode']\n",
    "TARGET_UPDATE_FREQ = best['target_update_freq']\n",
    "\n",
    "def get_qnetwork_sizes(num_nodes):\n",
    "    hidden1 = best['hidden1']\n",
    "    hidden2 = best['hidden2']\n",
    "    hidden3 = best['hidden3']\n",
    "    return hidden1, hidden2, hidden3\n",
    "\n",
    "# Now create your agent and start training as usual\n",
    "drl_agent = DQNAgent_PyTorch(\n",
    "    state_size=STATE_SIZE,\n",
    "    action_size=ACTION_SPACE_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    gamma=GAMMA,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    num_nodes=NUM_NODES\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "831eb6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DRL Training...\n",
      "DRL Episode: 1021/10215, Steps: 6, Total Steps: 6005, Reward: -13, Avg Loss: 14.4706, Epsilon: 0.928\n",
      "DRL Episode: 2042/10215, Steps: 3, Total Steps: 11972, Reward: -3, Avg Loss: 27.8929, Epsilon: 0.911\n",
      "DRL Episode: 3063/10215, Steps: 6, Total Steps: 17957, Reward: -8, Avg Loss: 24.6359, Epsilon: 0.895\n",
      "DRL Episode: 4084/10215, Steps: 8, Total Steps: 24074, Reward: 2, Avg Loss: 22.6204, Epsilon: 0.878\n",
      "DRL Episode: 5105/10215, Steps: 7, Total Steps: 30260, Reward: -5, Avg Loss: 24.5279, Epsilon: 0.861\n",
      "DRL Episode: 6126/10215, Steps: 6, Total Steps: 36453, Reward: -1, Avg Loss: 23.5852, Epsilon: 0.844\n",
      "DRL Episode: 7147/10215, Steps: 8, Total Steps: 42564, Reward: 7, Avg Loss: 25.5698, Epsilon: 0.827\n",
      "DRL Episode: 8168/10215, Steps: 5, Total Steps: 48806, Reward: -19, Avg Loss: 24.8027, Epsilon: 0.809\n",
      "DRL Episode: 9189/10215, Steps: 7, Total Steps: 55076, Reward: -9, Avg Loss: 19.8019, Epsilon: 0.792\n",
      "DRL Episode: 10210/10215, Steps: 10, Total Steps: 61390, Reward: 4, Avg Loss: 26.3877, Epsilon: 0.775\n",
      "\n",
      "DRL Training Finished. Total time: 1196.11 seconds\n"
     ]
    }
   ],
   "source": [
    "# drl_agent = DQNAgent_PyTorch(state_size=STATE_SIZE,\n",
    "#                            action_size=ACTION_SPACE_SIZE,\n",
    "#                            learning_rate=LEARNING_RATE,\n",
    "#                            gamma=GAMMA,\n",
    "#                            buffer_size=BUFFER_SIZE,\n",
    "#                            batch_size=BATCH_SIZE,\n",
    "#                            device=device, num_nodes=NUM_NODES)\n",
    "\n",
    "# Training History\n",
    "drl_episode_rewards = []\n",
    "drl_episode_losses = []\n",
    "drl_total_steps = 0\n",
    "drl_start_train_time = time.time()\n",
    "\n",
    "print(\"Starting DRL Training...\")\n",
    "\n",
    "#for start_node in range(0,NUM_NODES-1):\n",
    "#print(start_node)\n",
    "last_reward = 0\n",
    "episode = 0\n",
    "counter = 0\n",
    "while episode < NUM_EPISODES and counter < 2:\n",
    "#for episode in range(NUM_EPISODES):\n",
    "    start_node = random.randint(0, NUM_NODES-1)\n",
    "    current_node = start_node\n",
    "    time_elapsed = 0.0\n",
    "    state = np.array([current_node, time_elapsed / MAX_DURATION], dtype=np.float32)\n",
    "\n",
    "    episode_reward = 0\n",
    "    episode_loss_sum = 0\n",
    "    steps_in_episode = 0\n",
    "    done = False\n",
    "\n",
    "    for step in range(MAX_STEPS_PER_EPISODE):\n",
    "        action = drl_agent.act(state)\n",
    "        next_node = action\n",
    "        step_time = time_matrix[current_node][next_node]\n",
    "        # Use penalized reward matrix for DRL training decisions (implicitly via learned Q)\n",
    "        # but store experience based on actual rewards + terminal bonus/penalty\n",
    "        step_reward = reward_matrix[current_node][next_node] / REWARD_SCALE_FACTOR # Base reward for the step\n",
    "\n",
    "        next_time_elapsed = time_elapsed + step_time\n",
    "        next_state = np.array([next_node, min(next_time_elapsed, MAX_DURATION) / MAX_DURATION], dtype=np.float32)\n",
    "\n",
    "        terminal_reward = 0\n",
    "        done = False\n",
    "\n",
    "        # Termination checks (Same logic as before)\n",
    "        if next_node == start_node:\n",
    "            if MIN_DURATION <= next_time_elapsed <= MAX_DURATION:\n",
    "                terminal_reward = RETURN_SUCCESS_BONUS\n",
    "                done = True\n",
    "            elif next_time_elapsed < MIN_DURATION:\n",
    "                terminal_reward = INCOMPLETE_PENALTY\n",
    "                done = True\n",
    "            else: # > MAX_DURATION\n",
    "                terminal_reward = TIME_VIOLATION_PENALTY\n",
    "                done = True\n",
    "        elif next_time_elapsed > MAX_DURATION:\n",
    "            terminal_reward = TIME_VIOLATION_PENALTY\n",
    "            done = True\n",
    "\n",
    "        # Total reward for the experience tuple\n",
    "        total_reward_experience = step_reward + terminal_reward\n",
    "\n",
    "        drl_agent.remember(state, action, total_reward_experience, next_state, done)\n",
    "\n",
    "        state = next_state\n",
    "        current_node = next_node\n",
    "        time_elapsed = next_time_elapsed\n",
    "        episode_reward += step_reward # Track sum of actual step rewards\n",
    "        steps_in_episode += 1\n",
    "        drl_total_steps += 1\n",
    "\n",
    "        drl_agent.decay_epsilon(drl_total_steps)\n",
    "        loss = drl_agent.replay()\n",
    "        if loss > 0: episode_loss_sum += loss\n",
    "        if drl_total_steps % TARGET_UPDATE_FREQ == 0: drl_agent.update_target_model()\n",
    "        if done:\n",
    "            episode_reward += terminal_reward # Add final bonus/penalty for logging\n",
    "            break\n",
    "\n",
    "    drl_episode_rewards.append(episode_reward)\n",
    "    avg_loss = episode_loss_sum / steps_in_episode if steps_in_episode > 0 else 0\n",
    "    drl_episode_losses.append(avg_loss)\n",
    "    episode = episode + 1\n",
    "    if (episode + 1) % (NUM_EPISODES // 10) == 0: # Print progress 10 times\n",
    "        print(f\"DRL Episode: {episode + 1}/{NUM_EPISODES}, Steps: {steps_in_episode}, Total Steps: {drl_total_steps}, Reward: {episode_reward:.0f}, Avg Loss: {avg_loss:.4f}, Epsilon: {drl_agent.epsilon:.3f}\")\n",
    "        if last_reward == episode_reward:\n",
    "            counter = counter + 1\n",
    "            print(counter)\n",
    "        last_reward = episode_reward\n",
    "\n",
    "drl_training_time = time.time() - drl_start_train_time\n",
    "print(f\"\\nDRL Training Finished. Total time: {drl_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0ae01066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot DRL Training Progress\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(pd.Series(drl_episode_rewards).rolling(50).mean()) # Smoothed rewards\n",
    "plt.title('DRL Smoothed Episode Rewards')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Smoothed Reward')\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(pd.Series(drl_episode_losses).rolling(50).mean()) # Smoothed loss\n",
    "plt.title('DRL Smoothed Average Episode Loss')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7cb96c",
   "metadata": {},
   "source": [
    "### DRL Route Generation Function (Same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "96e89d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_optimal_route_pytorch(agent, start_node, time_matrix, reward_matrix, NUM_NODES,MAX_DURATION,MIN_DURATION):\n",
    "    \"\"\"\n",
    "    Generates a route using the learned policy (greedy selection),\n",
    "    preventing revisits to intermediate nodes.\n",
    "    If max_steps is reached, attempts forced return if valid.\n",
    "    Validates final duration window.\n",
    "    \"\"\"\n",
    "    max_steps=2*NUM_NODES  # Allow up to twice the number of nodes in steps\n",
    "    agent.epsilon = 0\n",
    "    agent.policy_net.eval()\n",
    "    current_node = start_node\n",
    "    time_elapsed = 0.0\n",
    "    state = np.array([current_node, time_elapsed / MAX_DURATION], dtype=np.float32)\n",
    "    route = [start_node]\n",
    "    visited_intermediate_nodes = set() # Keep track of nodes visited *other than* start_node\n",
    "    total_reward = 0.0\n",
    "    returned_home = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step in range(max_steps):\n",
    "            # --- Action Selection ---\n",
    "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(agent.device)\n",
    "            q_values = agent.policy_net(state_tensor)\n",
    "            q_values_numpy = q_values.cpu().data.numpy()[0]\n",
    "\n",
    "            # --- Masking Invalid Actions ---\n",
    "            # 1. Don't stay in the same node\n",
    "            q_values_numpy[current_node] = -np.inf\n",
    "\n",
    "            # 2. Don't visit intermediate nodes already visited\n",
    "            for visited_node_idx in visited_intermediate_nodes:\n",
    "                 if 0 <= visited_node_idx < len(q_values_numpy): # Bounds check\n",
    "                      q_values_numpy[visited_node_idx] = -np.inf\n",
    "\n",
    "            # --- Choose Best Valid Action ---\n",
    "            next_node = np.argmax(q_values_numpy)\n",
    "\n",
    "            # Check if any valid action exists\n",
    "            if q_values_numpy[next_node] == -np.inf:\n",
    "                 # No valid moves possible (maybe all unvisited nodes violate time or Q-values are terrible)\n",
    "                 # Try forcing return home immediately if possible\n",
    "                 # print(f\"DRL: Stuck at node {current_node}. No valid non-visited moves. Trying return home.\")\n",
    "                 if current_node != start_node:\n",
    "                     return_time = time_matrix[current_node][start_node]\n",
    "                     if time_elapsed + return_time <= MAX_DURATION + 1e-6:\n",
    "                         next_node = start_node # Override choice to return home\n",
    "                         # print(\"DRL: Forcing return home as only option.\")\n",
    "                     else:\n",
    "                        # print(f\"DRL Error: Stuck at node {current_node}. Cannot return home within duration.\")\n",
    "                        returned_home = False\n",
    "                        break # Cannot proceed\n",
    "                 else: # Stuck at start node? Should not happen if mask works.\n",
    "                    returned_home = False\n",
    "                    break\n",
    "\n",
    "\n",
    "            # --- Simulate Step ---\n",
    "            step_time = time_matrix[current_node][next_node]\n",
    "            step_reward = reward_matrix[current_node][next_node]\n",
    "\n",
    "            # --- Check immediate time violation (should be less likely now with stuck check) ---\n",
    "            if time_elapsed + step_time > MAX_DURATION + 1e-6 and next_node != start_node:\n",
    "                 # print(f\"DRL: Next step to {next_node} violates MAX_DURATION. Stopping.\")\n",
    "                 returned_home = False\n",
    "                 break\n",
    "\n",
    "            # --- Update State ---\n",
    "            time_elapsed += step_time\n",
    "            total_reward += step_reward\n",
    "            current_node = next_node\n",
    "            route.append(current_node)\n",
    "            # Add to visited set *only if* it's not the start node\n",
    "            if current_node != start_node:\n",
    "                visited_intermediate_nodes.add(current_node)\n",
    "\n",
    "            state = np.array([current_node, min(time_elapsed, MAX_DURATION) / MAX_DURATION], dtype=np.float32)\n",
    "\n",
    "            # --- Check for Natural Return ---\n",
    "            if current_node == start_node:\n",
    "                returned_home = True\n",
    "                break\n",
    "\n",
    "        # --- End of Step Loop ---\n",
    "\n",
    "        # --- Handle Forced Return if max_steps reached ---\n",
    "        # (This logic might be less necessary now but keep as fallback)\n",
    "        if not returned_home and current_node != start_node:\n",
    "            # print(f\"DRL: Max steps reached, attempting forced return from {current_node} to {start_node}\")\n",
    "            return_time = time_matrix[current_node][start_node]\n",
    "            return_reward = reward_matrix[current_node][start_node]\n",
    "            if time_elapsed + return_time <= MAX_DURATION + 1e-6:\n",
    "                time_elapsed += return_time\n",
    "                total_reward += return_reward\n",
    "                current_node = start_node\n",
    "                route.append(start_node)\n",
    "                returned_home = True\n",
    "            # else: # Forced return violates time\n",
    "                # returned_home remains False\n",
    "\n",
    "    # --- Final Validation ---\n",
    "    agent.policy_net.train()\n",
    "\n",
    "    is_cycle = returned_home and route[0] == start_node and route[-1] == start_node and len(route)>1\n",
    "\n",
    "    if not is_cycle:\n",
    "        return None, -np.inf, np.inf # Failed route\n",
    "\n",
    "    is_valid_duration = MIN_DURATION <= time_elapsed <= MAX_DURATION\n",
    "\n",
    "    # Check for duplicate intermediate nodes (should be prevented by logic above)\n",
    "    intermediate_nodes = route[1:-1]\n",
    "    has_duplicates = len(intermediate_nodes) != len(set(intermediate_nodes))\n",
    "    if has_duplicates:\n",
    "         print(f\"Warning: DRL route {route} has duplicate intermediate nodes despite masking!\")\n",
    "         # Treat as invalid? Or just note it. Let's return it but validity check below will fail if needed.\n",
    "\n",
    "    if is_valid_duration and not has_duplicates:\n",
    "        return route, total_reward, time_elapsed # Valid cycle found\n",
    "    else:\n",
    "        # Cycle formed, but duration or node visit is invalid\n",
    "        return route, total_reward, time_elapsed # Return invalid route details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210d9d0",
   "metadata": {},
   "source": [
    "## Part 3: MIP Formulation and Solution (using PuLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "83f9fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_mip(start_node, time_m, reward_m, min_d, max_d, num_n):\n",
    "    \"\"\"Solves the VRP variant using MIP for a given start node.\"\"\"\n",
    "    nodes = list(range(num_n))\n",
    "    other_nodes = [n for n in nodes if n != start_node]\n",
    "\n",
    "    # Create the model\n",
    "    prob = pulp.LpProblem(f\"VRP_Cycle_{start_node}\", pulp.LpMaximize)\n",
    "\n",
    "    # Decision Variables\n",
    "    x = pulp.LpVariable.dicts(\"Route\", (nodes, nodes), 0, 1, pulp.LpBinary)\n",
    "    u = pulp.LpVariable.dicts(\"MTZ\", nodes, 1, num_n - 1, pulp.LpContinuous)\n",
    "\n",
    "    # Objective Function\n",
    "    prob += pulp.lpSum(reward_m[i][j] * x[i][j] for i in nodes for j in nodes if i != j)\n",
    "\n",
    "    # Constraints\n",
    "    # 1. Degree Constraints\n",
    "    for k in nodes:\n",
    "        prob += pulp.lpSum(x[k][j] for j in nodes if k != j) == pulp.lpSum(x[j][k] for j in nodes if k != j)\n",
    "        if k == start_node:\n",
    "            prob += pulp.lpSum(x[start_node][j] for j in nodes if j != start_node) == 1\n",
    "            prob += pulp.lpSum(x[j][start_node] for j in nodes if j != start_node) == 1\n",
    "        else:\n",
    "             prob += pulp.lpSum(x[j][k] for j in nodes if j != k) <= 1\n",
    "\n",
    "    # 2. Duration Constraints\n",
    "    total_time = pulp.lpSum(time_m[i][j] * x[i][j] for i in nodes for j in nodes if i != j)\n",
    "    prob += total_time >= min_d\n",
    "    prob += total_time <= max_d\n",
    "\n",
    "    # 3. Subtour Elimination (MTZ)\n",
    "    for i in other_nodes:\n",
    "        prob += u[i] >= 1\n",
    "        for j in other_nodes:\n",
    "            if i != j:\n",
    "                 prob += u[i] - u[j] + 1 <= (num_n - 1) * (1 - x[i][j])\n",
    "\n",
    "    # Solve the problem\n",
    "    solver = pulp.PULP_CBC_CMD(msg=0)\n",
    "    prob.solve(solver)\n",
    "\n",
    "    # Extract results\n",
    "    status = pulp.LpStatus[prob.status]\n",
    "    route = None\n",
    "    total_reward = -np.inf\n",
    "    total_duration = np.inf\n",
    "\n",
    "    if status == 'Optimal':\n",
    "        total_reward = pulp.value(prob.objective)\n",
    "        total_duration = pulp.value(total_time)\n",
    "\n",
    "        # --- Modified Route Reconstruction ---\n",
    "        try: # Add a try-except block for safety during reconstruction\n",
    "            current_node = start_node\n",
    "            route = [start_node]\n",
    "            visited_count = 0 # Safety counter\n",
    "\n",
    "            while visited_count <= num_n: # Limit search depth\n",
    "                found_next = False\n",
    "                for j in nodes:\n",
    "                    # Check if arc variable exists, is not None, and is selected (> 0.99)\n",
    "                    # Also ensure j is not the current node\n",
    "                    if j != current_node and \\\n",
    "                       x[current_node][j] is not None and \\\n",
    "                       x[current_node][j].varValue is not None and \\\n",
    "                       x[current_node][j].varValue > 0.99:\n",
    "\n",
    "                        route.append(j)\n",
    "                        current_node = j\n",
    "                        found_next = True\n",
    "                        break # Move to the next node in the path\n",
    "\n",
    "                visited_count += 1\n",
    "\n",
    "                if current_node == start_node: # Successfully completed the cycle\n",
    "                    break\n",
    "                if not found_next: # Dead end found during reconstruction\n",
    "                    # print(f\"MIP Route Reconstruction Error: Dead end at node {current_node} for start {start_node}.\")\n",
    "                    route = None # Invalid route\n",
    "                    break\n",
    "                if visited_count > num_n: # Avoid infinite loops / too many steps\n",
    "                    # print(f\"MIP Route Reconstruction Error: Route too long for start {start_node}. Path: {route}\")\n",
    "                    route = None # Invalid route\n",
    "                    break\n",
    "\n",
    "            # Final validation of reconstructed route\n",
    "            if route is None or route[0] != start_node or route[-1] != start_node:\n",
    "                 # print(f\"MIP Route Reconstruction resulted in invalid path for start {start_node}. Route: {route}\")\n",
    "                 route = None\n",
    "                 # If route is invalid, reset reward/duration derived from MIP objective\n",
    "                 total_reward = -np.inf\n",
    "                 total_duration = np.inf\n",
    "                 status = 'Error_In_Route' # Update status to reflect this\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception during MIP route reconstruction for start {start_node}: {e}\")\n",
    "            route = None\n",
    "            total_reward = -np.inf\n",
    "            total_duration = np.inf\n",
    "            status = 'Error_Exception'\n",
    "        # --- End of Modified Route Reconstruction ---\n",
    "\n",
    "    # Ensure reward/duration are consistent if route is None\n",
    "    if route is None:\n",
    "         total_reward = -np.inf\n",
    "         total_duration = np.inf\n",
    "         # Update status if it was 'Optimal' but route failed\n",
    "         if status == 'Optimal': status = 'Optimal_Route_Fail'\n",
    "\n",
    "\n",
    "    return status, route, total_reward, total_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccb79d",
   "metadata": {},
   "source": [
    "## Part 4: Simple Greedy Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b7403663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_heuristic(start_node, time_m, reward_m, min_d, max_d, num_n):\n",
    "    \"\"\"\n",
    "    Solves using a simple greedy heuristic:\n",
    "    1. Always move to highest reward available node\n",
    "    2. Return to start node when no more valid moves\n",
    "    \"\"\"\n",
    "    current_node = start_node\n",
    "    time_elapsed = 0.0\n",
    "    total_reward = 0.0\n",
    "    route = [start_node]\n",
    "    visited = {start_node}\n",
    "    return_threshold = 0.85 * max_d\n",
    "\n",
    "    while True:  # Continue until we break\n",
    "        # Find next highest reward move\n",
    "        best_reward = -np.inf\n",
    "        best_next_node = None\n",
    "        \n",
    "        for next_node in range(num_n):\n",
    "            if next_node != current_node and next_node not in visited:\n",
    "                step_time = time_m[current_node][next_node]\n",
    "                return_time = time_m[next_node][start_node]  # Time to get back home\n",
    "                step_reward = reward_m[current_node][next_node]\n",
    "                \n",
    "                # Check if we can make this move and still get back home\n",
    "                total_future_time = time_elapsed + step_time + return_time\n",
    "                if total_future_time <= max_d:\n",
    "                    if step_reward > best_reward:\n",
    "                        best_reward = step_reward\n",
    "                        best_next_node = next_node\n",
    "\n",
    "        if best_next_node is not None:\n",
    "            # Make the move to the highest reward node\n",
    "            time_elapsed += time_m[current_node][best_next_node]\n",
    "            total_reward += reward_m[current_node][best_next_node]\n",
    "            current_node = best_next_node\n",
    "            route.append(current_node)\n",
    "            visited.add(current_node)\n",
    "        else:\n",
    "            # No more valid moves, return home\n",
    "            return_time = time_m[current_node][start_node]\n",
    "            if current_node != start_node:  # Only if we're not already home\n",
    "                time_elapsed += return_time\n",
    "                total_reward += reward_m[current_node][start_node]\n",
    "                route.append(start_node)\n",
    "            break\n",
    "        # If we've reached the time threshold, try to return home\n",
    "        if time_elapsed >= return_threshold:\n",
    "            return_time = time_m[current_node][start_node]\n",
    "            time_elapsed += return_time\n",
    "            total_reward += reward_m[current_node][start_node]\n",
    "            route.append(start_node)\n",
    "            break\n",
    "    # Final validation\n",
    "    is_valid = False\n",
    "    status = \"Infeasible\"\n",
    "    \n",
    "    if route[-1] == start_node and len(route) > 1:\n",
    "        if min_d <= time_elapsed <= max_d:\n",
    "            status = \"Optimal\"\n",
    "            is_valid = True\n",
    "\n",
    "    return status, route, total_reward, time_elapsed, is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600630e5",
   "metadata": {},
   "source": [
    "## Part 4.5: Obtain Upper Bound Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "35465cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_lp_relaxation(start_node, time_m, reward_m, min_d, max_d, num_n):\n",
    "    \"\"\"Solves LP relaxation of the VRP variant for upper bound.\"\"\"\n",
    "    nodes = list(range(num_n))\n",
    "    other_nodes = [n for n in nodes if n != start_node]\n",
    "\n",
    "    # Create LP model\n",
    "    lp_prob = pulp.LpProblem(f\"VRP_LP_Relaxation_{start_node}\", pulp.LpMaximize)\n",
    "    \n",
    "    # Decision Variables (continuous between 0 and 1)\n",
    "    x = pulp.LpVariable.dicts(\"Route\", (nodes, nodes), 0, 1, pulp.LpContinuous)\n",
    "    u = pulp.LpVariable.dicts(\"MTZ\", nodes, 1, num_n - 1, pulp.LpContinuous)\n",
    "\n",
    "    # Same objective and constraints as MIP\n",
    "    lp_prob += pulp.lpSum(reward_m[i][j] * x[i][j] for i in nodes for j in nodes if i != j)\n",
    "\n",
    "    for k in nodes:\n",
    "        lp_prob += pulp.lpSum(x[k][j] for j in nodes if k != j) == pulp.lpSum(x[j][k] for j in nodes if k != j)\n",
    "        if k == start_node:\n",
    "            lp_prob += pulp.lpSum(x[start_node][j] for j in nodes if j != start_node) == 1\n",
    "            lp_prob += pulp.lpSum(x[j][start_node] for j in nodes if j != start_node) == 1\n",
    "        else:\n",
    "            lp_prob += pulp.lpSum(x[j][k] for j in nodes if j != k) <= 1\n",
    "\n",
    "    total_time = pulp.lpSum(time_m[i][j] * x[i][j] for i in nodes for j in nodes if i != j)\n",
    "    lp_prob += total_time >= min_d\n",
    "    lp_prob += total_time <= max_d\n",
    "\n",
    "    # Solve LP\n",
    "    solver = pulp.PULP_CBC_CMD(msg=0)\n",
    "    lp_prob.solve(solver)\n",
    "\n",
    "    status = pulp.LpStatus[lp_prob.status]\n",
    "    upper_bound = pulp.value(lp_prob.objective) if status == 'Optimal' else np.inf\n",
    "\n",
    "    return status, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "c31c2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_regret2_heuristic(start_node, time_m, reward_m, min_d, max_d, num_n):\n",
    "    \"\"\"\n",
    "    Regret-2 heuristic: At each step, select the node where the difference between the best and second-best reward/time ratio is largest.\n",
    "    \"\"\"\n",
    "    current_node = start_node\n",
    "    time_elapsed = 0.0\n",
    "    total_reward = 0.0\n",
    "    route = [start_node]\n",
    "    visited = {start_node}\n",
    "    while True:\n",
    "        candidates = []\n",
    "        for next_node in range(num_n):\n",
    "            if next_node != current_node and next_node not in visited:\n",
    "                step_time = time_m[current_node][next_node]\n",
    "                return_time = time_m[next_node][start_node]\n",
    "                total_future_time = time_elapsed + step_time + return_time\n",
    "                if total_future_time <= max_d:\n",
    "                    # Calculate reward/time ratio for all possible next steps from this candidate\n",
    "                    ratios = []\n",
    "                    for future_node in range(num_n):\n",
    "                        if future_node != next_node and future_node not in visited:\n",
    "                            future_time = time_m[next_node][future_node]\n",
    "                            future_reward = reward_m[next_node][future_node]\n",
    "                            if future_time > 0:\n",
    "                                ratios.append(future_reward / future_time)\n",
    "                    ratios = sorted(ratios, reverse=True)\n",
    "                    best_ratio = reward_m[current_node][next_node] / step_time if step_time > 0 else 0\n",
    "                    second_best = ratios[0] if ratios else 0\n",
    "                    regret = best_ratio - second_best\n",
    "                    candidates.append((regret, next_node, step_time, reward_m[current_node][next_node]))\n",
    "        if candidates:\n",
    "            # Pick node with highest regret\n",
    "            candidates.sort(reverse=True)\n",
    "            _, best_next_node, step_time, step_reward = candidates[0]\n",
    "            time_elapsed += step_time\n",
    "            total_reward += step_reward\n",
    "            current_node = best_next_node\n",
    "            route.append(current_node)\n",
    "            visited.add(current_node)\n",
    "        else:\n",
    "            # Return home\n",
    "            if current_node != start_node:\n",
    "                time_elapsed += time_m[current_node][start_node]\n",
    "                total_reward += reward_m[current_node][start_node]\n",
    "                route.append(start_node)\n",
    "            break\n",
    "    is_valid = route[-1] == start_node and min_d <= time_elapsed <= max_d\n",
    "    status = \"Optimal\" if is_valid else \"Infeasible\"\n",
    "    return status, route, total_reward, time_elapsed, is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6f7d3",
   "metadata": {},
   "source": [
    "## Part 5: Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "88102da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Solvers for Each Start Node ---\n",
      "Solving for Start Node: 0\n",
      "[0, np.int64(2), np.int64(3), np.int64(1), np.int64(4), np.int64(5), np.int64(0)]\n",
      "Solving for Start Node: 1\n",
      "[1, np.int64(2), np.int64(3), np.int64(1)]\n",
      "Solving for Start Node: 2\n",
      "[2, np.int64(3), np.int64(1), np.int64(2)]\n",
      "Solving for Start Node: 3\n",
      "[3, np.int64(1), np.int64(2), np.int64(0), np.int64(3)]\n",
      "Solving for Start Node: 4\n",
      "[4, np.int64(1), np.int64(2), np.int64(0), np.int64(4)]\n",
      "Solving for Start Node: 5\n",
      "[5, np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5)]\n",
      "Solving for Start Node: 6\n",
      "[6, np.int64(2), np.int64(1), np.int64(3), np.int64(4), np.int64(5), np.int64(0), np.int64(9), np.int64(7), np.int64(8), np.int64(6)]\n",
      "Solving for Start Node: 7\n",
      "[7, np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(9), np.int64(7)]\n",
      "Solving for Start Node: 8\n",
      "[8, np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(0), np.int64(9), np.int64(7), np.int64(8)]\n",
      "Solving for Start Node: 9\n",
      "[9, np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(9)]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "results = []\n",
    "mip_times = []\n",
    "heuristic_times = []\n",
    "drl_inference_times = []\n",
    "heuristic2_times = []\n",
    "lp_times = []\n",
    "\n",
    "print(\"\\n--- Running Solvers for Each Start Node ---\")\n",
    "\n",
    "for s_node in range(NUM_NODES):\n",
    "    print(f\"Solving for Start Node: {s_node}\")\n",
    "    result_row = {'Start Node': s_node}\n",
    "\n",
    "    # First solve LP relaxation\n",
    "    t0 = time.time()\n",
    "    lp_status, lp_bound = solve_lp_relaxation(s_node, time_matrix, reward_matrix, MIN_DURATION, MAX_DURATION, NUM_NODES)\n",
    "    lp_times.append(time.time() - t0)\n",
    "    result_row['LP Status'] = lp_status\n",
    "    result_row['LP Upper Bound'] = lp_bound\n",
    "    \n",
    "    # Solve with DRL\n",
    "    t0 = time.time()\n",
    "    drl_route, drl_reward, drl_duration = generate_optimal_route_pytorch(drl_agent, s_node, time_matrix, reward_matrix,NUM_NODES,MAX_DURATION,MIN_DURATION)\n",
    "    drl_inference_times.append(time.time() - t0)\n",
    "    result_row['DRL Route'] = drl_route\n",
    "    result_row['DRL Reward'] = drl_reward if drl_route else -np.inf\n",
    "    print(drl_route)\n",
    "    result_row['DRL Duration'] = drl_duration if drl_route else np.inf\n",
    "    result_row['DRL Valid'] = drl_route is not None and drl_route[0] == drl_route[-1]\n",
    "\n",
    "    # Solve with MIP\n",
    "    t0 = time.time()\n",
    "    # Use original (non-penalized) reward matrix for MIP objective\n",
    "    mip_status, mip_route, mip_reward, mip_duration = solve_mip(s_node, time_matrix, reward_matrix, MIN_DURATION, MAX_DURATION, NUM_NODES)\n",
    "    mip_times.append(time.time() - t0)\n",
    "    result_row['MIP Status'] = mip_status\n",
    "    result_row['MIP Route'] = mip_route\n",
    "    result_row['MIP Reward'] = mip_reward if mip_status == 'Optimal' else -np.inf\n",
    "    result_row['MIP Duration'] = mip_duration if mip_status == 'Optimal' else np.inf\n",
    "    result_row['MIP Valid'] = mip_status == 'Optimal' and mip_route is not None\n",
    "\n",
    "    # Solve with Heuristic\n",
    "    t0 = time.time()\n",
    "    # Use original reward matrix for heuristic evaluation\n",
    "    heu_status, heu_route, heu_reward, heu_duration, heu_valid = solve_heuristic(s_node, time_matrix, reward_matrix, MIN_DURATION, MAX_DURATION, NUM_NODES)\n",
    "    heuristic_times.append(time.time() - t0)\n",
    "    result_row['Heuristic Route'] = heu_route\n",
    "    result_row['Heuristic Reward'] = heu_reward if heu_valid else (heu_reward if heu_route else -np.inf) # Show reward even if duration invalid\n",
    "    result_row['Heuristic Duration'] = heu_duration if heu_route else np.inf\n",
    "    result_row['Heuristic Valid'] = heu_valid\n",
    "\n",
    "    t0 = time.time()\n",
    "    # Use original reward matrix for heuristic evaluation\n",
    "    reg_status, reg_route, reg_reward, reg_duration, reg_valid = solve_regret2_heuristic(s_node, time_matrix, reward_matrix, MIN_DURATION, MAX_DURATION, NUM_NODES)\n",
    "    heuristic2_times.append(time.time() - t0)\n",
    "    result_row['Regret2 Route'] = reg_route\n",
    "    result_row['Regret2 Reward'] = reg_reward if reg_valid else (reg_reward if reg_route else -np.inf)\n",
    "    result_row['Regret2 Duration'] = reg_duration if reg_route else np.inf\n",
    "    result_row['Regret2 Valid'] = reg_valid\n",
    "    # Add gap calculations as for other heuristics\n",
    "    \n",
    "    # Calculate Optimality Gaps (relative to MIP if MIP is optimal)\n",
    "    mip_opt_reward = result_row['MIP Reward']\n",
    "    if result_row['MIP Valid']:\n",
    "        drl_gap = ((mip_opt_reward - result_row['DRL Reward']) / abs(mip_opt_reward)) * 100 if abs(mip_opt_reward) > 1e-6 and result_row['DRL Valid'] else float('nan')\n",
    "        heu_gap = ((mip_opt_reward - result_row['Heuristic Reward']) / abs(mip_opt_reward)) * 100 if abs(mip_opt_reward) > 1e-6 and result_row['Heuristic Valid'] else float('nan')\n",
    "        reg_gap = ((mip_opt_reward - result_row['Regret2 Reward']) / abs(mip_opt_reward)) * 100 if abs(mip_opt_reward) > 1e-6 and reg_valid else float('nan')\n",
    "    else:\n",
    "        drl_gap = float('nan')\n",
    "        heu_gap = float('nan')\n",
    "        reg_gap = float('nan')\n",
    "    # Add gap calculations relative to LP bound\n",
    "    if lp_status == 'Optimal':\n",
    "        mip_lp_gap = ((lp_bound - result_row['MIP Reward']) / abs(lp_bound)) * 100 if result_row['MIP Valid'] else float('nan')\n",
    "        drl_lp_gap = ((lp_bound - result_row['DRL Reward']) / abs(lp_bound)) * 100 if result_row['DRL Valid'] else float('nan')\n",
    "        heu_lp_gap = ((lp_bound - result_row['Heuristic Reward']) / abs(lp_bound)) * 100 if result_row['Heuristic Valid'] else float('nan')\n",
    "        reg_lp_gap = ((lp_bound - result_row['Regret2 Reward']) / abs(lp_bound)) * 100 if reg_valid else float('nan')\n",
    "    else:\n",
    "        mip_lp_gap = float('nan')\n",
    "        drl_lp_gap = float('nan')\n",
    "        heu_lp_gap = float('nan')  \n",
    "        reg_lp_gap = float('nan')  \n",
    "    result_row['MIP-LP Gap (%)'] = mip_lp_gap\n",
    "    result_row['DRL-LP Gap (%)'] = drl_lp_gap\n",
    "    result_row['Heuristic-LP Gap (%)'] = heu_lp_gap\n",
    "    result_row['Regret2-LP Gap (%)'] = reg_lp_gap\n",
    "    result_row['DRL Gap (%)'] = drl_gap\n",
    "    result_row['Heuristic Gap (%)'] = heu_gap\n",
    "    result_row['Regret2 Gap (%)'] = reg_gap\n",
    "\n",
    "    results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802be5e4",
   "metadata": {},
   "source": [
    "### Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e75c4614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparison Summary ---\n",
      "   Start Node  LP Upper Bound MIP Status  MIP Reward  MIP Valid  \\\n",
      "0           0          2304.8    Optimal      1449.0       True   \n",
      "1           1          2304.8    Optimal      1449.0       True   \n",
      "2           2          2304.8    Optimal      1449.0       True   \n",
      "3           3          2304.8    Optimal      1449.0       True   \n",
      "4           4          2304.8    Optimal      1449.0       True   \n",
      "5           5          2304.8    Optimal      1449.0       True   \n",
      "6           6          2304.8    Optimal      1449.0       True   \n",
      "7           7          2304.8    Optimal      1449.0       True   \n",
      "8           8          2304.8    Optimal      1449.0       True   \n",
      "9           9          2304.8    Optimal      1449.0       True   \n",
      "\n",
      "   MIP-LP Gap (%)  DRL Reward  DRL Valid  DRL-LP Gap (%)  Heuristic Reward  \\\n",
      "0            37.1      1483.0       True            35.7             813.0   \n",
      "1            37.1      1323.0       True            42.6            1313.0   \n",
      "2            37.1      1323.0       True            42.6            1091.0   \n",
      "3            37.1      1195.0       True            48.2             857.0   \n",
      "4            37.1      1055.0       True            54.2             924.0   \n",
      "5            37.1      1481.0       True            35.7             946.0   \n",
      "6            37.1       815.0       True            64.6             836.0   \n",
      "7            37.1      1252.0       True            45.7            1091.0   \n",
      "8            37.1       872.0       True            62.2            1111.0   \n",
      "9            37.1      1251.0       True            45.7            1240.0   \n",
      "\n",
      "   Heuristic Valid  Heuristic-LP Gap (%)  \n",
      "0             True                  64.7  \n",
      "1             True                  43.0  \n",
      "2             True                  52.7  \n",
      "3             True                  62.8  \n",
      "4             True                  59.9  \n",
      "5             True                  59.0  \n",
      "6             True                  63.7  \n",
      "7             True                  52.7  \n",
      "8             True                  51.8  \n",
      "9             True                  46.2  \n",
      "\n",
      "Example Routes for Start Node 0:\n",
      "MIP: [0, 1, 2, 3, 4, 5, 7, 8, 6, 9, 0]\n",
      "DRL: [0, np.int64(2), np.int64(3), np.int64(1), np.int64(4), np.int64(5), np.int64(0)]\n",
      "Heuristic: [0, 7, 9, 8, 6, 2, 3, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "# Format gaps for display\n",
    "results_df['DRL Gap (%)'] = results_df['DRL Gap (%)'].map('{:.1f}'.format, na_action='ignore')\n",
    "results_df['Heuristic Gap (%)'] = results_df['Heuristic Gap (%)'].map('{:.1f}'.format, na_action='ignore')\n",
    "\n",
    "# Select and reorder columns for better readability\n",
    "summary_cols = [\n",
    "    'Start Node',\n",
    "    'LP Upper Bound',\n",
    "    'MIP Status', 'MIP Reward', 'MIP Valid', 'MIP-LP Gap (%)',\n",
    "    'DRL Reward', 'DRL Valid', 'DRL-LP Gap (%)',\n",
    "    'Heuristic Reward', 'Heuristic Valid', 'Heuristic-LP Gap (%)',\n",
    "]\n",
    "print(\"\\n--- Comparison Summary ---\")\n",
    "print(results_df[summary_cols].round(1)) # Round rewards/durations\n",
    "\n",
    "# Display routes for a specific node if needed\n",
    "print(\"\\nExample Routes for Start Node 0:\")\n",
    "print(\"MIP:\", results_df.loc[0, 'MIP Route'])\n",
    "print(\"DRL:\", results_df.loc[0, 'DRL Route'])\n",
    "print(\"Heuristic:\", results_df.loc[0, 'Heuristic Route'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6595a30",
   "metadata": {},
   "source": [
    "### Aggregate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "1603e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Route Reward: 1483.0, Time: 33.2\n"
     ]
    }
   ],
   "source": [
    "reward = reward_matrix[0][2] + reward_matrix[2][3] + reward_matrix[3][1] + reward_matrix[1][4] + reward_matrix[4][5] + reward_matrix[5][0]\n",
    "time = time_matrix[0][2] + time_matrix[2][3] + time_matrix[3][1] + time_matrix[1][4] + time_matrix[4][5] + time_matrix[5][0]\n",
    "print(f\"\\nExample Route Reward: {reward}, Time: {time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "41f9c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Aggregate Performance ---\n",
      "\n",
      "Average Values:\n",
      "  LP Upper Bound: 2304.8\n",
      "  MIP Reward:     1449.0\n",
      "  DRL Reward:     1205.0\n",
      "  Heuristic:      1022.2\n",
      "  Regret2:        324.8\n",
      "\n",
      "Average Gap to LP Upper Bound:\n",
      "  MIP:       37.1%\n",
      "  DRL:       47.7%\n",
      "  Heuristic: 55.6%\n",
      "  Regret2:   85.9%\n",
      "\n",
      "--- Computation Times ---\n",
      "LP Relaxation Time:     0.0508 seconds per instance\n",
      "MIP Solve Time:         2.1929 seconds per instance\n",
      "DRL Training:           1196.11 seconds (Total)\n",
      "DRL Inference Time:     0.0098 seconds per instance\n",
      "Heuristic Time:         0.0012 seconds per instance\n",
      "Regret-2 Heuristic Time: 0.0040 seconds per instance\n"
     ]
    }
   ],
   "source": [
    "# Update the aggregate metrics section\n",
    "print(\"\\n--- Aggregate Performance ---\")\n",
    "\n",
    "# Success Rates (finding a valid route)\n",
    "mip_success = results_df['MIP Valid'].mean() * 100\n",
    "drl_success = results_df['DRL Valid'].mean() * 100\n",
    "heu_success = results_df['Heuristic Valid'].mean() * 100\n",
    "reg_success = results_df['Regret2 Valid'].mean() * 100\n",
    "#print(f\"Success Rate (Valid Route Found):\")\n",
    "#print(f\"  MIP:       {mip_success:.1f}%\")\n",
    "#print(f\"  DRL:       {drl_success:.1f}%\")\n",
    "#print(f\"  Heuristic: {heu_success:.1f}%\")\n",
    "#print(f\"  Regret2:   {reg_success:.1f}%\")\n",
    "\n",
    "# Average Rewards and Gaps\n",
    "avg_lp_bound = results_df['LP Upper Bound'].mean()\n",
    "avg_mip_reward = results_df.loc[results_df['MIP Valid'], 'MIP Reward'].mean()\n",
    "avg_drl_reward = results_df.loc[results_df['DRL Valid'], 'DRL Reward'].mean()\n",
    "avg_heu_reward = results_df.loc[results_df['Heuristic Valid'], 'Heuristic Reward'].mean()\n",
    "avg_regret2_reward = results_df.loc[results_df['Regret2 Valid'], 'Regret2 Reward'].mean()\n",
    "\n",
    "print(f\"\\nAverage Values:\")\n",
    "print(f\"  LP Upper Bound: {avg_lp_bound:.1f}\")\n",
    "print(f\"  MIP Reward:     {avg_mip_reward:.1f}\")\n",
    "print(f\"  DRL Reward:     {avg_drl_reward:.1f}\")\n",
    "print(f\"  Heuristic:      {avg_heu_reward:.1f}\")\n",
    "print(f\"  Regret2:        {avg_regret2_reward:.1f}\")\n",
    "\n",
    "# Average LP Gaps\n",
    "avg_mip_lp_gap = results_df['MIP-LP Gap (%)'].mean()\n",
    "avg_drl_lp_gap = results_df['DRL-LP Gap (%)'].mean()\n",
    "avg_heu_lp_gap = results_df['Heuristic-LP Gap (%)'].mean()\n",
    "avg_regret2_lp_gap = results_df['Regret2-LP Gap (%)'].mean()\n",
    "\n",
    "print(f\"\\nAverage Gap to LP Upper Bound:\")\n",
    "print(f\"  MIP:       {avg_mip_lp_gap:.1f}%\")\n",
    "print(f\"  DRL:       {avg_drl_lp_gap:.1f}%\")\n",
    "print(f\"  Heuristic: {avg_heu_lp_gap:.1f}%\")\n",
    "print(f\"  Regret2:   {avg_regret2_lp_gap:.1f}%\")\n",
    "\n",
    "# Average MIP Gaps\n",
    "# Convert string gaps to numeric, excluding NaN values\n",
    "#results_df['DRL Gap (%)'] = pd.to_numeric(results_df['DRL Gap (%)'], errors='coerce')\n",
    "#results_df['Heuristic Gap (%)'] = pd.to_numeric(results_df['Heuristic Gap (%)'], errors='coerce')\n",
    "#avg_drl_mip_gap = results_df['DRL Gap (%)'].mean()\n",
    "#avg_heu_mip_gap = results_df['Heuristic Gap (%)'].mean()\n",
    "#avg_regret2_mip_gap = results_df['Regret2 Gap (%)'].mean()\n",
    "\n",
    "#print(f\"\\nAverage Gap to MIP Solution:\")\n",
    "#print(f\"  DRL:       {avg_drl_mip_gap:.1f}%\")\n",
    "#print(f\"  Heuristic: {avg_heu_mip_gap:.1f}%\")\n",
    "#print(f\"  Regret2:   {avg_regret2_mip_gap:.1f}%\")\n",
    "\n",
    "# Computation Times\n",
    "print(\"\\n--- Computation Times ---\")\n",
    "print(f\"LP Relaxation Time:     {np.mean(lp_times):.4f} seconds per instance\")\n",
    "print(f\"MIP Solve Time:         {np.mean(mip_times):.4f} seconds per instance\")\n",
    "print(f\"DRL Training:           {drl_training_time:.2f} seconds (Total)\")\n",
    "print(f\"DRL Inference Time:     {np.mean(drl_inference_times):.4f} seconds per instance\")\n",
    "print(f\"Heuristic Time:         {np.mean(heuristic_times):.4f} seconds per instance\")\n",
    "print(f\"Regret-2 Heuristic Time: {np.mean(heuristic2_times):.4f} seconds per instance\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
