{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e300f916",
   "metadata": {},
   "source": [
    "# # VRP Variant Solver Comparison (8-Node Example)\n",
    "\n",
    "# We will compare three methods for solving a profit-maximizing, duration-constrained vehicle routing problem variant on an 8-node graph:\n",
    "# 1. Deep Reinforcement Learning (DRL) using DQN.\n",
    "# 2. Mixed-Integer Programming (MIP) for the optimal solution.\n",
    "# 3. A simple Greedy Heuristic (Best Reward/Time Ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1170ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical # For sampling actions\n",
    "import random\n",
    "from collections import deque, namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pulp \n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ee856",
   "metadata": {},
   "source": [
    "# # Define Constants (Adjusted for 8 Nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f7e36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set input dates\n",
    "date = \"_2024-12-09\"\n",
    "truck = \"VAN\"\n",
    "mpg = 6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d111816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name\n",
    "file_name1 = \"rate_q2_west_\"+truck+date+\".csv\"\n",
    "file_name2 = \"duration_west.csv\"\n",
    "file_name3 = \"prob_west_\"+truck+date+\".csv\"\n",
    "file_name4 = \"load_av_west_\"+truck+date+\".csv\"\n",
    "file_name5 = \"distance_west.csv\"\n",
    "file_name6 = \"diesel_west\"+date+\".csv\"\n",
    "file_name7 = \"labels_west.csv\"\n",
    "# Read the Excel file into a DataFrame\n",
    "rate_matrix = pd.read_csv(file_name1,header= None)\n",
    "time_matrix = pd.read_csv(file_name2,header = None)\n",
    "markov_matrix = pd.read_csv(file_name3,header=None)\n",
    "loads_matrix = pd.read_csv(file_name4,header=None)\n",
    "distance_matrix = pd.read_csv(file_name5,header=None)\n",
    "diesel_matrix = pd.read_csv(file_name6,header=None)\n",
    "hub_labels = pd.read_csv(file_name7,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371ccd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_matrix = rate_matrix * distance_matrix\n",
    "revenue_matrix[loads_matrix <= 1] = 0\n",
    "diesel_matrix = diesel_matrix / mpg\n",
    "var_cost_matrix = 1.2 * distance_matrix\n",
    "cost_matrix = distance_matrix * diesel_matrix\n",
    "cost_matrix = cost_matrix + 163\n",
    "cost_matrix = cost_matrix + var_cost_matrix\n",
    "reward_matrix = revenue_matrix - cost_matrix\n",
    "time_matrix *= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f8e466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NODES = 8\n",
    "ACTION_SPACE_SIZE = NUM_NODES\n",
    "\n",
    "# Problem Constraints (Keep the same duration limits for consistency)\n",
    "DURATION_LIMIT = 60.0\n",
    "DURATION_TOLERANCE = 0.20\n",
    "MIN_DURATION = DURATION_LIMIT * (1 - DURATION_TOLERANCE)\n",
    "MAX_DURATION = DURATION_LIMIT * (1 + DURATION_TOLERANCE)\n",
    "BIG_M_PENALTY = -1e9 # Large negative number for rewards\n",
    "\n",
    "# Use a fixed seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db19180f",
   "metadata": {},
   "source": [
    "# ### Generate Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebbb01f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating sample data for 8 nodes...\n",
      "\n",
      "Sample Time Matrix (hours):\n",
      "      0     1     2     3     4     5     6     7\n",
      "0   0.0   3.4   4.2   5.4   3.7   1.7  19.1  11.5\n",
      "1   3.4   0.0   5.1   8.1   6.1   2.6  19.0  10.9\n",
      "2   4.1   5.1   0.0   8.8   6.9   2.8  15.8   7.8\n",
      "3   5.4   8.0   8.8   0.0   4.1   6.3  23.8  16.1\n",
      "4   3.6   6.1   6.9   4.1   0.0   4.4  21.9  14.2\n",
      "5   1.7   2.6   2.8   6.4   4.4   0.0  17.7  10.1\n",
      "6  19.0  19.0  15.9  23.7  21.7  17.7   0.0   8.1\n",
      "7  11.4  11.0   7.9  16.1  14.1  10.1   8.0   0.0\n",
      "\n",
      "Sample Reward Matrix:\n",
      "       0      1      2      3      4      5      6      7\n",
      "0 -163.0   28.0   79.0  149.0   79.0  -68.0 -408.0 -519.0\n",
      "1  252.0 -163.0  188.0  400.0  316.0  204.0 -435.0 -518.0\n",
      "2  213.0  533.0 -163.0  429.0  327.0   20.0 -367.0 -411.0\n",
      "3  183.0  371.0  390.0 -163.0  119.0  238.0 -826.0 -623.0\n",
      "4  127.0  358.0  249.0  164.0 -163.0  211.0 -609.0 -521.0\n",
      "5   -5.0   -3.0   13.0  224.0  190.0 -163.0 -404.0 -491.0\n",
      "6 -276.0 -360.0 -327.0 -407.0 -391.0 -348.0 -163.0 -373.0\n",
      "7  272.0  323.0  193.0  215.0  220.0  232.0   31.0 -163.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Generating sample data for {NUM_NODES} nodes...\")\n",
    "time_matrix = time_matrix.iloc[:NUM_NODES, :NUM_NODES]\n",
    "reward_matrix = reward_matrix.iloc[:NUM_NODES, :NUM_NODES]\n",
    "# Round for clarity\n",
    "time_matrix = np.round(time_matrix, 1)\n",
    "reward_matrix = np.round(reward_matrix, 0)\n",
    "\n",
    "# Create DataFrames for easy viewing\n",
    "time_df = pd.DataFrame(time_matrix, index=range(NUM_NODES), columns=range(NUM_NODES))\n",
    "reward_df = pd.DataFrame(reward_matrix, index=range(NUM_NODES), columns=range(NUM_NODES))\n",
    "\n",
    "print(\"\\nSample Time Matrix (hours):\")\n",
    "print(time_df)\n",
    "print(\"\\nSample Reward Matrix:\")\n",
    "print(reward_df)\n",
    "\n",
    "# Apply Big M penalty to reward matrix diagonal (used by DRL and Heuristic)\n",
    "reward_matrix_penalized = reward_matrix.copy()\n",
    "reward_array = reward_matrix_penalized.to_numpy()\n",
    "np.fill_diagonal(reward_array, BIG_M_PENALTY)\n",
    "reward_matrix_penalized = pd.DataFrame(reward_array, index=reward_matrix_penalized.index, columns=reward_matrix_penalized.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b23b65",
   "metadata": {},
   "source": [
    "# **Data Description:**\n",
    "# * **Nodes:** 8 locations, indexed 0 through 7.\n",
    "# * **Time Matrix:** Shows the travel time in hours between any two nodes `i` and `j` (`time_matrix[i][j]`). Times are generally between 2 and 15 hours and are slightly asymmetric (travel `i` to `j` might take slightly different time than `j` to `i`). Diagonal is 0.\n",
    "# * **Reward Matrix:** Shows the reward (profit) gained by traveling between nodes `i` and `j` (`reward_matrix[i][j]`). Rewards range roughly from 50 to 500. There's a loose inverse correlation with time (shorter trips *tend* to have higher reward density) plus random noise. Diagonal is 0.\n",
    "#\n",
    "# **Goal Reminder:** For each starting node, find a route (cycle) that starts and ends at that node, maximizes total reward, and has a total duration around 60 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d228d8a",
   "metadata": {},
   "source": [
    "## Part 2: DRL Implementation and Training\n",
    "### DRL Hyperparameters and Agent Definition (Using PyTorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f17bfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# DRL Hyperparameters (Can potentially reduce episodes/steps for smaller problem)\n",
    "STATE_SIZE = 2 # (current_node_index, time_elapsed_normalized)\n",
    "LEARNING_RATE = 0.001\n",
    "GAMMA = 0.95 # Discount factor\n",
    "\n",
    "EPSILON_START = 1.0\n",
    "EPSILON_END = 0.05 # Can end higher for smaller problems\n",
    "EPSILON_DECAY_STEPS = 5000 # Decay faster for smaller problems?\n",
    "\n",
    "BUFFER_SIZE = 10000 # Smaller buffer might be okay\n",
    "BATCH_SIZE = 32 # Smaller batch size\n",
    "\n",
    "NUM_EPISODES = 3000 # Reduced episodes for 8 nodes\n",
    "MAX_STEPS_PER_EPISODE = 50 # Max steps per route attempt\n",
    "TARGET_UPDATE_FREQ = 50 # Update target net more frequently\n",
    "\n",
    "# Rewards / Penalties (Keep the same)\n",
    "RETURN_SUCCESS_BONUS = 100\n",
    "TIME_VIOLATION_PENALTY = -1000\n",
    "INCOMPLETE_PENALTY = -200\n",
    "\n",
    "# PyTorch Device Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff18d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from torch_geometric.nn import GATConv\n",
    "    from torch_geometric.data import Data\n",
    "    PYG_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PYG_AVAILABLE = False\n",
    "    print(\"Warning: PyTorch Geometric not found. GNN will be a simpler MLP placeholder.\")\n",
    "    # Fallback GNN definition or simplified version will be used.\n",
    "\n",
    "# (Constants NUM_NODES, MAX_DURATION, etc. are assumed to be defined from previous cells)\n",
    "NODE_INITIAL_EMBED_DIM = 32 # Dimension for initial nn.Embedding of nodes\n",
    "GNN_HIDDEN_DIM = 64\n",
    "GNN_EMBED_DIM = 64         # Output dimension of GNN for each node\n",
    "\n",
    "class GNNEncoder(nn.Module):\n",
    "    def __init__(self, num_nodes, node_initial_embed_dim, gnn_hidden_dim, gnn_embed_dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.initial_node_embeddings = nn.Embedding(num_nodes, node_initial_embed_dim)\n",
    "\n",
    "        if PYG_AVAILABLE:\n",
    "            self.conv1 = GATConv(node_initial_embed_dim, gnn_hidden_dim, heads=heads, dropout=0.1)\n",
    "            self.conv2 = GATConv(gnn_hidden_dim * heads, gnn_embed_dim, heads=1, concat=False, dropout=0.1)\n",
    "        else: # Fallback if PyG not available\n",
    "            self.fc1 = nn.Linear(node_initial_embed_dim, gnn_hidden_dim * heads)\n",
    "            self.fc2 = nn.Linear(gnn_hidden_dim * heads, gnn_embed_dim)\n",
    "\n",
    "\n",
    "    def forward(self, node_indices_tensor, edge_index_tensor=None):\n",
    "        # node_indices_tensor: torch.arange(0, self.num_nodes)\n",
    "        # edge_index_tensor: Graph connectivity [2, NumEdges]. For fully connected, all pairs.\n",
    "\n",
    "        x = self.initial_node_embeddings(node_indices_tensor) # [NUM_NODES, node_initial_embed_dim]\n",
    "\n",
    "        if PYG_AVAILABLE and edge_index_tensor is not None:\n",
    "            x = F.dropout(x, p=0.1, training=self.training)\n",
    "            x = F.elu(self.conv1(x, edge_index_tensor))\n",
    "            x = F.dropout(x, p=0.1, training=self.training)\n",
    "            x = self.conv2(x, edge_index_tensor) # Output: [NUM_NODES, GNN_EMBED_DIM]\n",
    "        else: # Fallback MLP\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Prepare edge_index for a fully connected graph (excluding self-loops)\n",
    "source_nodes = []\n",
    "target_nodes = []\n",
    "for i in range(NUM_NODES):\n",
    "    for j in range(NUM_NODES):\n",
    "        if i != j:\n",
    "            source_nodes.append(i)\n",
    "            target_nodes.append(j)\n",
    "edge_index = torch.tensor([source_nodes, target_nodes], dtype=torch.long).to(device)\n",
    "all_node_indices = torch.arange(0, NUM_NODES, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b40bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_HIDDEN_DIM = 128\n",
    "TIME_FEATURE_DIM = 1 # For normalized time_elapsed\n",
    "\n",
    "class ActorPolicyNetwork(nn.Module):\n",
    "    def __init__(self, gnn_embed_dim, time_feature_dim, lstm_hidden_dim, num_nodes, C=10.0): # C for tanh clipping\n",
    "        super().__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.gnn_embed_dim = gnn_embed_dim\n",
    "        self.lstm_hidden_dim = lstm_hidden_dim\n",
    "        self.C = C\n",
    "\n",
    "        # LSTM to encode current route context\n",
    "        # Input: GNN embedding of current_node + time_elapsed\n",
    "        self.lstm_input_dim = gnn_embed_dim + time_feature_dim\n",
    "        self.lstm = nn.LSTMCell(self.lstm_input_dim, lstm_hidden_dim) # LSTMCell for step-by-step\n",
    "\n",
    "        # Attention mechanism (Pointer style)\n",
    "        # Query: LSTM hidden state (h_t)\n",
    "        # Keys: Static GNN embeddings of all nodes\n",
    "        self.W_query = nn.Linear(lstm_hidden_dim, lstm_hidden_dim, bias=False) # For query\n",
    "        self.W_keys = nn.Linear(gnn_embed_dim, lstm_hidden_dim, bias=False)  # For keys (node_embeddings)\n",
    "        self.V_attention = nn.Linear(lstm_hidden_dim, 1, bias=False) # To get scores\n",
    "\n",
    "    def forward(self, current_node_gnn_embed, time_elapsed_norm,\n",
    "                static_node_embeddings, lstm_hidden_cell_state, # (h_prev, c_prev)\n",
    "                invalid_actions_mask):\n",
    "        # current_node_gnn_embed: [GNN_EMBED_DIM]\n",
    "        # time_elapsed_norm: scalar\n",
    "        # static_node_embeddings: [NUM_NODES, GNN_EMBED_DIM]\n",
    "        # lstm_hidden_cell_state: (h_prev [1, LSTM_HIDDEN_DIM], c_prev [1, LSTM_HIDDEN_DIM])\n",
    "        # invalid_actions_mask: boolean tensor of shape [NUM_NODES]\n",
    "        static_node_embeddings = static_node_embeddings.detach().clone()\n",
    "        time_feature = torch.tensor([time_elapsed_norm], dtype=current_node_gnn_embed.dtype,\n",
    "                            device=current_node_gnn_embed.device).detach()\n",
    "        lstm_input = torch.cat((current_node_gnn_embed, time_feature), dim=-1).unsqueeze(0) # [1, lstm_input_dim]\n",
    "\n",
    "        h_t, c_t = self.lstm(lstm_input, lstm_hidden_cell_state) # h_t, c_t shapes: [1, LSTM_HIDDEN_DIM]\n",
    "\n",
    "        # Attention\n",
    "        query_proj = self.W_query(h_t) # [1, LSTM_HIDDEN_DIM]\n",
    "        keys_proj = self.W_keys(static_node_embeddings) # [NUM_NODES, LSTM_HIDDEN_DIM]\n",
    "\n",
    "        # Expand query to match keys for broadcasting addition (or use broadcasting directly)\n",
    "        # Scores: V * tanh(query_proj + keys_proj)\n",
    "        # query_proj needs to be [1, LSTM_HIDDEN_DIM], keys_proj [NUM_NODES, LSTM_HIDDEN_DIM]\n",
    "        # Addition will broadcast query_proj over the first dimension of keys_proj\n",
    "        attention_scores = self.V_attention(torch.tanh(query_proj + keys_proj)).squeeze(-1) # [NUM_NODES]\n",
    "\n",
    "        # Apply clipping C * tanh (optional, from Kool et al. 2019)\n",
    "        # attention_scores = self.C * torch.tanh(attention_scores)\n",
    "\n",
    "        # Apply mask for invalid actions\n",
    "        attention_scores = attention_scores.clone()\n",
    "        attention_scores = attention_scores.masked_fill(invalid_actions_mask, -float('inf'))\n",
    "\n",
    "        action_probs = F.softmax(attention_scores, dim=-1) # [NUM_NODES]\n",
    "\n",
    "        return action_probs, (h_t, c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd1775ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q-Network Definition (Same as before)\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64) # Smaller network might suffice\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "# DQN Agent Definition (Same DQNAgent_PyTorch class as before)\n",
    "# Ensure the DQNAgent_PyTorch class definition from the previous response is included here\n",
    "class DQNAgent_PyTorch:\n",
    "    def __init__(self, state_size, action_size, learning_rate, gamma, buffer_size, batch_size, device):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)\n",
    "        self.gamma = gamma\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "\n",
    "        # Use the smaller QNetwork\n",
    "        self.policy_net = QNetwork(state_size, action_size).to(self.device)\n",
    "        self.target_net = QNetwork(state_size, action_size).to(self.device)\n",
    "        self.update_target_model()\n",
    "        self.target_net.eval()\n",
    "\n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=learning_rate)\n",
    "        self.loss_function = nn.MSELoss()\n",
    "        self.epsilon = EPSILON_START\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state, invalid_actions=None): # Added invalid_actions parameter\n",
    "        \"\"\"Selects an action using epsilon-greedy strategy, avoiding invalid actions.\"\"\"\n",
    "        if invalid_actions is None:\n",
    "            invalid_actions = set()\n",
    "\n",
    "        current_node_index = int(state[0]) # Assuming state[0] is node index\n",
    "\n",
    "        # Add current node itself to invalid actions for this step\n",
    "        current_step_invalid_actions = invalid_actions.union({current_node_index})\n",
    "\n",
    "        possible_actions = list(range(self.action_size))\n",
    "        valid_actions = [a for a in possible_actions if a not in current_step_invalid_actions]\n",
    "\n",
    "        # If no valid actions are possible (shouldn't normally happen unless trapped)\n",
    "        if not valid_actions:\n",
    "            # Fallback: maybe allow returning home if that's the only invalid action?\n",
    "            # Or just return a dummy action (e.g., 0) - the environment should handle this.\n",
    "            # Let's return current_node to signal being stuck, though env should handle.\n",
    "             # print(f\"Warning: No valid actions from node {current_node_index} with invalid set {current_step_invalid_actions}\")\n",
    "             return current_node_index # Return current node to signal being stuck\n",
    "\n",
    "        if random.random() <= self.epsilon:\n",
    "            # Explore: Choose randomly from valid actions\n",
    "            return random.choice(valid_actions)\n",
    "        else:\n",
    "            # Exploit: Choose the best action from Q-values among valid ones\n",
    "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(self.device)\n",
    "            self.policy_net.eval()\n",
    "            with torch.no_grad():\n",
    "                q_values = self.policy_net(state_tensor)\n",
    "            self.policy_net.train()\n",
    "\n",
    "            q_values_numpy = q_values.cpu().data.numpy()[0]\n",
    "\n",
    "            # Mask invalid actions by setting their Q-values to -infinity\n",
    "            for invalid_action in current_step_invalid_actions:\n",
    "                 if 0 <= invalid_action < self.action_size:\n",
    "                      q_values_numpy[invalid_action] = -np.inf\n",
    "\n",
    "            # Choose the best among the remaining valid actions\n",
    "            best_action = np.argmax(q_values_numpy)\n",
    "\n",
    "            # Sanity check if argmax still picked an invalid action (e.g., all are -inf)\n",
    "            if q_values_numpy[best_action] == -np.inf:\n",
    "                 # print(f\"Warning: All valid actions have -inf Q-value from node {current_node_index}. Choosing randomly from valid.\")\n",
    "                 # Fallback to random choice among valid if exploitation leads nowhere\n",
    "                 if valid_actions: # Ensure valid_actions is not empty\n",
    "                    return random.choice(valid_actions)\n",
    "                 else: # Truly stuck\n",
    "                    return current_node_index # Signal stuck\n",
    "\n",
    "            return best_action\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < self.batch_size:\n",
    "            return 0.0\n",
    "        minibatch = random.sample(self.memory, self.batch_size)\n",
    "        states = torch.from_numpy(np.vstack([e[0] for e in minibatch])).float().to(self.device)\n",
    "        actions = torch.from_numpy(np.vstack([e[1] for e in minibatch])).long().to(self.device)\n",
    "        rewards = torch.from_numpy(np.vstack([e[2] for e in minibatch])).float().to(self.device)\n",
    "        next_states = torch.from_numpy(np.vstack([e[3] for e in minibatch])).float().to(self.device)\n",
    "        dones = torch.from_numpy(np.vstack([e[4] for e in minibatch]).astype(np.uint8)).float().to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            target_q_next = self.target_net(next_states)\n",
    "            max_q_next = target_q_next.max(1)[0].unsqueeze(1)\n",
    "            target_q_values = rewards + (self.gamma * max_q_next * (1 - dones))\n",
    "\n",
    "        current_q_values = self.policy_net(states)\n",
    "        action_q_values = current_q_values.gather(1, actions)\n",
    "        loss = self.loss_function(action_q_values, target_q_values)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def decay_epsilon(self, current_step):\n",
    "         self.epsilon = max(EPSILON_END, EPSILON_START - (EPSILON_START - EPSILON_END) * (current_step / EPSILON_DECAY_STEPS))\n",
    "\n",
    "    def load(self, path):\n",
    "        try:\n",
    "             self.policy_net.load_state_dict(torch.load(path, map_location=self.device))\n",
    "             self.update_target_model()\n",
    "             print(f\"Model weights loaded from {path}\")\n",
    "        except Exception as e:\n",
    "             print(f\"Error loading model weights: {e}\")\n",
    "\n",
    "    def save(self, path):\n",
    "        try:\n",
    "             os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "             torch.save(self.policy_net.state_dict(), path)\n",
    "             print(f\"Model weights saved to {path}\")\n",
    "        except Exception as e:\n",
    "             print(f\"Error saving model weights: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5192963f",
   "metadata": {},
   "source": [
    "### DRL Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d881e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting REINFORCE Training (GNN + Attention Policy)...\n",
      "Starting DRL Training...\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 1, 64]] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 145\u001b[0m\n\u001b[0;32m    143\u001b[0m policy_optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 145\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m policy_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (episode \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (NUM_EPISODES_POLICY_GRAD \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m20\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\USUARIO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.FloatTensor [1, 1, 64]] is at version 1; expected version 0 instead. Hint: the backtrace further above shows the operation that failed to compute its gradient. The variable in question was changed in there or anywhere later. Good luck!"
     ]
    }
   ],
   "source": [
    "# --- Hyperparameters for REINFORCE ---\n",
    "POLICY_LR = 1e-4\n",
    "# NUM_EPISODES_POLICY_GRAD = max(NUM_EPISODES, 5000) # Needs enough exploration\n",
    "NUM_EPISODES_POLICY_GRAD = 5000 # For 8 nodes, might be okay. More for 57.\n",
    "REINFORCE_BASELINE_EMA_ALPHA = 0.1 # For exponential moving average baseline\n",
    "\n",
    "# --- Initialize Models ---\n",
    "gnn_encoder = GNNEncoder(NUM_NODES, NODE_INITIAL_EMBED_DIM, GNN_HIDDEN_DIM, GNN_EMBED_DIM).to(device)\n",
    "actor_policy = ActorPolicyNetwork(GNN_EMBED_DIM, TIME_FEATURE_DIM, LSTM_HIDDEN_DIM, NUM_NODES).to(device)\n",
    "policy_optimizer = optim.Adam(list(gnn_encoder.parameters()) + list(actor_policy.parameters()), lr=POLICY_LR)\n",
    "\n",
    "# --- EMA Baseline ---\n",
    "ema_baseline = 0.0\n",
    "first_baseline_update = True\n",
    "\n",
    "# --- Training History ---\n",
    "pg_episode_rewards = []\n",
    "pg_episode_lengths = []\n",
    "\n",
    "print(\"\\nStarting REINFORCE Training (GNN + Attention Policy)...\")\n",
    "training_start_time_pg = time.time()\n",
    "\n",
    "# Precompute static node embeddings (as graph doesn't change)\n",
    "static_node_embeddings = gnn_encoder(all_node_indices, edge_index)\n",
    "\n",
    "print(\"Starting DRL Training...\")\n",
    "for start_node in range(0,7):\n",
    "    print(start_node)\n",
    "    for episode in range(NUM_EPISODES):\n",
    "        current_node_idx = torch.tensor(start_node)\n",
    "        time_elapsed = 0.0\n",
    "        visited_intermediate_nodes = set()\n",
    "\n",
    "        # Initial LSTM hidden state\n",
    "        h_prev = torch.zeros(1, LSTM_HIDDEN_DIM, device=device)\n",
    "        c_prev = torch.zeros(1, LSTM_HIDDEN_DIM, device=device)\n",
    "        lstm_state = (h_prev, c_prev)\n",
    "\n",
    "        episode_log_probs = []\n",
    "        episode_step_rewards = [] # Store r_t (reward for taking action a_{t-1} leading to s_t)\n",
    "        # current_path_pg = [current_node_idx] # For debugging\n",
    "\n",
    "        for step in range(MAX_STEPS_PER_EPISODE):\n",
    "            current_node_gnn_embed = static_node_embeddings[current_node_idx.item()].clone()\n",
    "            norm_time = time_elapsed / MAX_DURATION\n",
    "\n",
    "            # --- Create Mask for Invalid Actions ---\n",
    "            invalid_mask = torch.zeros(NUM_NODES, dtype=torch.bool, device=device)\n",
    "            invalid_mask[current_node_idx.item()] = True # Cannot stay\n",
    "            for visited_idx in visited_intermediate_nodes:\n",
    "                invalid_mask[visited_idx] = True # Cannot revisit intermediate\n",
    "\n",
    "            # Detach the LSTM state before passing to the actor policy\n",
    "            h_prev, c_prev = lstm_state\n",
    "            lstm_state = (h_prev.detach(), c_prev.detach())  # Detach the previous hidden and cell state from the graph\n",
    "            # Get action probabilities and update the LSTM state\n",
    "            action_probs, lstm_state = actor_policy(current_node_gnn_embed, norm_time,\n",
    "                                                    static_node_embeddings, lstm_state,\n",
    "                                                    invalid_mask)\n",
    "            \n",
    "            # Handle case where all actions are masked (stuck)\n",
    "            if torch.all(action_probs == 0) or torch.all(torch.isinf(action_probs)):\n",
    "                # This can happen if all valid moves lead to -inf scores\n",
    "                # print(f\"PG Episode {episode}: Stuck at node {current_node_idx}, no valid actions. Probabilities: {action_probs.cpu().detach().numpy()}\")\n",
    "                # Penalize and end episode if stuck\n",
    "                # We need to ensure we don't take log of 0 prob.\n",
    "                # This implies an issue with masking or network output if it persists.\n",
    "                # For now, let's assign a large penalty to the episode.\n",
    "                # Episode will end, and this path gets low G.\n",
    "                # episode_step_rewards.append(INCOMPLETE_PENALTY * 2) # Large penalty for getting stuck\n",
    "                # done_pg = True # Treat as done\n",
    "                # break # Break from step loop\n",
    "                # Fallback: choose any unmasked node if possible, or just end with penalty\n",
    "                # This part needs careful handling if a \"stuck\" state is possible and not a bug\n",
    "                # If truly no valid actions, the loop should end due to no action taken\n",
    "                if torch.sum(action_probs > 0) == 0: # If all probabilities are zero after masking\n",
    "                    episode_step_rewards.append(INCOMPLETE_PENALTY) # Penalize this step\n",
    "                    break # end episode\n",
    "\n",
    "            action_dist = Categorical(action_probs)\n",
    "            next_node_idx = action_dist.sample()\n",
    "            log_prob = action_dist.log_prob(next_node_idx)\n",
    "            episode_log_probs.append(log_prob)\n",
    "\n",
    "            # --- Simulate Step in Environment ---\n",
    "            actual_step_reward = reward_matrix[current_node_idx.item()][next_node_idx.item()]\n",
    "            step_time = time_matrix[current_node_idx.item()][next_node_idx.item()]\n",
    "\n",
    "            current_node_idx = next_node_idx.detach() # Update current node for next iteration\n",
    "            # current_path_pg.append(current_node_idx)\n",
    "            time_elapsed += step_time\n",
    "            if current_node_idx != start_node:\n",
    "                visited_intermediate_nodes.add(current_node_idx.item())\n",
    "\n",
    "            # --- Check Termination & Terminal Rewards ---\n",
    "            done_pg = False\n",
    "            terminal_reward_pg = 0\n",
    "            if current_node_idx == start_node: # Returned home\n",
    "                if MIN_DURATION <= time_elapsed <= MAX_DURATION:\n",
    "                    terminal_reward_pg = RETURN_SUCCESS_BONUS\n",
    "                elif time_elapsed < MIN_DURATION:\n",
    "                    terminal_reward_pg = INCOMPLETE_PENALTY\n",
    "                else: # time_elapsed > MAX_DURATION\n",
    "                    terminal_reward_pg = TIME_VIOLATION_PENALTY\n",
    "                done_pg = True\n",
    "            elif time_elapsed > MAX_DURATION:\n",
    "                terminal_reward_pg = TIME_VIOLATION_PENALTY\n",
    "                done_pg = True\n",
    "            elif step == MAX_STEPS_PER_EPISODE - 1: # Max steps reached\n",
    "                terminal_reward_pg = INCOMPLETE_PENALTY # Penalize not finishing\n",
    "                done_pg = True\n",
    "            \n",
    "            episode_step_rewards.append(actual_step_reward + terminal_reward_pg if done_pg else actual_step_reward)\n",
    "\n",
    "            if done_pg:\n",
    "                break\n",
    "        \n",
    "        # --- Episode Finished, Calculate Returns and Update Policy ---\n",
    "        if not episode_log_probs: # Handles empty episodes if stuck at step 0\n",
    "            pg_episode_rewards.append(sum(episode_step_rewards))\n",
    "            pg_episode_lengths.append(len(episode_step_rewards))\n",
    "            continue\n",
    "\n",
    "        episode_return = sum(episode_step_rewards)\n",
    "        pg_episode_rewards.append(episode_return)\n",
    "        pg_episode_lengths.append(len(episode_step_rewards))\n",
    "\n",
    "        # Update baseline\n",
    "        if first_baseline_update:\n",
    "            ema_baseline = episode_return\n",
    "            first_baseline_update = False\n",
    "        else:\n",
    "            ema_baseline = REINFORCE_BASELINE_EMA_ALPHA * episode_return + (1 - REINFORCE_BASELINE_EMA_ALPHA) * ema_baseline\n",
    "        \n",
    "        # Calculate advantages (Return - Baseline)\n",
    "        advantages = torch.tensor(episode_return - ema_baseline, device=device) # Single advantage for whole episode\n",
    "        \n",
    "        # Calculate loss: - sum(log_probs * advantage)\n",
    "        # For REINFORCE, often the advantage is applied to each log_prob.\n",
    "        # However, a common variant for sequence generation applies the total (G-b) to all log_probs.\n",
    "        loss = -torch.sum(torch.stack(episode_log_probs) * advantages) / len(episode_log_probs) # Average loss\n",
    "\n",
    "        policy_optimizer.zero_grad()\n",
    "        with torch.autograd.set_detect_anomaly(True):\n",
    "            loss.backward(retain_graph=True)\n",
    "        policy_optimizer.step()\n",
    "\n",
    "        if (episode + 1) % (NUM_EPISODES_POLICY_GRAD // 20) == 0:\n",
    "            print(f\"PG Episode {episode+1}/{NUM_EPISODES_POLICY_GRAD} | Avg Reward (last 100): {np.mean(pg_episode_rewards[-100:]):.1f} | \"\n",
    "                f\"Avg Length: {np.mean(pg_episode_lengths[-100:]):.1f} | Baseline: {ema_baseline:.1f} | Loss: {loss.item():.2f}\")\n",
    "\n",
    "training_end_time_pg = time.time()\n",
    "print(f\"\\nPolicy Gradient Training Finished. Total time: {(training_end_time_pg - training_start_time_pg):.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PG Training Progress\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(pd.Series(pg_episode_rewards).rolling(100).mean())\n",
    "plt.title('PG Smoothed Episode Rewards (GNN+Attention)')\n",
    "plt.xlabel('Episode'); plt.ylabel('Smoothed Reward'); plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(pd.Series(pg_episode_lengths).rolling(100).mean())\n",
    "plt.title('PG Smoothed Episode Lengths')\n",
    "plt.xlabel('Episode'); plt.ylabel('Smoothed Length'); plt.grid(True)\n",
    "plt.tight_layout(); plt.show()\n",
    "\n",
    "# Save models\n",
    "torch.save(gnn_encoder.state_dict(), \"gnn_encoder_8node.pth\")\n",
    "torch.save(actor_policy.state_dict(), \"actor_policy_attention_8node.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "831eb6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DRL Training...\n",
      "0\n",
      "DRL_NR Episode: 300/3000, Steps: 8, Reward: 317, Avg Loss: 43171192576.0000, Epsilon: 0.703\n",
      "DRL_NR Episode: 600/3000, Steps: 8, Reward: 215, Avg Loss: 2916994318336.0000, Epsilon: 0.381\n",
      "DRL_NR Episode: 900/3000, Steps: 8, Reward: 570, Avg Loss: 32050718179328.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1200/3000, Steps: 8, Reward: 570, Avg Loss: 154729544941568.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1500/3000, Steps: 8, Reward: 570, Avg Loss: 476179375063040.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1800/3000, Steps: 8, Reward: 570, Avg Loss: 965379098673152.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2100/3000, Steps: 7, Reward: -1281, Avg Loss: 1906310516085321.2500, Epsilon: 0.050\n",
      "DRL_NR Episode: 2400/3000, Steps: 8, Reward: 570, Avg Loss: 4726761782771712.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2700/3000, Steps: 8, Reward: 570, Avg Loss: 7384076587630592.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 3000/3000, Steps: 8, Reward: 570, Avg Loss: 16991014505938944.0000, Epsilon: 0.050\n",
      "\n",
      "DRL Training (No Revisit) Finished. Total time: 30.28 seconds\n",
      "1\n",
      "DRL_NR Episode: 300/3000, Steps: 7, Reward: 593, Avg Loss: 32391787037327360.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 600/3000, Steps: 6, Reward: 376, Avg Loss: 35724433087791104.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 900/3000, Steps: 7, Reward: 593, Avg Loss: 56405443493981624.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1200/3000, Steps: 7, Reward: 593, Avg Loss: 67483901157853480.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1500/3000, Steps: 7, Reward: 593, Avg Loss: 117803998150094256.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1800/3000, Steps: 7, Reward: 593, Avg Loss: 143493628998713344.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2100/3000, Steps: 7, Reward: 593, Avg Loss: 168602097391875808.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2400/3000, Steps: 8, Reward: 441, Avg Loss: 246511748192927744.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2700/3000, Steps: 8, Reward: 975, Avg Loss: 232418339144597504.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 3000/3000, Steps: 8, Reward: 736, Avg Loss: 195995983937536000.0000, Epsilon: 0.050\n",
      "\n",
      "DRL Training (No Revisit) Finished. Total time: 58.54 seconds\n",
      "2\n",
      "DRL_NR Episode: 300/3000, Steps: 6, Reward: 275, Avg Loss: 496039671529209856.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 600/3000, Steps: 6, Reward: 275, Avg Loss: 522676675015256768.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 900/3000, Steps: 6, Reward: 275, Avg Loss: 638255911397927552.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1200/3000, Steps: 7, Reward: -1330, Avg Loss: 806495391654758656.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1500/3000, Steps: 6, Reward: 275, Avg Loss: 1130153115603260800.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1800/3000, Steps: 6, Reward: -67, Avg Loss: 948342514262212608.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2100/3000, Steps: 6, Reward: 275, Avg Loss: 1362257500512627456.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2400/3000, Steps: 6, Reward: 275, Avg Loss: 1319354430811100416.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2700/3000, Steps: 6, Reward: -89, Avg Loss: 1942020956680967424.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 3000/3000, Steps: 6, Reward: 275, Avg Loss: 1726424914228936704.0000, Epsilon: 0.050\n",
      "\n",
      "DRL Training (No Revisit) Finished. Total time: 82.42 seconds\n",
      "3\n",
      "DRL_NR Episode: 300/3000, Steps: 5, Reward: -132, Avg Loss: 2210437780540175104.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 600/3000, Steps: 5, Reward: -132, Avg Loss: 2295301798823670528.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 900/3000, Steps: 5, Reward: -132, Avg Loss: 3147956051221518848.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1200/3000, Steps: 6, Reward: 436, Avg Loss: 3037154947630454272.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1500/3000, Steps: 6, Reward: -284, Avg Loss: 3992584006175555584.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1800/3000, Steps: 5, Reward: -132, Avg Loss: 4778023545963386880.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2100/3000, Steps: 5, Reward: -132, Avg Loss: 5883979191487457280.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2400/3000, Steps: 5, Reward: -132, Avg Loss: 5344561865533109248.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2700/3000, Steps: 5, Reward: -132, Avg Loss: 5406768769971047424.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 3000/3000, Steps: 5, Reward: -132, Avg Loss: 5468643841799723008.0000, Epsilon: 0.050\n",
      "\n",
      "DRL Training (No Revisit) Finished. Total time: 102.30 seconds\n",
      "4\n",
      "DRL_NR Episode: 300/3000, Steps: 4, Reward: -546, Avg Loss: 7470196760636293120.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 600/3000, Steps: 4, Reward: -546, Avg Loss: 8772179743815499776.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 900/3000, Steps: 4, Reward: -546, Avg Loss: 7135482606275002368.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1200/3000, Steps: 4, Reward: -546, Avg Loss: 9638076486770491392.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1500/3000, Steps: 4, Reward: -546, Avg Loss: 9930996554892574720.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1800/3000, Steps: 4, Reward: -546, Avg Loss: 11166538111989579776.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2100/3000, Steps: 4, Reward: -546, Avg Loss: 12954912878581776384.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2400/3000, Steps: 4, Reward: -546, Avg Loss: 12586635719465762816.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2700/3000, Steps: 4, Reward: -546, Avg Loss: 12501319389586391040.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 3000/3000, Steps: 4, Reward: -546, Avg Loss: 12211212696841879552.0000, Epsilon: 0.050\n",
      "\n",
      "DRL Training (No Revisit) Finished. Total time: 118.77 seconds\n",
      "5\n",
      "DRL_NR Episode: 300/3000, Steps: 3, Reward: -745, Avg Loss: 12415728548303951872.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 600/3000, Steps: 3, Reward: -745, Avg Loss: 14666448275066847232.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 900/3000, Steps: 3, Reward: -745, Avg Loss: 19281678019470557184.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1200/3000, Steps: 3, Reward: -745, Avg Loss: 17353504793266137088.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1500/3000, Steps: 3, Reward: -745, Avg Loss: 19857537705417461760.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1800/3000, Steps: 3, Reward: -745, Avg Loss: 17487214936304474112.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2100/3000, Steps: 3, Reward: -745, Avg Loss: 14472323266617104384.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2400/3000, Steps: 3, Reward: -745, Avg Loss: 18629149021214953472.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2700/3000, Steps: 3, Reward: -745, Avg Loss: 15121893845586237440.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 3000/3000, Steps: 3, Reward: -745, Avg Loss: 17571347733542512640.0000, Epsilon: 0.050\n",
      "\n",
      "DRL Training (No Revisit) Finished. Total time: 131.66 seconds\n",
      "6\n",
      "DRL_NR Episode: 300/3000, Steps: 2, Reward: -542, Avg Loss: 27053712299847057408.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 600/3000, Steps: 2, Reward: -542, Avg Loss: 17395209086055743488.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 900/3000, Steps: 2, Reward: -542, Avg Loss: 21654454898536742912.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1200/3000, Steps: 2, Reward: -542, Avg Loss: 22294152962600075264.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1500/3000, Steps: 2, Reward: -542, Avg Loss: 21980793248195543040.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 1800/3000, Steps: 2, Reward: -542, Avg Loss: 20457862991097888768.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2100/3000, Steps: 2, Reward: -542, Avg Loss: 24483244329618374656.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2400/3000, Steps: 3, Reward: -1047, Avg Loss: 23902429511268958208.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 2700/3000, Steps: 2, Reward: -542, Avg Loss: 30805543941469896704.0000, Epsilon: 0.050\n",
      "DRL_NR Episode: 3000/3000, Steps: 2, Reward: -542, Avg Loss: 24296538459128987648.0000, Epsilon: 0.050\n",
      "\n",
      "DRL Training (No Revisit) Finished. Total time: 139.97 seconds\n"
     ]
    }
   ],
   "source": [
    "drl_agent_no_revisit = DQNAgent_PyTorch(state_size=STATE_SIZE,\n",
    "                                        action_size=ACTION_SPACE_SIZE,\n",
    "                                        learning_rate=LEARNING_RATE,\n",
    "                                        gamma=GAMMA,\n",
    "                                        buffer_size=BUFFER_SIZE,\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        device=device)\n",
    "\n",
    "# Training History\n",
    "drl_nr_episode_rewards = []\n",
    "drl_nr_episode_losses = []\n",
    "drl_nr_total_steps = 0\n",
    "drl_nr_start_train_time = time.time()\n",
    "\n",
    "print(\"Starting DRL Training...\")\n",
    "for start_node in range(0,7):\n",
    "    print(start_node)\n",
    "    for episode in range(NUM_EPISODES):\n",
    "        current_node = start_node\n",
    "        time_elapsed = 0.0\n",
    "        state = np.array([current_node, time_elapsed / MAX_DURATION], dtype=np.float32)\n",
    "\n",
    "        # Track visited intermediate nodes for this episode\n",
    "        visited_intermediate_nodes = set()\n",
    "\n",
    "        episode_reward = 0\n",
    "        episode_loss_sum = 0\n",
    "        steps_in_episode = 0\n",
    "        done = False\n",
    "        # current_path = [start_node] # Optional: for debugging\n",
    "\n",
    "        for step in range(MAX_STEPS_PER_EPISODE):\n",
    "            # 1. Select action, passing invalid nodes\n",
    "            # Invalid nodes are those already visited (excluding start_node)\n",
    "            action = drl_agent_no_revisit.act(state, invalid_actions=visited_intermediate_nodes)\n",
    "\n",
    "            # If action signals being stuck (returned current_node), terminate episode\n",
    "            if action == current_node and step > 0 : # Check step > 0 to allow starting state\n",
    "                # print(f\"Episode {episode}: Agent stuck at node {current_node}. Terminating.\")\n",
    "                # Apply a penalty for getting stuck?\n",
    "                terminal_reward = INCOMPLETE_PENALTY # Penalize getting stuck\n",
    "                total_reward_experience = step_reward + terminal_reward # step_reward is from previous step\n",
    "                # Need reward for current state - maybe 0? Let's use INCOMPLETE_PENALTY directly.\n",
    "\n",
    "                # Store final experience leading to stuck state? Maybe not, just end.\n",
    "                # We need the *previous* state and the action that *would* have led here.\n",
    "                # Let's just apply penalty and end episode. Reward is tracked separately.\n",
    "                episode_reward += INCOMPLETE_PENALTY\n",
    "                done = True # Mark as done because stuck\n",
    "                break # End this episode\n",
    "\n",
    "            next_node = action\n",
    "            # current_path.append(next_node) # Optional debug\n",
    "\n",
    "            # 2. Execute action in environment (Get reward and next state)\n",
    "            step_time = time_matrix[current_node][next_node]\n",
    "            step_reward = reward_matrix[current_node][next_node] # Base reward for the step\n",
    "\n",
    "            next_time_elapsed = time_elapsed + step_time\n",
    "            next_state = np.array([next_node, min(next_time_elapsed, MAX_DURATION) / MAX_DURATION], dtype=np.float32)\n",
    "\n",
    "            terminal_reward = 0\n",
    "            done = False\n",
    "\n",
    "            # 3. Check termination conditions (Same logic: success, time violation)\n",
    "            if next_node == start_node: # Returned home\n",
    "                if MIN_DURATION <= next_time_elapsed <= MAX_DURATION:\n",
    "                    terminal_reward = RETURN_SUCCESS_BONUS\n",
    "                    done = True\n",
    "                elif next_time_elapsed < MIN_DURATION:\n",
    "                    terminal_reward = INCOMPLETE_PENALTY\n",
    "                    done = True\n",
    "                else: # > MAX_DURATION\n",
    "                    terminal_reward = TIME_VIOLATION_PENALTY\n",
    "                    done = True\n",
    "            elif next_time_elapsed > MAX_DURATION:\n",
    "                terminal_reward = TIME_VIOLATION_PENALTY\n",
    "                done = True\n",
    "            # No explicit penalty here if max_steps reached, handled by potential incomplete penalty later?\n",
    "            # Or add: elif step == MAX_STEPS_PER_EPISODE - 1: done = True; terminal_reward = INCOMPLETE_PENALTY\n",
    "\n",
    "\n",
    "            # 4. Store experience in replay buffer\n",
    "            total_reward_experience = step_reward + terminal_reward\n",
    "            drl_agent_no_revisit.remember(state, action, total_reward_experience, next_state, done)\n",
    "\n",
    "            # 5. Update state, rewards, steps etc.\n",
    "            state = next_state\n",
    "            # Update visited intermediate nodes *after* storing experience, *before* next action selection\n",
    "            if next_node != start_node:\n",
    "                visited_intermediate_nodes.add(next_node)\n",
    "            current_node = next_node\n",
    "            time_elapsed = next_time_elapsed\n",
    "            episode_reward += step_reward\n",
    "            steps_in_episode += 1\n",
    "            drl_nr_total_steps += 1\n",
    "\n",
    "            # 6. Decay epsilon\n",
    "            drl_agent_no_revisit.decay_epsilon(drl_nr_total_steps)\n",
    "\n",
    "            # 7. Train model\n",
    "            loss = drl_agent_no_revisit.replay()\n",
    "            if loss > 0: episode_loss_sum += loss\n",
    "\n",
    "            # 8. Update target network\n",
    "            if drl_nr_total_steps % TARGET_UPDATE_FREQ == 0:\n",
    "                drl_agent_no_revisit.update_target_model()\n",
    "\n",
    "            if done:\n",
    "                episode_reward += terminal_reward\n",
    "                break # End episode\n",
    "\n",
    "        # --- End of Episode ---\n",
    "        drl_nr_episode_rewards.append(episode_reward)\n",
    "        avg_loss = episode_loss_sum / steps_in_episode if steps_in_episode > 0 else 0\n",
    "        drl_nr_episode_losses.append(avg_loss)\n",
    "\n",
    "        if (episode + 1) % (NUM_EPISODES // 10) == 0:\n",
    "            print(f\"DRL_NR Episode: {episode + 1}/{NUM_EPISODES}, Steps: {steps_in_episode}, Reward: {episode_reward:.0f}, Avg Loss: {avg_loss:.4f}, Epsilon: {drl_agent_no_revisit.epsilon:.3f}\")\n",
    "\n",
    "    drl_nr_training_time = time.time() - drl_nr_start_train_time\n",
    "    print(f\"\\nDRL Training (No Revisit) Finished. Total time: {drl_nr_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0ae01066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot DRL Training Progress\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(pd.Series(drl_episode_rewards).rolling(50).mean()) # Smoothed rewards\n",
    "plt.title('DRL Smoothed Episode Rewards')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Smoothed Reward')\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(pd.Series(drl_episode_losses).rolling(50).mean()) # Smoothed loss\n",
    "plt.title('DRL Smoothed Average Episode Loss')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Smoothed Loss')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7cb96c",
   "metadata": {},
   "source": [
    "### DRL Route Generation Function (Same as before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "96e89d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_optimal_route_pytorch(agent, start_node, time_matrix, reward_matrix, max_steps=2*NUM_NODES):\n",
    "    \"\"\"\n",
    "    Generates a route using the learned policy (greedy selection),\n",
    "    preventing revisits to intermediate nodes.\n",
    "    If max_steps is reached, attempts forced return if valid.\n",
    "    Validates final duration window.\n",
    "    \"\"\"\n",
    "    agent.epsilon = 0\n",
    "    agent.policy_net.eval()\n",
    "    current_node = start_node\n",
    "    time_elapsed = 0.0\n",
    "    state = np.array([current_node, time_elapsed / MAX_DURATION], dtype=np.float32)\n",
    "    route = [start_node]\n",
    "    visited_intermediate_nodes = set() # Keep track of nodes visited *other than* start_node\n",
    "    total_reward = 0.0\n",
    "    returned_home = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step in range(max_steps):\n",
    "            # --- Action Selection ---\n",
    "            state_tensor = torch.from_numpy(state).float().unsqueeze(0).to(agent.device)\n",
    "            q_values = agent.policy_net(state_tensor)\n",
    "            q_values_numpy = q_values.cpu().data.numpy()[0]\n",
    "\n",
    "            # --- Masking Invalid Actions ---\n",
    "            # 1. Don't stay in the same node\n",
    "            q_values_numpy[current_node] = -np.inf\n",
    "\n",
    "            # 2. Don't visit intermediate nodes already visited\n",
    "            for visited_node_idx in visited_intermediate_nodes:\n",
    "                 if 0 <= visited_node_idx < len(q_values_numpy): # Bounds check\n",
    "                      q_values_numpy[visited_node_idx] = -np.inf\n",
    "\n",
    "            # --- Choose Best Valid Action ---\n",
    "            next_node = np.argmax(q_values_numpy)\n",
    "\n",
    "            # Check if any valid action exists\n",
    "            if q_values_numpy[next_node] == -np.inf:\n",
    "                 # No valid moves possible (maybe all unvisited nodes violate time or Q-values are terrible)\n",
    "                 # Try forcing return home immediately if possible\n",
    "                 # print(f\"DRL: Stuck at node {current_node}. No valid non-visited moves. Trying return home.\")\n",
    "                 if current_node != start_node:\n",
    "                     return_time = time_matrix[current_node][start_node]\n",
    "                     if time_elapsed + return_time <= MAX_DURATION + 1e-6:\n",
    "                         next_node = start_node # Override choice to return home\n",
    "                         # print(\"DRL: Forcing return home as only option.\")\n",
    "                     else:\n",
    "                        # print(f\"DRL Error: Stuck at node {current_node}. Cannot return home within duration.\")\n",
    "                        returned_home = False\n",
    "                        break # Cannot proceed\n",
    "                 else: # Stuck at start node? Should not happen if mask works.\n",
    "                    returned_home = False\n",
    "                    break\n",
    "\n",
    "\n",
    "            # --- Simulate Step ---\n",
    "            step_time = time_matrix[current_node][next_node]\n",
    "            step_reward = reward_matrix[current_node][next_node]\n",
    "\n",
    "            # --- Check immediate time violation (should be less likely now with stuck check) ---\n",
    "            if time_elapsed + step_time > MAX_DURATION + 1e-6 and next_node != start_node:\n",
    "                 # print(f\"DRL: Next step to {next_node} violates MAX_DURATION. Stopping.\")\n",
    "                 returned_home = False\n",
    "                 break\n",
    "\n",
    "            # --- Update State ---\n",
    "            time_elapsed += step_time\n",
    "            total_reward += step_reward\n",
    "            current_node = next_node\n",
    "            route.append(current_node)\n",
    "            # Add to visited set *only if* it's not the start node\n",
    "            if current_node != start_node:\n",
    "                visited_intermediate_nodes.add(current_node)\n",
    "\n",
    "            state = np.array([current_node, min(time_elapsed, MAX_DURATION) / MAX_DURATION], dtype=np.float32)\n",
    "\n",
    "            # --- Check for Natural Return ---\n",
    "            if current_node == start_node:\n",
    "                returned_home = True\n",
    "                break\n",
    "\n",
    "        # --- End of Step Loop ---\n",
    "\n",
    "        # --- Handle Forced Return if max_steps reached ---\n",
    "        # (This logic might be less necessary now but keep as fallback)\n",
    "        if not returned_home and current_node != start_node:\n",
    "            # print(f\"DRL: Max steps reached, attempting forced return from {current_node} to {start_node}\")\n",
    "            return_time = time_matrix[current_node][start_node]\n",
    "            return_reward = reward_matrix[current_node][start_node]\n",
    "            if time_elapsed + return_time <= MAX_DURATION + 1e-6:\n",
    "                time_elapsed += return_time\n",
    "                total_reward += return_reward\n",
    "                current_node = start_node\n",
    "                route.append(start_node)\n",
    "                returned_home = True\n",
    "            # else: # Forced return violates time\n",
    "                # returned_home remains False\n",
    "\n",
    "    # --- Final Validation ---\n",
    "    agent.policy_net.train()\n",
    "\n",
    "    is_cycle = returned_home and route[0] == start_node and route[-1] == start_node and len(route)>1\n",
    "\n",
    "    if not is_cycle:\n",
    "        return None, -np.inf, np.inf # Failed route\n",
    "\n",
    "    is_valid_duration = MIN_DURATION <= time_elapsed <= MAX_DURATION\n",
    "\n",
    "    # Check for duplicate intermediate nodes (should be prevented by logic above)\n",
    "    intermediate_nodes = route[1:-1]\n",
    "    has_duplicates = len(intermediate_nodes) != len(set(intermediate_nodes))\n",
    "    if has_duplicates:\n",
    "         print(f\"Warning: DRL route {route} has duplicate intermediate nodes despite masking!\")\n",
    "         # Treat as invalid? Or just note it. Let's return it but validity check below will fail if needed.\n",
    "\n",
    "    if is_valid_duration and not has_duplicates:\n",
    "        return route, total_reward, time_elapsed # Valid cycle found\n",
    "    else:\n",
    "        # Cycle formed, but duration or node visit is invalid\n",
    "        return route, total_reward, time_elapsed # Return invalid route details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9210d9d0",
   "metadata": {},
   "source": [
    "## Part 3: MIP Formulation and Solution (using PuLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "83f9fe26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_mip(start_node, time_m, reward_m, min_d, max_d, num_n):\n",
    "    \"\"\"Solves the VRP variant using MIP for a given start node.\"\"\"\n",
    "    nodes = list(range(num_n))\n",
    "    other_nodes = [n for n in nodes if n != start_node]\n",
    "\n",
    "    # Create the model\n",
    "    prob = pulp.LpProblem(f\"VRP_Cycle_{start_node}\", pulp.LpMaximize)\n",
    "\n",
    "    # Decision Variables\n",
    "    x = pulp.LpVariable.dicts(\"Route\", (nodes, nodes), 0, 1, pulp.LpBinary)\n",
    "    u = pulp.LpVariable.dicts(\"MTZ\", nodes, 1, num_n - 1, pulp.LpContinuous)\n",
    "\n",
    "    # Objective Function\n",
    "    prob += pulp.lpSum(reward_m[i][j] * x[i][j] for i in nodes for j in nodes if i != j)\n",
    "\n",
    "    # Constraints\n",
    "    # 1. Degree Constraints\n",
    "    for k in nodes:\n",
    "        prob += pulp.lpSum(x[k][j] for j in nodes if k != j) == pulp.lpSum(x[j][k] for j in nodes if k != j)\n",
    "        if k == start_node:\n",
    "            prob += pulp.lpSum(x[start_node][j] for j in nodes if j != start_node) == 1\n",
    "            prob += pulp.lpSum(x[j][start_node] for j in nodes if j != start_node) == 1\n",
    "        else:\n",
    "             prob += pulp.lpSum(x[j][k] for j in nodes if j != k) <= 1\n",
    "\n",
    "    # 2. Duration Constraints\n",
    "    total_time = pulp.lpSum(time_m[i][j] * x[i][j] for i in nodes for j in nodes if i != j)\n",
    "    prob += total_time >= min_d\n",
    "    prob += total_time <= max_d\n",
    "\n",
    "    # 3. Subtour Elimination (MTZ)\n",
    "    for i in other_nodes:\n",
    "        prob += u[i] >= 1\n",
    "        for j in other_nodes:\n",
    "            if i != j:\n",
    "                 prob += u[i] - u[j] + 1 <= (num_n - 1) * (1 - x[i][j])\n",
    "\n",
    "    # Solve the problem\n",
    "    solver = pulp.PULP_CBC_CMD(msg=0)\n",
    "    prob.solve(solver)\n",
    "\n",
    "    # Extract results\n",
    "    status = pulp.LpStatus[prob.status]\n",
    "    route = None\n",
    "    total_reward = -np.inf\n",
    "    total_duration = np.inf\n",
    "\n",
    "    if status == 'Optimal':\n",
    "        total_reward = pulp.value(prob.objective)\n",
    "        total_duration = pulp.value(total_time)\n",
    "\n",
    "        # --- Modified Route Reconstruction ---\n",
    "        try: # Add a try-except block for safety during reconstruction\n",
    "            current_node = start_node\n",
    "            route = [start_node]\n",
    "            visited_count = 0 # Safety counter\n",
    "\n",
    "            while visited_count <= num_n: # Limit search depth\n",
    "                found_next = False\n",
    "                for j in nodes:\n",
    "                    # Check if arc variable exists, is not None, and is selected (> 0.99)\n",
    "                    # Also ensure j is not the current node\n",
    "                    if j != current_node and \\\n",
    "                       x[current_node][j] is not None and \\\n",
    "                       x[current_node][j].varValue is not None and \\\n",
    "                       x[current_node][j].varValue > 0.99:\n",
    "\n",
    "                        route.append(j)\n",
    "                        current_node = j\n",
    "                        found_next = True\n",
    "                        break # Move to the next node in the path\n",
    "\n",
    "                visited_count += 1\n",
    "\n",
    "                if current_node == start_node: # Successfully completed the cycle\n",
    "                    break\n",
    "                if not found_next: # Dead end found during reconstruction\n",
    "                    # print(f\"MIP Route Reconstruction Error: Dead end at node {current_node} for start {start_node}.\")\n",
    "                    route = None # Invalid route\n",
    "                    break\n",
    "                if visited_count > num_n: # Avoid infinite loops / too many steps\n",
    "                    # print(f\"MIP Route Reconstruction Error: Route too long for start {start_node}. Path: {route}\")\n",
    "                    route = None # Invalid route\n",
    "                    break\n",
    "\n",
    "            # Final validation of reconstructed route\n",
    "            if route is None or route[0] != start_node or route[-1] != start_node:\n",
    "                 # print(f\"MIP Route Reconstruction resulted in invalid path for start {start_node}. Route: {route}\")\n",
    "                 route = None\n",
    "                 # If route is invalid, reset reward/duration derived from MIP objective\n",
    "                 total_reward = -np.inf\n",
    "                 total_duration = np.inf\n",
    "                 status = 'Error_In_Route' # Update status to reflect this\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exception during MIP route reconstruction for start {start_node}: {e}\")\n",
    "            route = None\n",
    "            total_reward = -np.inf\n",
    "            total_duration = np.inf\n",
    "            status = 'Error_Exception'\n",
    "        # --- End of Modified Route Reconstruction ---\n",
    "\n",
    "    # Ensure reward/duration are consistent if route is None\n",
    "    if route is None:\n",
    "         total_reward = -np.inf\n",
    "         total_duration = np.inf\n",
    "         # Update status if it was 'Optimal' but route failed\n",
    "         if status == 'Optimal': status = 'Optimal_Route_Fail'\n",
    "\n",
    "\n",
    "    return status, route, total_reward, total_duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccb79d",
   "metadata": {},
   "source": [
    "## Part 4: Simple Greedy Heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b7403663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_heuristic(start_node, time_m, reward_m, min_d, max_d, num_n):\n",
    "    \"\"\"Solves using a greedy heuristic (Best Reward/Time Ratio).\"\"\"\n",
    "    current_node = start_node\n",
    "    time_elapsed = 0.0\n",
    "    total_reward = 0.0\n",
    "    route = [start_node]\n",
    "    visited = {start_node}\n",
    "\n",
    "    max_steps = num_n * 2 # Safety break\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        best_ratio = -np.inf\n",
    "        best_next_node = -1\n",
    "        candidates = []\n",
    "\n",
    "        # Find potential next nodes and their ratios\n",
    "        for next_node in range(num_n):\n",
    "            if next_node != current_node and next_node not in visited:\n",
    "                step_time = time_m[current_node][next_node]\n",
    "                step_reward = reward_m[current_node][next_node] # Use non-penalized rewards\n",
    "\n",
    "                if step_reward == BIG_M_PENALTY: continue # Skip penalized self-loops if any\n",
    "\n",
    "                # Check if adding this step exceeds max duration\n",
    "                if time_elapsed + step_time <= max_d:\n",
    "                    if step_time > 1e-6: # Avoid division by zero\n",
    "                        ratio = step_reward / step_time\n",
    "                    else:\n",
    "                        ratio = np.inf # Prioritize zero-time moves if rewarding\n",
    "\n",
    "                    candidates.append({'node': next_node, 'ratio': ratio, 'time': step_time, 'reward': step_reward})\n",
    "\n",
    "        # Sort candidates by ratio (highest first)\n",
    "        candidates.sort(key=lambda x: x['ratio'], reverse=True)\n",
    "\n",
    "        selected_move = None\n",
    "        if candidates:\n",
    "            selected_move = candidates[0] # Choose best ratio move initially\n",
    "        # else: # No valid moves that don't exceed max duration or all nodes visited\n",
    "            # Try returning home directly if not already home\n",
    "            if current_node != start_node:\n",
    "                 return_time = time_m[current_node][start_node]\n",
    "                 return_reward = reward_m[current_node][start_node]\n",
    "                 if time_elapsed + return_time <= max_d:\n",
    "                     selected_move = {'node': start_node, 'time': return_time, 'reward': return_reward}\n",
    "                 # else: No valid move possible, loop will terminate\n",
    "\n",
    "        if selected_move:\n",
    "            next_n = selected_move['node']\n",
    "            time_elapsed += selected_move['time']\n",
    "            total_reward += selected_move['reward']\n",
    "            current_node = next_n\n",
    "            route.append(next_n)\n",
    "            if next_n != start_node:\n",
    "                visited.add(next_n)\n",
    "\n",
    "            if current_node == start_node: # Completed a cycle\n",
    "                break\n",
    "        else:\n",
    "            # No move possible (either stuck or only invalid moves remaining)\n",
    "            break # Exit loop\n",
    "\n",
    "    # Final validation\n",
    "    status = \"Infeasible\"\n",
    "    is_valid = False\n",
    "    if route[-1] == start_node and len(route) > 1: # Check if it's a cycle\n",
    "         if min_d <= time_elapsed <= max_d:\n",
    "             status = \"Optimal\" # Heuristic found a valid solution\n",
    "             is_valid = True\n",
    "         else:\n",
    "            status = \"Feasible_Invalid_Duration\" # Found cycle, wrong duration\n",
    "    # else: Route did not end at start node\n",
    "\n",
    "\n",
    "    return status, route, total_reward, time_elapsed, is_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd6f7d3",
   "metadata": {},
   "source": [
    "## Part 5: Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88102da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Solvers for Each Start Node ---\n",
      "Solving for Start Node: 0\n",
      "Solving for Start Node: 1\n",
      "Solving for Start Node: 2\n",
      "Solving for Start Node: 3\n",
      "Solving for Start Node: 4\n",
      "Solving for Start Node: 5\n",
      "Solving for Start Node: 6\n",
      "Solving for Start Node: 7\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "mip_times = []\n",
    "heuristic_times = []\n",
    "drl_inference_times = []\n",
    "\n",
    "print(\"\\n--- Running Solvers for Each Start Node ---\")\n",
    "\n",
    "for s_node in range(NUM_NODES):\n",
    "    print(f\"Solving for Start Node: {s_node}\")\n",
    "    result_row = {'Start Node': s_node}\n",
    "\n",
    "    # Solve with DRL\n",
    "    t0 = time.time()\n",
    "    drl_route, drl_reward, drl_duration = generate_optimal_route_pytorch(drl_agent, s_node, time_matrix, reward_matrix)\n",
    "    drl_inference_times.append(time.time() - t0)\n",
    "    result_row['DRL Route'] = drl_route\n",
    "    result_row['DRL Reward'] = drl_reward if drl_route else -np.inf\n",
    "    result_row['DRL Duration'] = drl_duration if drl_route else np.inf\n",
    "    result_row['DRL Valid'] = drl_route is not None and drl_route[0] == drl_route[-1]\n",
    "    # Solve with MIP\n",
    "    t0 = time.time()\n",
    "    # Use original (non-penalized) reward matrix for MIP objective\n",
    "    mip_status, mip_route, mip_reward, mip_duration = solve_mip(s_node, time_matrix, reward_matrix, MIN_DURATION, MAX_DURATION, NUM_NODES)\n",
    "    mip_times.append(time.time() - t0)\n",
    "    result_row['MIP Status'] = mip_status\n",
    "    result_row['MIP Route'] = mip_route\n",
    "    result_row['MIP Reward'] = mip_reward if mip_status == 'Optimal' else -np.inf\n",
    "    result_row['MIP Duration'] = mip_duration if mip_status == 'Optimal' else np.inf\n",
    "    result_row['MIP Valid'] = mip_status == 'Optimal' and mip_route is not None\n",
    "\n",
    "    # Solve with Heuristic\n",
    "    t0 = time.time()\n",
    "    # Use original reward matrix for heuristic evaluation\n",
    "    heu_status, heu_route, heu_reward, heu_duration, heu_valid = solve_heuristic(s_node, time_matrix, reward_matrix, MIN_DURATION, MAX_DURATION, NUM_NODES)\n",
    "    heuristic_times.append(time.time() - t0)\n",
    "    result_row['Heuristic Route'] = heu_route\n",
    "    result_row['Heuristic Reward'] = heu_reward if heu_valid else (heu_reward if heu_route else -np.inf) # Show reward even if duration invalid\n",
    "    result_row['Heuristic Duration'] = heu_duration if heu_route else np.inf\n",
    "    result_row['Heuristic Valid'] = heu_valid\n",
    "\n",
    "    # Calculate Optimality Gaps (relative to MIP if MIP is optimal)\n",
    "    mip_opt_reward = result_row['MIP Reward']\n",
    "    if result_row['MIP Valid']:\n",
    "        drl_gap = ((mip_opt_reward - result_row['DRL Reward']) / abs(mip_opt_reward)) * 100 if abs(mip_opt_reward) > 1e-6 and result_row['DRL Valid'] else float('nan')\n",
    "        heu_gap = ((mip_opt_reward - result_row['Heuristic Reward']) / abs(mip_opt_reward)) * 100 if abs(mip_opt_reward) > 1e-6 and result_row['Heuristic Valid'] else float('nan')\n",
    "    else:\n",
    "        drl_gap = float('nan')\n",
    "        heu_gap = float('nan')\n",
    "\n",
    "    result_row['DRL Gap (%)'] = drl_gap\n",
    "    result_row['Heuristic Gap (%)'] = heu_gap\n",
    "\n",
    "    results.append(result_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802be5e4",
   "metadata": {},
   "source": [
    "### Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e75c4614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparison Summary ---\n",
      "   Start Node MIP Status  MIP Reward  MIP Valid  DRL Reward  DRL Valid  \\\n",
      "0           0    Optimal      1380.0       True      1331.0       True   \n",
      "1           1    Optimal      1380.0       True       721.0       True   \n",
      "2           2    Optimal      1380.0       True       721.0       True   \n",
      "3           3    Optimal      1380.0       True       792.0       True   \n",
      "4           4    Optimal      1380.0       True      1594.0       True   \n",
      "5           5    Optimal      1380.0       True      1351.0       True   \n",
      "6           6    Optimal      1094.0       True       333.0       True   \n",
      "7           7    Optimal      1380.0       True       167.0       True   \n",
      "\n",
      "  DRL Gap (%)  Heuristic Reward  Heuristic Valid  Heuristic Gap (%)  \n",
      "0         3.6             280.0            False                NaN  \n",
      "1        47.8             721.0            False                NaN  \n",
      "2        47.8             819.0            False                NaN  \n",
      "3        42.6             771.0            False                NaN  \n",
      "4       -15.5             674.0            False                NaN  \n",
      "5         2.1             201.0            False                NaN  \n",
      "6        69.6            -342.0            False                NaN  \n",
      "7        87.9            -301.0            False                NaN  \n",
      "\n",
      "Example Routes for Start Node 0:\n",
      "MIP: [0, 7, 5, 4, 1, 2, 3, 0]\n",
      "DRL: [0, np.int64(1), np.int64(2), np.int64(3), np.int64(5), np.int64(0)]\n",
      "Heuristic: [0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "# Format gaps for display\n",
    "results_df['DRL Gap (%)'] = results_df['DRL Gap (%)'].map('{:.1f}'.format, na_action='ignore')\n",
    "results_df['Heuristic Gap (%)'] = results_df['Heuristic Gap (%)'].map('{:.1f}'.format, na_action='ignore')\n",
    "\n",
    "# Select and reorder columns for better readability\n",
    "summary_cols = [\n",
    "    'Start Node',\n",
    "    'MIP Status', 'MIP Reward', 'MIP Valid', #'MIP Route',\n",
    "    'DRL Reward', 'DRL Valid', 'DRL Gap (%)', #'DRL Route',\n",
    "    'Heuristic Reward', 'Heuristic Valid', 'Heuristic Gap (%)', #'Heuristic Route'\n",
    "]\n",
    "print(\"\\n--- Comparison Summary ---\")\n",
    "print(results_df[summary_cols].round(1)) # Round rewards/durations\n",
    "\n",
    "# Display routes for a specific node if needed\n",
    "print(\"\\nExample Routes for Start Node 0:\")\n",
    "print(\"MIP:\", results_df.loc[0, 'MIP Route'])\n",
    "print(\"DRL:\", results_df.loc[0, 'DRL Route'])\n",
    "print(\"Heuristic:\", results_df.loc[0, 'Heuristic Route'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6595a30",
   "metadata": {},
   "source": [
    "### Aggregate Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f9c7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Aggregate Performance ---\n",
      "Success Rate (Valid Route Found):\n",
      "  MIP:       100.0%\n",
      "  DRL:       100.0%\n",
      "  Heuristic: 0.0%\n",
      "\n",
      "Average Reward (for valid routes found):\n",
      "  MIP:       1344.2\n",
      "  DRL:       876.2\n",
      "  Heuristic: nan\n",
      "\n",
      "Average Optimality Gap (vs MIP, when both valid):\n",
      "  DRL:       35.7%\n",
      "  Heuristic: nan%\n",
      "\n",
      "--- Computation Times ---\n",
      "DRL Training:          311.83 seconds (Total)\n",
      "Average MIP Solve Time: 0.066 seconds per instance\n",
      "Average DRL Infer Time: 0.0021 seconds per instance\n",
      "Average Heuristic Time: 0.0000 seconds per instance\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Aggregate Performance ---\")\n",
    "\n",
    "# Success Rates (finding a valid route)\n",
    "mip_success = results_df['MIP Valid'].mean() * 100\n",
    "drl_success = results_df['DRL Valid'].mean() * 100\n",
    "heu_success = results_df['Heuristic Valid'].mean() * 100\n",
    "print(f\"Success Rate (Valid Route Found):\")\n",
    "print(f\"  MIP:       {mip_success:.1f}%\")\n",
    "print(f\"  DRL:       {drl_success:.1f}%\")\n",
    "print(f\"  Heuristic: {heu_success:.1f}%\")\n",
    "\n",
    "# Average Rewards (only for valid routes found by respective method)\n",
    "avg_mip_reward = results_df.loc[results_df['MIP Valid'], 'MIP Reward'].mean()\n",
    "avg_drl_reward = results_df.loc[results_df['DRL Valid'], 'DRL Reward'].mean()\n",
    "avg_heu_reward = results_df.loc[results_df['Heuristic Valid'], 'Heuristic Reward'].mean()\n",
    "print(f\"\\nAverage Reward (for valid routes found):\")\n",
    "print(f\"  MIP:       {avg_mip_reward:.1f}\")\n",
    "print(f\"  DRL:       {avg_drl_reward:.1f}\")\n",
    "print(f\"  Heuristic: {avg_heu_reward:.1f}\")\n",
    "\n",
    "# Average Optimality Gap (only for cases where MIP found optimal & method found valid)\n",
    "# Convert gaps back to numeric for calculation\n",
    "results_df['DRL Gap (%)'] = pd.to_numeric(results_df['DRL Gap (%)'], errors='coerce')\n",
    "results_df['Heuristic Gap (%)'] = pd.to_numeric(results_df['Heuristic Gap (%)'], errors='coerce')\n",
    "\n",
    "avg_drl_gap = results_df['DRL Gap (%)'].mean() # Mean ignores NaN by default\n",
    "avg_heu_gap = results_df['Heuristic Gap (%)'].mean()\n",
    "print(f\"\\nAverage Optimality Gap (vs MIP, when both valid):\")\n",
    "print(f\"  DRL:       {avg_drl_gap:.1f}%\")\n",
    "print(f\"  Heuristic: {avg_heu_gap:.1f}%\")\n",
    "\n",
    "# Computation Times\n",
    "print(\"\\n--- Computation Times ---\")\n",
    "print(f\"DRL Training:          {drl_nr_training_time:.2f} seconds (Total)\")\n",
    "print(f\"Average MIP Solve Time: {np.mean(mip_times):.3f} seconds per instance\")\n",
    "print(f\"Average DRL Infer Time: {np.mean(drl_inference_times):.4f} seconds per instance\")\n",
    "print(f\"Average Heuristic Time: {np.mean(heuristic_times):.4f} seconds per instance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c229f355",
   "metadata": {},
   "source": [
    "# ### Initial Observations \n",
    "# * The **MIP solver** (if successful) finds the true optimal solution, providing the best possible reward within the constraints. However, it can be the slowest per instance. Its success depends on the solver's ability to handle the constraints and find an integer solution within its limits.\n",
    "# * The **DRL agent** learns a policy that attempts to maximize rewards. Its performance is sensitive to hyperparameters, training duration, and the network's ability to generalize. It might find good, near-optimal solutions but isn't guaranteed to be optimal. Training takes time upfront, but generating a route (inference) is very fast. Its success rate might be lower than MIP if training wasn't sufficient or the problem is complex.\n",
    "# * The **Greedy Heuristic** is very fast but highly myopic. It often finds suboptimal solutions or fails to meet the duration constraints (especially the lower bound `MIN_DURATION`). Its success rate and reward quality are typically the lowest.\n",
    "# * **Optimality Gaps:** The average gaps quantify how close DRL and the heuristic get to the optimal MIP reward *when both find a valid solution*. Lower gaps are better. DRL would ideally have a smaller gap than the heuristic.\n",
    "# * **Success Rate:** Comparing the percentage of starting nodes for which each method found a *valid* route is crucial. A method might get high rewards on average but only succeed on a few easy instances.\n",
    "#\n",
    "# **Next Steps:** Based on these 8-node results, you can decide:\n",
    "# 1.  Do the DRL hyperparameters or network architecture need tuning?\n",
    "# 2.  Is the state representation adequate?\n",
    "# 3.  Is the MIP formulation correct and computationally tractable enough for N=57 (might need a more powerful solver or longer time limits)?\n",
    "# 4.  Is the simple heuristic too weak? Should a stronger one (e.g., insertion, SA) be considered for the N=57 case?\n",
    "# 5.  Does the sample data reasonably reflect the characteristics of your full 57-node dataset? If not, adjust the data generation or use actual data if available.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
