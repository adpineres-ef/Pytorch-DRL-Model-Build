{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch==2.0.1) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch==2.0.1) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch==2.0.1) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch==2.0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch==2.0.1) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from sympy->torch==2.0.1) (1.3.0)\n",
      "Requirement already satisfied: torch-geometric==2.3.1 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (4.65.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (1.14.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (3.1.4)\n",
      "Requirement already satisfied: requests in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (2.29.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (3.1.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (1.5.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch-geometric==2.3.1) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from jinja2->torch-geometric==2.3.1) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from requests->torch-geometric==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from requests->torch-geometric==2.3.1) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from requests->torch-geometric==2.3.1) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from requests->torch-geometric==2.3.1) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from scikit-learn->torch-geometric==2.3.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from scikit-learn->torch-geometric==2.3.1) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from tqdm->torch-geometric==2.3.1) (0.4.6)\n",
      "Collecting numpy==1.23.0\n",
      "  Using cached numpy-1.23.0.tar.gz (10.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: numpy\n",
      "  Building wheel for numpy (pyproject.toml): started\n",
      "  Building wheel for numpy (pyproject.toml): finished with status 'error'\n",
      "Failed to build numpy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for numpy (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [213 lines of output]\n",
      "      setup.py:71: RuntimeWarning: NumPy 1.23.0 may not yet support Python 3.11.\n",
      "        warnings.warn(\n",
      "      Running from numpy source directory.\n",
      "      setup.py:86: DeprecationWarning:\n",
      "      \n",
      "        `numpy.distutils` is deprecated since NumPy 1.23.0, as a result\n",
      "        of the deprecation of `distutils` itself. It will be removed for\n",
      "        Python >= 3.12. For older Python versions it will remain present.\n",
      "        It is recommended to use `setuptools < 60.0` for those Python versions.\n",
      "        For more details, see:\n",
      "          https://numpy.org/devdocs/reference/distutils_status_migration.html\n",
      "      \n",
      "      \n",
      "        import numpy.distutils.command.sdist\n",
      "      Cythonizing sources\n",
      "      Processing numpy/random\\_bounded_integers.pxd.in\n",
      "      Processing numpy/random\\bit_generator.pyx\n",
      "      Processing numpy/random\\mtrand.pyx\n",
      "      Processing numpy/random\\_bounded_integers.pyx.in\n",
      "      Processing numpy/random\\_common.pyx\n",
      "      Processing numpy/random\\_generator.pyx\n",
      "      Processing numpy/random\\_mt19937.pyx\n",
      "      Processing numpy/random\\_pcg64.pyx\n",
      "      Processing numpy/random\\_philox.pyx\n",
      "      Processing numpy/random\\_sfc64.pyx\n",
      "      INFO: blas_opt_info:\n",
      "      INFO: blas_armpl_info:\n",
      "      INFO: No module named 'numpy.distutils._msvccompiler' in numpy.distutils; trying from distutils\n",
      "      INFO: customize MSVCCompiler\n",
      "      INFO:   libraries armpl_lp64_mp not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: blas_mkl_info:\n",
      "      INFO:   libraries mkl_rt not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: blis_info:\n",
      "      INFO:   libraries blis not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: openblas_info:\n",
      "      INFO:   libraries openblas not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO: get_default_fcompiler: matching types: '['gnu', 'intelv', 'absoft', 'compaqv', 'intelev', 'gnu95', 'g95', 'intelvem', 'intelem', 'flang']'\n",
      "      INFO: customize GnuFCompiler\n",
      "      WARN: Could not locate executable g77\n",
      "      WARN: Could not locate executable f77\n",
      "      INFO: customize IntelVisualFCompiler\n",
      "      WARN: Could not locate executable ifort\n",
      "      WARN: Could not locate executable ifl\n",
      "      INFO: customize AbsoftFCompiler\n",
      "      WARN: Could not locate executable f90\n",
      "      INFO: customize CompaqVisualFCompiler\n",
      "      WARN: Could not locate executable DF\n",
      "      INFO: customize IntelItaniumVisualFCompiler\n",
      "      WARN: Could not locate executable efl\n",
      "      INFO: customize Gnu95FCompiler\n",
      "      WARN: Could not locate executable gfortran\n",
      "      WARN: Could not locate executable f95\n",
      "      INFO: customize G95FCompiler\n",
      "      WARN: Could not locate executable g95\n",
      "      INFO: customize IntelEM64VisualFCompiler\n",
      "      INFO: customize IntelEM64TFCompiler\n",
      "      WARN: Could not locate executable efort\n",
      "      WARN: Could not locate executable efc\n",
      "      INFO: customize PGroupFlangCompiler\n",
      "      WARN: Could not locate executable flang\n",
      "      WARN: don't know how to compile Fortran code on platform 'nt'\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: accelerate_info:\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_3_10_blas_threads_info:\n",
      "      INFO: Setting PTATLAS=ATLAS\n",
      "      INFO:   libraries tatlas not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_3_10_blas_info:\n",
      "      INFO:   libraries satlas not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_blas_threads_info:\n",
      "      INFO: Setting PTATLAS=ATLAS\n",
      "      INFO:   libraries ptf77blas,ptcblas,atlas not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_blas_info:\n",
      "      INFO:   libraries f77blas,cblas,atlas not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      C:\\Users\\USUARIO\\AppData\\Local\\Temp\\pip-install-_l0zhw9o\\numpy_06fefd0f44e24a95965de3d18597992f\\numpy\\distutils\\system_info.py:2077: UserWarning:\n",
      "          Optimized (vendor) Blas libraries are not found.\n",
      "          Falls back to netlib Blas library which has worse performance.\n",
      "          A better performance should be easily gained by switching\n",
      "          Blas library.\n",
      "        if self._calc_info(blas):\n",
      "      INFO: blas_info:\n",
      "      INFO:   libraries blas not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      C:\\Users\\USUARIO\\AppData\\Local\\Temp\\pip-install-_l0zhw9o\\numpy_06fefd0f44e24a95965de3d18597992f\\numpy\\distutils\\system_info.py:2077: UserWarning:\n",
      "          Blas (http://www.netlib.org/blas/) libraries not found.\n",
      "          Directories to search for the libraries can be specified in the\n",
      "          numpy/distutils/site.cfg file (section [blas]) or by setting\n",
      "          the BLAS environment variable.\n",
      "        if self._calc_info(blas):\n",
      "      INFO: blas_src_info:\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      C:\\Users\\USUARIO\\AppData\\Local\\Temp\\pip-install-_l0zhw9o\\numpy_06fefd0f44e24a95965de3d18597992f\\numpy\\distutils\\system_info.py:2077: UserWarning:\n",
      "          Blas (http://www.netlib.org/blas/) sources not found.\n",
      "          Directories to search for the sources can be specified in the\n",
      "          numpy/distutils/site.cfg file (section [blas_src]) or by setting\n",
      "          the BLAS_SRC environment variable.\n",
      "        if self._calc_info(blas):\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      non-existing path in 'numpy\\\\distutils': 'site.cfg'\n",
      "      INFO: lapack_opt_info:\n",
      "      INFO: lapack_armpl_info:\n",
      "      INFO:   libraries armpl_lp64_mp not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: lapack_mkl_info:\n",
      "      INFO:   libraries mkl_rt not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: openblas_lapack_info:\n",
      "      INFO:   libraries openblas not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: openblas_clapack_info:\n",
      "      INFO:   libraries openblas,lapack not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: flame_info:\n",
      "      INFO:   libraries flame not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_3_10_threads_info:\n",
      "      INFO: Setting PTATLAS=ATLAS\n",
      "      INFO:   libraries tatlas,tatlas not found in C:\\Users\\USUARIO\\miniconda3\\lib\n",
      "      INFO:   libraries tatlas,tatlas not found in C:\\\n",
      "      INFO:   libraries tatlas,tatlas not found in C:\\Users\\USUARIO\\miniconda3\\libs\n",
      "      INFO: <class 'numpy.distutils.system_info.atlas_3_10_threads_info'>\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_3_10_info:\n",
      "      INFO:   libraries satlas,satlas not found in C:\\Users\\USUARIO\\miniconda3\\lib\n",
      "      INFO:   libraries satlas,satlas not found in C:\\\n",
      "      INFO:   libraries satlas,satlas not found in C:\\Users\\USUARIO\\miniconda3\\libs\n",
      "      INFO: <class 'numpy.distutils.system_info.atlas_3_10_info'>\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_threads_info:\n",
      "      INFO: Setting PTATLAS=ATLAS\n",
      "      INFO:   libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\USUARIO\\miniconda3\\lib\n",
      "      INFO:   libraries ptf77blas,ptcblas,atlas not found in C:\\\n",
      "      INFO:   libraries ptf77blas,ptcblas,atlas not found in C:\\Users\\USUARIO\\miniconda3\\libs\n",
      "      INFO: <class 'numpy.distutils.system_info.atlas_threads_info'>\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: atlas_info:\n",
      "      INFO:   libraries f77blas,cblas,atlas not found in C:\\Users\\USUARIO\\miniconda3\\lib\n",
      "      INFO:   libraries f77blas,cblas,atlas not found in C:\\\n",
      "      INFO:   libraries f77blas,cblas,atlas not found in C:\\Users\\USUARIO\\miniconda3\\libs\n",
      "      INFO: <class 'numpy.distutils.system_info.atlas_info'>\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: lapack_info:\n",
      "      INFO:   libraries lapack not found in ['C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\lib', 'C:\\\\', 'C:\\\\Users\\\\USUARIO\\\\miniconda3\\\\libs']\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      C:\\Users\\USUARIO\\AppData\\Local\\Temp\\pip-install-_l0zhw9o\\numpy_06fefd0f44e24a95965de3d18597992f\\numpy\\distutils\\system_info.py:1902: UserWarning:\n",
      "          Lapack (http://www.netlib.org/lapack/) libraries not found.\n",
      "          Directories to search for the libraries can be specified in the\n",
      "          numpy/distutils/site.cfg file (section [lapack]) or by setting\n",
      "          the LAPACK environment variable.\n",
      "        return getattr(self, '_calc_info_{}'.format(name))()\n",
      "      INFO: lapack_src_info:\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      C:\\Users\\USUARIO\\AppData\\Local\\Temp\\pip-install-_l0zhw9o\\numpy_06fefd0f44e24a95965de3d18597992f\\numpy\\distutils\\system_info.py:1902: UserWarning:\n",
      "          Lapack (http://www.netlib.org/lapack/) sources not found.\n",
      "          Directories to search for the sources can be specified in the\n",
      "          numpy/distutils/site.cfg file (section [lapack_src]) or by setting\n",
      "          the LAPACK_SRC environment variable.\n",
      "        return getattr(self, '_calc_info_{}'.format(name))()\n",
      "      INFO:   NOT AVAILABLE\n",
      "      INFO:\n",
      "      INFO: numpy_linalg_lapack_lite:\n",
      "      INFO:   FOUND:\n",
      "      INFO:     language = c\n",
      "      INFO:     define_macros = [('HAVE_BLAS_ILP64', None), ('BLAS_SYMBOL_SUFFIX', '64_')]\n",
      "      INFO:\n",
      "      Warning: attempted relative import with no known parent package\n",
      "      C:\\Users\\USUARIO\\AppData\\Local\\Temp\\pip-build-env-3e4cjsfx\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:275: UserWarning: Unknown distribution option: 'define_macros'\n",
      "        warnings.warn(msg)\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running config_cc\n",
      "      INFO: unifing config_cc, config, build_clib, build_ext, build commands --compiler options\n",
      "      running config_fc\n",
      "      INFO: unifing config_fc, config, build_clib, build_ext, build commands --fcompiler options\n",
      "      running build_src\n",
      "      INFO: build_src\n",
      "      INFO: building py_modules sources\n",
      "      creating build\n",
      "      creating build\\src.win-amd64-3.11\n",
      "      creating build\\src.win-amd64-3.11\\numpy\n",
      "      creating build\\src.win-amd64-3.11\\numpy\\distutils\n",
      "      INFO: building library \"npymath\" sources\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for numpy\n",
      "ERROR: Could not build wheels for numpy, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.5.3\n",
      "  Using cached pandas-1.5.3-cp311-cp311-win_amd64.whl (10.3 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from pandas==1.5.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from pandas==1.5.3) (2023.3.post1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from pandas==1.5.3) (2.1.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.3\n",
      "    Uninstalling pandas-2.2.3:\n",
      "      Successfully uninstalled pandas-2.2.3\n",
      "Successfully installed pandas-1.5.3\n"
     ]
    }
   ],
   "source": [
    "packages = [\n",
    "    \"torch==2.0.1\",\n",
    "    \"torch-geometric==2.3.1\",\n",
    "    \"numpy==1.23.0\",\n",
    "    \"pandas==1.5.3\"\n",
    "]\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Instalación de cada paquete uno por uno\n",
    "for package in packages:\n",
    "    !pip install {package}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\usuario\\miniconda3\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\miniconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\usuario\\miniconda3\\lib\\site-packages (1.5.3)\n",
      "Collecting pandas\n",
      "  Using cached pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\usuario\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.5.3\n",
      "    Uninstalling pandas-1.5.3:\n",
      "      Successfully uninstalled pandas-1.5.3\n",
      "Successfully installed pandas-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install --upgrade numpy pandas\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch.distributions import Categorical\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set input dates\n",
    "date = \"_2024-11-17\"\n",
    "truck = \"FLATBED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file name\n",
    "file_name1 = \"rate_q2_west_\"+truck+date+\".csv\"\n",
    "file_name2 = \"duration_west.csv\"\n",
    "file_name3 = \"prob_west_\"+truck+date+\".csv\"\n",
    "file_name4 = \"load_av_west_\"+truck+date+\".csv\"\n",
    "file_name5 = \"distance_west.csv\"\n",
    "file_name6 = \"diesel_west\"+date+\".csv\"\n",
    "file_name7 = \"labels_west.csv\"\n",
    "# Read the Excel file into a DataFrame\n",
    "rate_matrix = pd.read_csv(file_name1,header= None)\n",
    "time_matrix = pd.read_csv(file_name2,header = None)\n",
    "markov_matrix = pd.read_csv(file_name3,header=None)\n",
    "loads_matrix = pd.read_csv(file_name4,header=None)\n",
    "distance_matrix = pd.read_csv(file_name5,header=None)\n",
    "diesel_matrix = pd.read_csv(file_name6,header=None)\n",
    "hub_labels = pd.read_csv(file_name7,header=None)\n",
    "initial_node = 9\n",
    "time_limit = 45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_matrix = rate_matrix * distance_matrix\n",
    "revenue_matrix[loads_matrix <= 1] = 0\n",
    "diesel_matrix = diesel_matrix / 6\n",
    "cost_matrix = distance_matrix * diesel_matrix\n",
    "cost_matrix = cost_matrix + 163\n",
    "reward_matrix = revenue_matrix - cost_matrix\n",
    "time_matrix *= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEnvironment:\n",
    "    def __init__(self, reward_matrix, time_matrix, markov_matrix, initial_node, time_limit, loads_matrix):\n",
    "        self.reward_matrix = reward_matrix\n",
    "        self.time_matrix = time_matrix\n",
    "        self.markov_matrix = markov_matrix\n",
    "        self.initial_node = initial_node\n",
    "        self.time_limit = time_limit\n",
    "        self.loads_matrix = loads_matrix\n",
    "        self.num_nodes = reward_matrix.shape[0]\n",
    "        self.edge_index = self.generate_edge_index()\n",
    "        \n",
    "    def generate_edge_index(self):\n",
    "        edges = []\n",
    "        for i in range(self.num_nodes):\n",
    "            for j in range(self.num_nodes):\n",
    "                if i != j:\n",
    "                    edges.append((i, j))\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "        edge_index = edge_index[1]\n",
    "        return edge_index\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_node = self.initial_node\n",
    "        self.remaining_time = self.time_limit\n",
    "        self.visited_nodes = [self.initial_node]\n",
    "        self.visited_edges = []\n",
    "        self.total_reward = 0\n",
    "        return self.get_state()\n",
    "\n",
    "    def get_state(self):\n",
    "        return torch.tensor([self.current_node, self.remaining_time], dtype=torch.float32)\n",
    "\n",
    "    def is_terminal(self):\n",
    "        # Helper function for terminal conditions\n",
    "        return (self.remaining_time <= -self.time_limit * 0.5) and (self.current_node == self.initial_node)\n",
    "\n",
    "    def step(self, action):\n",
    "        next_node = action.item()\n",
    "        edge = (self.current_node, next_node)\n",
    "\n",
    "        if edge in self.visited_edges or self.current_node == next_node:\n",
    "            # Handle invalid moves (e.g., repeat or self-loop)\n",
    "            return self.get_state(), 0, False, {}, self.visited_nodes\n",
    "\n",
    "        self.visited_edges.append(edge)\n",
    "        reward = self.reward_matrix.iloc[self.current_node, next_node]\n",
    "        time_consumption = self.time_matrix.iloc[self.current_node, next_node]\n",
    "        self.total_reward += reward\n",
    "        self.remaining_time -= time_consumption\n",
    "        self.current_node = next_node\n",
    "        self.visited_nodes.append(next_node)\n",
    "\n",
    "        if self.is_terminal():\n",
    "            done = True\n",
    "            # Optionally include final rewards or reset if necessary\n",
    "            return self.get_state(), reward, done, {}, self.visited_nodes\n",
    "            \n",
    "        # Check if time to return to start\n",
    "        if -self.time_limit * 0.25 < self.remaining_time <= 0:\n",
    "            edge = (self.current_node, self.initial_node)\n",
    "            reward = self.reward_matrix.iloc[self.current_node, self.initial_node]\n",
    "            #loads = self.loads_matrix.iloc[self.current_node, self.initial_node]\n",
    "            time_consumption = self.time_matrix.iloc[self.current_node, self.initial_node]\n",
    "            self.total_reward += reward\n",
    "            self.remaining_time -= time_consumption\n",
    "            self.current_node = self.initial_node\n",
    "            self.visited_nodes.append(self.initial_node)\n",
    "            done = (self.current_node == self.initial_node)\n",
    "            return self.get_state(), reward, done, {},self.visited_nodes\n",
    "        elif (len(self.visited_nodes) == self.num_nodes) or (self.remaining_time <= -self.time_limit*0.25):\n",
    "            self.current_node = self.initial_node\n",
    "            self.remaining_time = self.time_limit\n",
    "            self.visited_nodes = [self.initial_node]\n",
    "            self.visited_edges = []\n",
    "            self.total_reward = 0\n",
    "            return self.get_state(), 0, False, {},self.visited_nodes\n",
    "\n",
    "        # Not terminal and valid move\n",
    "        return self.get_state(), reward, False, {}, self.visited_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention_weights = nn.Linear(hidden_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute attention scores and normalize\n",
    "        scores = self.attention_weights(x)\n",
    "        weights = F.softmax(scores, dim=1)\n",
    "        # Apply attention weights to the input\n",
    "        attended_output = torch.bmm(weights.transpose(1, 2), x).squeeze(1)\n",
    "        return attended_output\n",
    "\n",
    "class AttentionDQN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AttentionDQN, self).__init__()\n",
    "        \n",
    "        # Initial linear layers\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # Attention layers\n",
    "        self.attention_layer = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        # Final linear layers after attention\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        # Standard forward pass through initial layers\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        \n",
    "        # Attention mechanism\n",
    "        # Expand dimensions to create compatibility for bmm\n",
    "        x_expanded = x.unsqueeze(1)  # Shape: [batch_size, 1, hidden_size]\n",
    "        \n",
    "        attention_scores = F.softmax(self.attention_layer(x), dim=-1)  # Shape: [batch_size, hidden_size]\n",
    "        attention_scores = attention_scores.unsqueeze(2)  # Shape: [batch_size, hidden_size, 1]\n",
    "        \n",
    "        # Apply attention to the input\n",
    "        attended_output = torch.bmm(x_expanded, attention_scores).squeeze(2)  # Shape: [batch_size, hidden_size]\n",
    "        \n",
    "        # Continue forward pass after attention\n",
    "        x = F.relu(self.fc3(attended_output))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "    \n",
    "    class SimpleDQN(nn.Module):\n",
    "        def __init__(self, input_size, hidden_size, output_size):\n",
    "            super(SimpleDQN, self).__init__()\n",
    "            \n",
    "            # Input layer: maps input of size 2 to the hidden size\n",
    "            self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "            \n",
    "            # Attention layer: self-attention based mechanism to align with hidden size\n",
    "            self.attention_layer = nn.Linear(hidden_size, hidden_size)  # Matches the hidden dimension\n",
    "            self.attention_score = nn.Linear(hidden_size, 1)\n",
    "            \n",
    "            # Additional fully connected layers\n",
    "            self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "            self.fc3 = nn.Linear(hidden_size, output_size)  # Maps to the output size for Q-values\n",
    "            \n",
    "        def forward(self, x):\n",
    "            # First layer transformation\n",
    "            x = F.relu(self.fc1(x))  # Project input to hidden size\n",
    "            \n",
    "            # Attention mechanism\n",
    "            attention_scores = F.softmax(self.attention_score(x), dim=1)\n",
    "            attended_output = attention_scores * x  # Element-wise attention application\n",
    "            \n",
    "            # Process through the remaining layers\n",
    "            x = F.relu(self.fc2(attended_output))\n",
    "            return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "env = GraphEnvironment(reward_matrix, time_matrix, markov_matrix, initial_node, time_limit,loads_matrix)\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "gamma = 0.5\n",
    "epsilon_start = 1.0\n",
    "epsilon_decay = 0.995\n",
    "epsilon_min = 0.01\n",
    "num_episodes = 700\n",
    "hidden_size = env.num_nodes * (env.num_nodes - 1)  # Set according to number of arcs\n",
    "\n",
    "# Initialize the model with attention mechanism\n",
    "input_size = 2  # state dimensions: current node, remaining time\n",
    "output_size = len(env.edge_index)  # number of possible actions (edges)\n",
    "model = SimpleDQN(input_size, hidden_size, output_size)  # Using the new Attention DQN\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Set epsilon\n",
    "epsilon = epsilon_start\n",
    "\n",
    "# Action selection with epsilon-greedy policy\n",
    "def select_action(state, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        a_type = 1\n",
    "        options = env.markov_matrix.iloc[int(state[0].item())]\n",
    "        probabilities = options / options.sum()\n",
    "        action = torch.tensor(int(np.random.choice(options.index, p=probabilities.values) + ((state[0].item()) * (env.num_nodes - 1))))\n",
    "        return action, a_type\n",
    "    else:\n",
    "        with torch.no_grad():\n",
    "            q_values = model(state.unsqueeze(0))\n",
    "            a_type = 2\n",
    "            return q_values.argmax(dim=-1).unsqueeze(0), a_type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, Total Reward: 1909.2499999999998, Start Node: 9, Visited Nodes: [9, 12, 6, 11, 13, 37, 9]\n",
      "Episode 2, Total Reward: 8780.438333333332, Start Node: 9, Visited Nodes: [9, 12, 29, 16, 32, 17, 26, 9]\n",
      "Episode 3, Total Reward: 3826.675, Start Node: 9, Visited Nodes: [9, 7, 4, 1, 42, 41, 14, 1, 9]\n",
      "Episode 4, Total Reward: 2979.1450000000004, Start Node: 9, Visited Nodes: [9, 12, 11, 9, 7, 10, 27, 7, 12, 9]\n",
      "Episode 5, Total Reward: 3476.9033333333327, Start Node: 9, Visited Nodes: [9, 7, 12, 10, 13, 36, 13, 16, 9]\n",
      "Episode 6, Total Reward: 4422.581666666667, Start Node: 9, Visited Nodes: [9, 12, 34, 14, 36, 33, 37, 9]\n",
      "Episode 7, Total Reward: 4220.966666666666, Start Node: 9, Visited Nodes: [9, 7, 12, 6, 13, 16, 39, 9]\n",
      "Episode 8, Total Reward: 5881.615000000001, Start Node: 9, Visited Nodes: [9, 7, 5, 0, 6, 41, 9]\n",
      "Episode 9, Total Reward: 5737.081666666666, Start Node: 9, Visited Nodes: [9, 12, 8, 10, 7, 10, 6, 34, 27, 6, 9]\n",
      "Episode 10, Total Reward: 6229.594999999999, Start Node: 9, Visited Nodes: [9, 26, 12, 10, 13, 28, 9]\n",
      "Episode 11, Total Reward: 4074.4300000000003, Start Node: 9, Visited Nodes: [9, 12, 11, 9, 7, 12, 10, 9, 34, 33, 37, 9]\n",
      "Episode 12, Total Reward: 3987.451666666667, Start Node: 9, Visited Nodes: [9, 12, 6, 13, 16, 31, 9]\n",
      "Episode 13, Total Reward: 4869.54, Start Node: 9, Visited Nodes: [9, 7, 6, 12, 6, 10, 6, 13, 15, 9]\n",
      "Episode 14, Total Reward: 2438.91, Start Node: 9, Visited Nodes: [9, 12, 10, 13, 16, 27, 25, 9]\n",
      "Episode 15, Total Reward: 8190.028333333334, Start Node: 9, Visited Nodes: [9, 12, 10, 8, 10, 33, 14, 16, 9]\n",
      "Episode 16, Total Reward: 5389.498333333334, Start Node: 9, Visited Nodes: [9, 12, 13, 37, 31, 9]\n",
      "Episode 17, Total Reward: 4387.708333333333, Start Node: 9, Visited Nodes: [9, 33, 40, 25, 5, 0, 9]\n",
      "Episode 18, Total Reward: 2452.5599999999995, Start Node: 9, Visited Nodes: [9, 4, 6, 27, 2, 9]\n",
      "Episode 19, Total Reward: 4492.975, Start Node: 9, Visited Nodes: [9, 7, 33, 27, 8, 6, 31, 19, 9]\n",
      "Episode 20, Total Reward: 3569.706666666667, Start Node: 9, Visited Nodes: [9, 8, 7, 10, 13, 32, 9]\n",
      "Episode 21, Total Reward: 8900.246666666666, Start Node: 9, Visited Nodes: [9, 26, 33, 8, 13, 9]\n",
      "Episode 22, Total Reward: 3904.45, Start Node: 9, Visited Nodes: [9, 12, 6, 12, 13, 37, 9]\n",
      "Episode 23, Total Reward: 5024.26, Start Node: 9, Visited Nodes: [9, 11, 9, 7, 11, 7, 9, 12, 26, 39, 32, 12, 9]\n",
      "Episode 24, Total Reward: 2842.0999999999995, Start Node: 9, Visited Nodes: [9, 11, 13, 51, 54, 9]\n",
      "Episode 25, Total Reward: 5789.335, Start Node: 9, Visited Nodes: [9, 12, 8, 12, 10, 27, 2, 5, 0, 15, 9]\n",
      "Episode 26, Total Reward: 3113.5466666666666, Start Node: 9, Visited Nodes: [9, 27, 12, 6, 12, 31, 33, 9]\n",
      "Episode 27, Total Reward: 3385.3599999999997, Start Node: 9, Visited Nodes: [9, 7, 10, 27, 4, 0, 6, 9]\n",
      "Episode 28, Total Reward: 4820.123333333333, Start Node: 9, Visited Nodes: [9, 12, 9, 5, 3, 2, 28, 9]\n",
      "Episode 29, Total Reward: 3636.9816666666657, Start Node: 9, Visited Nodes: [9, 8, 11, 0, 54, 9]\n",
      "Episode 30, Total Reward: 3547.2916666666674, Start Node: 9, Visited Nodes: [9, 12, 27, 14, 16, 19, 32, 9]\n",
      "Episode 31, Total Reward: 3153.5299999999993, Start Node: 9, Visited Nodes: [9, 51, 54, 9]\n",
      "Episode 32, Total Reward: 6039.033333333333, Start Node: 9, Visited Nodes: [9, 13, 16, 32, 20, 32, 9]\n",
      "Episode 33, Total Reward: 2699.8349999999996, Start Node: 9, Visited Nodes: [9, 12, 10, 13, 16, 1, 9]\n",
      "Episode 34, Total Reward: 6556.343333333333, Start Node: 9, Visited Nodes: [9, 12, 10, 27, 9, 51, 9]\n",
      "Episode 35, Total Reward: 4138.699999999999, Start Node: 9, Visited Nodes: [9, 1, 13, 33, 9, 12, 7, 9]\n",
      "Episode 36, Total Reward: 3018.9633333333336, Start Node: 9, Visited Nodes: [9, 7, 4, 52, 9]\n",
      "Episode 37, Total Reward: 4380.328333333333, Start Node: 9, Visited Nodes: [9, 32, 41, 5, 9]\n",
      "Episode 38, Total Reward: 3519.828333333334, Start Node: 9, Visited Nodes: [9, 7, 32, 41, 14, 16, 9]\n",
      "Episode 39, Total Reward: 13628.25166666667, Start Node: 9, Visited Nodes: [9, 12, 9, 7, 32, 12, 27, 9]\n",
      "Episode 40, Total Reward: 2671.4949999999994, Start Node: 9, Visited Nodes: [9, 12, 41, 27, 11, 9]\n",
      "Episode 41, Total Reward: 6160.243333333333, Start Node: 9, Visited Nodes: [9, 12, 33, 36, 11, 9, 41, 9]\n",
      "Episode 42, Total Reward: 4367.498333333333, Start Node: 9, Visited Nodes: [9, 12, 6, 32, 28, 33, 24, 1, 9]\n",
      "Episode 43, Total Reward: 4926.026666666667, Start Node: 9, Visited Nodes: [9, 12, 9, 7, 31, 38, 32, 10, 9]\n",
      "Episode 44, Total Reward: 3382.4466666666667, Start Node: 9, Visited Nodes: [9, 12, 27, 41, 14, 16, 41, 9]\n",
      "Episode 45, Total Reward: 3401.4100000000003, Start Node: 9, Visited Nodes: [9, 41, 14, 37, 31, 39, 32, 9]\n",
      "Episode 46, Total Reward: 6423.273333333334, Start Node: 9, Visited Nodes: [9, 7, 10, 6, 10, 8, 6, 27, 39, 32, 9]\n",
      "Episode 47, Total Reward: 7978.508333333332, Start Node: 9, Visited Nodes: [9, 12, 11, 39, 32, 39, 31, 9]\n",
      "Episode 48, Total Reward: 9169.679999999998, Start Node: 9, Visited Nodes: [9, 2, 39, 38, 32, 39, 41, 9]\n",
      "Episode 49, Total Reward: 6539.929999999999, Start Node: 9, Visited Nodes: [9, 12, 27, 7, 12, 39, 9]\n",
      "Episode 50, Total Reward: 2357.2499999999995, Start Node: 9, Visited Nodes: [9, 12, 8, 10, 13, 42, 33, 12, 9]\n",
      "Episode 51, Total Reward: 3938.158333333333, Start Node: 9, Visited Nodes: [9, 12, 31, 41, 15, 11, 9]\n",
      "Episode 52, Total Reward: 5712.253333333332, Start Node: 9, Visited Nodes: [9, 12, 39, 38, 6, 13, 9]\n",
      "Episode 53, Total Reward: 10777.563333333334, Start Node: 9, Visited Nodes: [9, 12, 6, 41, 13, 16, 9]\n",
      "Episode 54, Total Reward: 4144.871666666667, Start Node: 9, Visited Nodes: [9, 12, 6, 13, 15, 13, 16, 9]\n",
      "Episode 55, Total Reward: 1503.6799999999998, Start Node: 9, Visited Nodes: [9, 12, 13, 16, 13, 9]\n",
      "Episode 56, Total Reward: 3555.0016666666666, Start Node: 9, Visited Nodes: [9, 12, 32, 19, 34, 15, 9]\n",
      "Episode 57, Total Reward: 9762.936666666666, Start Node: 9, Visited Nodes: [9, 39, 32, 41, 36, 9]\n",
      "Episode 58, Total Reward: 5963.321666666668, Start Node: 9, Visited Nodes: [9, 12, 41, 14, 37, 9]\n",
      "Episode 59, Total Reward: 5200.3566666666675, Start Node: 9, Visited Nodes: [9, 7, 9, 12, 6, 27, 5, 37, 9]\n",
      "Episode 60, Total Reward: 1340.7399999999998, Start Node: 9, Visited Nodes: [9, 33, 37, 41, 13, 9]\n",
      "Episode 61, Total Reward: 4898.951666666666, Start Node: 9, Visited Nodes: [9, 12, 6, 39, 41, 14, 51, 9]\n",
      "Episode 62, Total Reward: 2967.806666666667, Start Node: 9, Visited Nodes: [9, 33, 41, 14, 42, 33, 4, 9]\n",
      "Episode 63, Total Reward: 5028.4333333333325, Start Node: 9, Visited Nodes: [9, 12, 33, 37, 31, 41, 9]\n",
      "Episode 64, Total Reward: 3250.078333333333, Start Node: 9, Visited Nodes: [9, 7, 12, 8, 10, 13, 16, 22, 9]\n",
      "Episode 65, Total Reward: 4985.424999999999, Start Node: 9, Visited Nodes: [9, 33, 38, 41, 35, 9]\n",
      "Episode 66, Total Reward: 6917.5633333333335, Start Node: 9, Visited Nodes: [9, 7, 12, 10, 33, 18, 51, 9]\n",
      "Episode 67, Total Reward: 3176.2533333333336, Start Node: 9, Visited Nodes: [9, 7, 10, 7, 6, 33, 37, 23, 27, 9]\n",
      "Episode 68, Total Reward: 3508.6566666666663, Start Node: 9, Visited Nodes: [9, 12, 37, 19, 51, 9]\n",
      "Episode 69, Total Reward: 3802.963333333333, Start Node: 9, Visited Nodes: [9, 12, 51, 48, 9]\n",
      "Episode 70, Total Reward: 2611.791666666667, Start Node: 9, Visited Nodes: [9, 51, 41, 14, 18, 9]\n",
      "Episode 71, Total Reward: 7394.401666666668, Start Node: 9, Visited Nodes: [9, 7, 10, 13, 16, 41, 9]\n",
      "Episode 72, Total Reward: 5230.701666666667, Start Node: 9, Visited Nodes: [9, 12, 27, 13, 15, 13, 31, 9]\n",
      "Episode 73, Total Reward: 5246.466666666667, Start Node: 9, Visited Nodes: [9, 8, 7, 33, 31, 20, 31, 38, 28, 26, 9]\n",
      "Episode 74, Total Reward: 4165.245, Start Node: 9, Visited Nodes: [9, 12, 10, 33, 31, 19, 1, 9]\n",
      "Episode 75, Total Reward: 9975.565, Start Node: 9, Visited Nodes: [9, 7, 33, 31, 39, 31, 41, 9]\n",
      "Episode 76, Total Reward: 3957.3149999999996, Start Node: 9, Visited Nodes: [9, 31, 41, 14, 16, 9]\n",
      "Episode 77, Total Reward: 13327.745, Start Node: 9, Visited Nodes: [9, 12, 37, 31, 33, 37, 39, 9]\n",
      "Episode 78, Total Reward: 4422.789999999999, Start Node: 9, Visited Nodes: [9, 7, 12, 2, 1, 10, 13, 9]\n",
      "Episode 79, Total Reward: 2500.923333333333, Start Node: 9, Visited Nodes: [9, 33, 41, 30, 6, 28, 9]\n",
      "Episode 80, Total Reward: 3390.3516666666665, Start Node: 9, Visited Nodes: [9, 7, 29, 31, 41, 34, 9]\n",
      "Episode 81, Total Reward: 3320.3583333333336, Start Node: 9, Visited Nodes: [9, 1, 6, 8, 7, 12, 41, 9]\n",
      "Episode 82, Total Reward: 2580.451666666666, Start Node: 9, Visited Nodes: [9, 33, 14, 42, 40, 31, 6, 9]\n",
      "Episode 83, Total Reward: 4615.916666666666, Start Node: 9, Visited Nodes: [9, 6, 29, 10, 41, 9]\n",
      "Episode 84, Total Reward: 4886.29, Start Node: 9, Visited Nodes: [9, 33, 30, 27, 15, 9]\n",
      "Episode 85, Total Reward: 2578.4199999999996, Start Node: 9, Visited Nodes: [9, 12, 7, 29, 28, 11, 9]\n",
      "Episode 86, Total Reward: 6290.128333333334, Start Node: 9, Visited Nodes: [9, 8, 6, 41, 15, 11, 9]\n",
      "Episode 87, Total Reward: 2908.6049999999996, Start Node: 9, Visited Nodes: [9, 29, 10, 41, 9]\n",
      "Episode 88, Total Reward: 6832.106666666666, Start Node: 9, Visited Nodes: [9, 12, 33, 36, 41, 14, 41, 0, 9]\n",
      "Episode 89, Total Reward: 3321.5800000000004, Start Node: 9, Visited Nodes: [9, 7, 10, 8, 40, 7, 33, 9]\n",
      "Episode 90, Total Reward: 2956.3399999999992, Start Node: 9, Visited Nodes: [9, 12, 9, 11, 2, 6, 41, 9]\n",
      "Episode 91, Total Reward: 4404.191666666667, Start Node: 9, Visited Nodes: [9, 7, 41, 1, 0, 6, 9]\n",
      "Episode 92, Total Reward: 8835.746666666668, Start Node: 9, Visited Nodes: [9, 41, 43, 31, 41, 9]\n",
      "Episode 93, Total Reward: 7711.920000000001, Start Node: 9, Visited Nodes: [9, 33, 42, 1, 6, 9]\n",
      "Episode 94, Total Reward: 5198.259999999999, Start Node: 9, Visited Nodes: [9, 12, 9, 39, 38, 41, 9]\n",
      "Episode 95, Total Reward: 8290.455, Start Node: 9, Visited Nodes: [9, 12, 6, 33, 16, 41, 14, 16, 9]\n",
      "Episode 96, Total Reward: 2860.0183333333325, Start Node: 9, Visited Nodes: [9, 12, 33, 37, 36, 41, 9]\n",
      "Episode 97, Total Reward: 6048.701666666667, Start Node: 9, Visited Nodes: [9, 7, 2, 33, 37, 31, 41, 9]\n",
      "Episode 98, Total Reward: 2256.5049999999997, Start Node: 9, Visited Nodes: [9, 12, 41, 8, 9]\n",
      "Episode 99, Total Reward: 2745.248333333333, Start Node: 9, Visited Nodes: [9, 33, 14, 37, 29, 24, 9]\n",
      "Episode 100, Total Reward: 4246.496666666667, Start Node: 9, Visited Nodes: [9, 33, 36, 41, 2, 42, 9]\n",
      "Episode 101, Total Reward: 12462.016666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 102, Total Reward: 3619.505, Start Node: 9, Visited Nodes: [9, 41, 33, 36, 33, 9, 12, 9]\n",
      "Episode 103, Total Reward: 3078.933333333333, Start Node: 9, Visited Nodes: [9, 5, 41, 52, 9]\n",
      "Episode 104, Total Reward: 3535.368333333333, Start Node: 9, Visited Nodes: [9, 12, 10, 41, 52, 9]\n",
      "Episode 105, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 106, Total Reward: 3120.3900000000003, Start Node: 9, Visited Nodes: [9, 41, 13, 37, 31, 9]\n",
      "Episode 107, Total Reward: 3895.5616666666665, Start Node: 9, Visited Nodes: [9, 7, 41, 52, 9]\n",
      "Episode 108, Total Reward: 4607.716666666667, Start Node: 9, Visited Nodes: [9, 7, 10, 6, 41, 52, 9]\n",
      "Episode 109, Total Reward: 3678.2749999999996, Start Node: 9, Visited Nodes: [9, 12, 41, 52, 9]\n",
      "Episode 110, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 111, Total Reward: 2732.7899999999995, Start Node: 9, Visited Nodes: [9, 12, 41, 11, 9, 9]\n",
      "Episode 112, Total Reward: 3328.711666666666, Start Node: 9, Visited Nodes: [9, 34, 54, 9]\n",
      "Episode 113, Total Reward: 6961.5633333333335, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 114, Total Reward: 5111.471666666666, Start Node: 9, Visited Nodes: [9, 34, 6, 41, 14, 9]\n",
      "Episode 115, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 116, Total Reward: 6595.278333333334, Start Node: 9, Visited Nodes: [9, 41, 6, 8, 11, 9]\n",
      "Episode 117, Total Reward: 3859.095, Start Node: 9, Visited Nodes: [9, 7, 12, 41, 52, 9]\n",
      "Episode 118, Total Reward: 3678.2749999999996, Start Node: 9, Visited Nodes: [9, 12, 41, 52, 9]\n",
      "Episode 119, Total Reward: 5183.964999999999, Start Node: 9, Visited Nodes: [9, 41, 2, 1, 41, 9]\n",
      "Episode 120, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 121, Total Reward: 6125.029999999999, Start Node: 9, Visited Nodes: [9, 5, 41, 52, 9]\n",
      "Episode 122, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 123, Total Reward: 3746.8466666666664, Start Node: 9, Visited Nodes: [9, 41, 14, 41, 2, 10, 9]\n",
      "Episode 124, Total Reward: 3058.878333333333, Start Node: 9, Visited Nodes: [9, 7, 1, 6, 41, 9]\n",
      "Episode 125, Total Reward: 2428.225, Start Node: 9, Visited Nodes: [9, 12, 41, 28, 38, 9]\n",
      "Episode 126, Total Reward: 3413.7583333333337, Start Node: 9, Visited Nodes: [9, 41, 6, 27, 9]\n",
      "Episode 127, Total Reward: 6801.6883333333335, Start Node: 9, Visited Nodes: [9, 7, 10, 9, 41, 52, 9]\n",
      "Episode 128, Total Reward: 3289.25, Start Node: 9, Visited Nodes: [9, 12, 21, 45, 9]\n",
      "Episode 129, Total Reward: 5691.639999999999, Start Node: 9, Visited Nodes: [9, 12, 9, 41, 14, 42, 41, 13, 9]\n",
      "Episode 130, Total Reward: 7738.985000000001, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 131, Total Reward: 6386.523333333333, Start Node: 9, Visited Nodes: [9, 41, 46, 52, 9]\n",
      "Episode 132, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 133, Total Reward: 6947.208333333334, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 134, Total Reward: 10931.001666666667, Start Node: 9, Visited Nodes: [9, 41, 21, 42, 53, 9]\n",
      "Episode 135, Total Reward: 18790.27, Start Node: 9, Visited Nodes: [9, 42, 54, 9]\n",
      "Episode 136, Total Reward: 3173.9699999999993, Start Node: 9, Visited Nodes: [9, 12, 41, 11, 7, 9]\n",
      "Episode 137, Total Reward: 3744.6466666666665, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 138, Total Reward: 3673.8266666666664, Start Node: 9, Visited Nodes: [9, 41, 14, 41, 52, 9]\n",
      "Episode 139, Total Reward: 6133.348333333333, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 140, Total Reward: 3058.1516666666666, Start Node: 9, Visited Nodes: [9, 12, 10, 30, 12, 11, 44, 9]\n",
      "Episode 141, Total Reward: 5819.9, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 142, Total Reward: 4478.866666666666, Start Node: 9, Visited Nodes: [9, 7, 1, 0, 6, 13, 9]\n",
      "Episode 143, Total Reward: 12239.645, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 144, Total Reward: 7362.268333333333, Start Node: 9, Visited Nodes: [9, 12, 33, 31, 28, 7, 10, 9]\n",
      "Episode 145, Total Reward: 7876.428333333333, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 146, Total Reward: 7074.52, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 147, Total Reward: 7024.913333333333, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 148, Total Reward: 1432.8816666666662, Start Node: 9, Visited Nodes: [9, 42, 8, 13, 9]\n",
      "Episode 149, Total Reward: 5819.9, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 150, Total Reward: 4545.171666666667, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 151, Total Reward: 7132.33, Start Node: 9, Visited Nodes: [9, 12, 41, 52, 9]\n",
      "Episode 152, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 153, Total Reward: 9636.266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 154, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 155, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 156, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 157, Total Reward: 8355.458333333334, Start Node: 9, Visited Nodes: [9, 41, 21, 44, 9]\n",
      "Episode 158, Total Reward: 14105.588333333335, Start Node: 9, Visited Nodes: [9, 12, 32, 39, 38, 44, 9]\n",
      "Episode 159, Total Reward: 3059.376666666667, Start Node: 9, Visited Nodes: [9, 12, 27, 44, 46, 9]\n",
      "Episode 160, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 161, Total Reward: 3762.1383333333333, Start Node: 9, Visited Nodes: [9, 12, 41, 1, 6, 9]\n",
      "Episode 162, Total Reward: 12241.146666666667, Start Node: 9, Visited Nodes: [9, 7, 41, 1, 41, 9]\n",
      "Episode 163, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 164, Total Reward: 4067.9066666666677, Start Node: 9, Visited Nodes: [9, 41, 13, 34, 27, 9, 9]\n",
      "Episode 165, Total Reward: 3431.2816666666663, Start Node: 9, Visited Nodes: [9, 7, 41, 11, 1, 9]\n",
      "Episode 166, Total Reward: 3312.425, Start Node: 9, Visited Nodes: [9, 41, 1, 10, 9]\n",
      "Episode 167, Total Reward: 11258.18, Start Node: 9, Visited Nodes: [9, 41, 1, 4, 41, 9]\n",
      "Episode 168, Total Reward: 3287.0133333333333, Start Node: 9, Visited Nodes: [9, 41, 6, 1, 9]\n",
      "Episode 169, Total Reward: 3978.8916666666664, Start Node: 9, Visited Nodes: [9, 41, 14, 13, 1, 41, 9]\n",
      "Episode 170, Total Reward: 3312.425, Start Node: 9, Visited Nodes: [9, 41, 1, 10, 9]\n",
      "Episode 171, Total Reward: 2946.341666666666, Start Node: 9, Visited Nodes: [9, 12, 41, 7, 10, 9]\n",
      "Episode 172, Total Reward: 3156.1066666666666, Start Node: 9, Visited Nodes: [9, 7, 10, 6, 41, 2, 9]\n",
      "Episode 173, Total Reward: 2887.583333333333, Start Node: 9, Visited Nodes: [9, 41, 45, 1, 9]\n",
      "Episode 174, Total Reward: 4174.323333333333, Start Node: 9, Visited Nodes: [9, 12, 41, 15, 1, 41, 9]\n",
      "Episode 175, Total Reward: 3588.46, Start Node: 9, Visited Nodes: [9, 41, 33, 1, 41, 9]\n",
      "Episode 176, Total Reward: 4062.085, Start Node: 9, Visited Nodes: [9, 12, 41, 1, 41, 9]\n",
      "Episode 177, Total Reward: 5184.766666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 4, 1, 3, 9]\n",
      "Episode 178, Total Reward: 3611.8900000000003, Start Node: 9, Visited Nodes: [9, 41, 1, 6, 9]\n",
      "Episode 179, Total Reward: 2854.45, Start Node: 9, Visited Nodes: [9, 12, 1, 0, 41, 1, 9]\n",
      "Episode 180, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 181, Total Reward: 4341.845, Start Node: 9, Visited Nodes: [9, 41, 1, 28, 9]\n",
      "Episode 182, Total Reward: 6930.564999999999, Start Node: 9, Visited Nodes: [9, 41, 9, 7, 12, 6, 9]\n",
      "Episode 183, Total Reward: 4086.3699999999994, Start Node: 9, Visited Nodes: [9, 41, 36, 35, 6, 11, 9]\n",
      "Episode 184, Total Reward: 3616.771666666667, Start Node: 9, Visited Nodes: [9, 41, 15, 6, 27, 9]\n",
      "Episode 185, Total Reward: 6895.731666666667, Start Node: 9, Visited Nodes: [9, 1, 26, 1, 41, 9]\n",
      "Episode 186, Total Reward: 3177.581666666666, Start Node: 9, Visited Nodes: [9, 12, 6, 8, 41, 6, 9]\n",
      "Episode 187, Total Reward: 3757.6899999999996, Start Node: 9, Visited Nodes: [9, 41, 14, 41, 1, 6, 9]\n",
      "Episode 188, Total Reward: 3418.6383333333333, Start Node: 9, Visited Nodes: [9, 41, 33, 15, 1, 9]\n",
      "Episode 189, Total Reward: 3949.243333333333, Start Node: 9, Visited Nodes: [9, 7, 10, 41, 1, 41, 9]\n",
      "Episode 190, Total Reward: 3979.425, Start Node: 9, Visited Nodes: [9, 7, 41, 1, 6, 9]\n",
      "Episode 191, Total Reward: 8183.8116666666665, Start Node: 9, Visited Nodes: [9, 41, 1, 0, 41, 9]\n",
      "Episode 192, Total Reward: 3528.0266666666666, Start Node: 9, Visited Nodes: [9, 41, 52, 9]\n",
      "Episode 193, Total Reward: 1631.6233333333334, Start Node: 9, Visited Nodes: [9, 1, 4, 13, 34, 1, 41, 9]\n",
      "Episode 194, Total Reward: 4035.3399999999997, Start Node: 9, Visited Nodes: [9, 11, 9, 12, 41, 14, 37, 9]\n",
      "Episode 195, Total Reward: 3830.7233333333334, Start Node: 9, Visited Nodes: [9, 12, 41, 14, 1, 6, 9]\n",
      "Episode 196, Total Reward: 4522.961666666667, Start Node: 9, Visited Nodes: [9, 7, 9, 41, 1, 41, 9]\n",
      "Episode 197, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 198, Total Reward: 3611.8900000000003, Start Node: 9, Visited Nodes: [9, 41, 1, 6, 9]\n",
      "Episode 199, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 200, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 201, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 202, Total Reward: 7533.4349999999995, Start Node: 9, Visited Nodes: [9, 12, 41, 1, 41, 9]\n",
      "Episode 203, Total Reward: 7321.933333333333, Start Node: 9, Visited Nodes: [9, 12, 16, 29, 1, 41, 9]\n",
      "Episode 204, Total Reward: 3742.808333333333, Start Node: 9, Visited Nodes: [9, 7, 10, 41, 1, 3, 9]\n",
      "Episode 205, Total Reward: 3462.673333333333, Start Node: 9, Visited Nodes: [9, 12, 41, 1, 10, 9]\n",
      "Episode 206, Total Reward: 4279.371666666667, Start Node: 9, Visited Nodes: [9, 7, 41, 1, 41, 9]\n",
      "Episode 207, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 208, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 209, Total Reward: 3481.6016666666665, Start Node: 9, Visited Nodes: [9, 12, 8, 10, 41, 13, 1, 9]\n",
      "Episode 210, Total Reward: 6991.599999999999, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 211, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 212, Total Reward: 4062.085, Start Node: 9, Visited Nodes: [9, 12, 41, 1, 41, 9]\n",
      "Episode 213, Total Reward: 3611.8900000000003, Start Node: 9, Visited Nodes: [9, 41, 1, 6, 9]\n",
      "Episode 214, Total Reward: 7120.526666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 215, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 216, Total Reward: 4034.353333333333, Start Node: 9, Visited Nodes: [9, 12, 41, 13, 1, 0, 10, 9]\n",
      "Episode 217, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 218, Total Reward: 3149.076666666667, Start Node: 9, Visited Nodes: [9, 41, 23, 1, 9]\n",
      "Episode 219, Total Reward: 7898.135, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 220, Total Reward: 10339.165, Start Node: 9, Visited Nodes: [9, 41, 14, 41, 1, 6, 9]\n",
      "Episode 221, Total Reward: 3500.7766666666666, Start Node: 9, Visited Nodes: [9, 41, 22, 1, 9]\n",
      "Episode 222, Total Reward: 4651.665, Start Node: 9, Visited Nodes: [9, 41, 13, 51, 15, 9]\n",
      "Episode 223, Total Reward: 4062.085, Start Node: 9, Visited Nodes: [9, 12, 41, 1, 41, 9]\n",
      "Episode 224, Total Reward: 2929.785, Start Node: 9, Visited Nodes: [9, 41, 47, 1, 9]\n",
      "Episode 225, Total Reward: 4421.303333333333, Start Node: 9, Visited Nodes: [9, 41, 1, 0, 5, 41, 9]\n",
      "Episode 226, Total Reward: 4062.085, Start Node: 9, Visited Nodes: [9, 12, 41, 1, 41, 9]\n",
      "Episode 227, Total Reward: 4877.8533333333335, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 228, Total Reward: 3982.4283333333333, Start Node: 9, Visited Nodes: [9, 7, 2, 41, 1, 41, 9]\n",
      "Episode 229, Total Reward: 3112.9566666666665, Start Node: 9, Visited Nodes: [9, 41, 14, 8, 11, 9]\n",
      "Episode 230, Total Reward: 3578.7999999999997, Start Node: 9, Visited Nodes: [9, 39, 1, 0, 9]\n",
      "Episode 231, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 232, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 233, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 234, Total Reward: 3911.836666666667, Start Node: 9, Visited Nodes: [9, 41, 1, 41, 9]\n",
      "Episode 235, Total Reward: 6836.176666666667, Start Node: 9, Visited Nodes: [9, 41, 14, 34, 1, 34, 36, 9]\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for i in [9]:  # Iterate through each possible starting node\n",
    "    stop_counter = 0\n",
    "    best_reward = 0\n",
    "    last_reward = 0\n",
    "    epsilon = epsilon_start\n",
    "    episode = 0\n",
    "    patience_counter = 150\n",
    "\n",
    "    while stop_counter < 10 and episode < num_episodes and epsilon > epsilon_min and patience_counter > 0:\n",
    "        initial_node = i\n",
    "        env = GraphEnvironment(reward_matrix, time_matrix, markov_matrix, initial_node, time_limit, loads_matrix)\n",
    "        state = env.reset()\n",
    "        done = False\n",
    "        total_reward = 0\n",
    "\n",
    "        # Adjust epsilon for each episode\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "\n",
    "        while not done:\n",
    "            # Choose an action using epsilon-greedy policy\n",
    "            action, _ = select_action(state, epsilon)\n",
    "            new_node = env.edge_index[action.item()]\n",
    "\n",
    "            # Execute the action in the environment\n",
    "            next_state, reward, done, _, visited_nodes = env.step(new_node)\n",
    "            total_reward += reward\n",
    "\n",
    "            # Calculate the target\n",
    "            with torch.no_grad():\n",
    "                # Reshape `next_state` to fit the model's expected input (batch size, feature size)\n",
    "                next_state_expanded = next_state.unsqueeze(0)  # Adding batch dimension if needed\n",
    "\n",
    "                # Compute target\n",
    "                if done:\n",
    "                    target = torch.tensor(reward, dtype=torch.float32)\n",
    "                else:\n",
    "                    next_q_values = model(next_state_expanded)  # Predict Q-values for the next state\n",
    "                    max_next_q_value = next_q_values.max()  # Get the max Q-value for the best action in the next state\n",
    "                    target = torch.tensor(reward, dtype=torch.float32) + gamma * max_next_q_value\n",
    "\n",
    "\n",
    "            # Update model based on state-action pair and loss\n",
    "            state_expanded = state.unsqueeze(0)\n",
    "            q_values = model(state_expanded).squeeze(0)\n",
    "            loss = loss_fn(q_values[action.item()].float(), target.float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update state for the next step\n",
    "            state = next_state\n",
    "\n",
    "        # Check for reward improvement and update stopping criteria\n",
    "        if total_reward > best_reward:\n",
    "            patience_counter = 100 if total_reward > best_reward * 1.1 else patience_counter - 1\n",
    "            best_reward = total_reward\n",
    "        else:\n",
    "            patience_counter -= 1\n",
    "\n",
    "        stop_counter = stop_counter + 1 if last_reward == total_reward else 0\n",
    "        last_reward = total_reward\n",
    "\n",
    "        # Print progress\n",
    "        print(f\"Episode {episode + 1}, Total Reward: {total_reward}, Start Node: {i}, Visited Nodes: {visited_nodes}\")\n",
    "        episode += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display Results and Route Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_days(route, time_matrix):\n",
    "  total_time = 0\n",
    "  for i in range(0,len(route)-1):\n",
    "    lane_time = time_matrix.iloc[route[i],route[i+1]]\n",
    "    total_time = total_time + lane_time + 2\n",
    "  days = int(np.floor(total_time / 11))\n",
    "  return days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_route (route,hub_labels):\n",
    "  visualized_route = []\n",
    "  for i in range(0,len(route)):\n",
    "    name = hub_labels.at[route[i], 0]\n",
    "    visualized_route.append(name)\n",
    "  return visualized_route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best(route, reward, best_profits, most_profit_routes):\n",
    "    if reward > best_profits.min():\n",
    "        # Find the index of the lowest value in best_profits\n",
    "        min_index = best_profits.idxmin()\n",
    "        \n",
    "        # Replace the lowest value with the new reward\n",
    "        best_profits[min_index] = reward\n",
    "        \n",
    "        # Replace the corresponding route in most_profit_routes\n",
    "        most_profit_routes[min_index] = route\n",
    "        \n",
    "    return best_profits, most_profit_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n",
      "Route: ['Los Angeles (CA)', 'Cheyenne (WY)', 'Delta (CO)', 'Chandler (AZ)', 'Fresno (CA)', 'Los Angeles (CA)'] Profit: 4177.991666666667 Feasible: 1\n"
     ]
    }
   ],
   "source": [
    "type1=0\n",
    "type2=0\n",
    "type3=0\n",
    "type4=0\n",
    "# Inference loop\n",
    "for i in [9]:\n",
    "    for j in range(0,50):\n",
    "      taken_actions = []\n",
    "      time_limit = 55\n",
    "      # Reset environment to get initial state\n",
    "      # Initialize environment\n",
    "      initial_node=i\n",
    "      env = GraphEnvironment(reward_matrix, time_matrix, markov_matrix, initial_node, time_limit,loads_matrix)\n",
    "      state = env.reset()\n",
    "      # Episode loop\n",
    "      done = False\n",
    "      q_values = model(state.unsqueeze(0))\n",
    "      while not done:\n",
    "          # Select action using the trained model\n",
    "          with torch.no_grad():\n",
    "              q_values = model(state.unsqueeze(0))\n",
    "              # Apply action mask to zero out probabilities of previously taken actions\n",
    "              action_mask = torch.zeros_like(q_values)\n",
    "              # Set probabilities of previously taken actions to -infinity\n",
    "              action_mask[0,taken_actions] = float('-1000000')\n",
    "              masked_q_values = q_values + action_mask\n",
    "              probabilities = F.softmax(masked_q_values, dim=-1)\n",
    "              action = torch.multinomial(probabilities, num_samples=1).unsqueeze(0)\n",
    "          # Take action in the environment\n",
    "          new_node = env.edge_index[action[0].item()]\n",
    "          next_state, reward, done, _,route = env.step(new_node)\n",
    "          # Update current state\n",
    "          state = next_state\n",
    "          # Update list of previously taken actions\n",
    "          taken_actions.append(action[0].item())\n",
    "          if done :\n",
    "            total_reward =0\n",
    "            total_revenue = 0\n",
    "            total_time = 0\n",
    "            feasible = 1\n",
    "            steps = len(route)-1\n",
    "            for j in range(0,steps):\n",
    "              reward = reward_matrix.iloc[route[j],route[j+1]]\n",
    "              revenue = revenue_matrix.iloc[route[j],route[j+1]]\n",
    "              time = time_matrix.iloc[route[j],route[j+1]]\n",
    "              total_reward = total_reward + reward\n",
    "              total_revenue = total_revenue + revenue\n",
    "              total_time = total_time + time\n",
    "              loads = loads_matrix.iloc[route[j],route[j+1]]\n",
    "              if loads < 2:\n",
    "                feasible = 0\n",
    "      if total_reward > 0 and feasible == 1:\n",
    "        type1=type1+1\n",
    "      elif total_reward > 0 and feasible == 0:\n",
    "        type2=type2+1\n",
    "      elif total_reward <= 0 and feasible == 1:\n",
    "        type3=type3+1\n",
    "      else:\n",
    "        type4=type4+1\n",
    "      days = calculate_days(route, time_matrix)\n",
    "      visualized_route = visualize_route(route,hub_labels)\n",
    "      # Output episode solution\n",
    "      print(\"Route:\",visualized_route,\"Profit:\",total_reward,\"Feasible:\",feasible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Profitable Routes  Non-Profitable Routes\n",
      "Doable Routes                     50                      0\n",
      "Non Doable Routes                  0                      0\n"
     ]
    }
   ],
   "source": [
    "#Display Confusion matrix\n",
    "# Create the confusion matrix using a dictionary\n",
    "data = {\n",
    "    'Profitable Routes': [type1, type2],\n",
    "    'Non-Profitable Routes': [type3, type4]\n",
    "}\n",
    "# Define the index labels\n",
    "index_labels = ['Doable Routes', 'Non Doable Routes']\n",
    "# Create the DataFrame\n",
    "confusion_matrix = pd.DataFrame(data, index=index_labels)\n",
    "# Display the DataFrame\n",
    "print(confusion_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
